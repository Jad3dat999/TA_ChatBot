[
  {
    "text": "Signing Special Registration Forms E-mail me and CC Marci Wilson <mlw8@rice.edu> who can sign \u2022 forms on my behalf (provided I approve). If you are from outside Rice, please coordinate with an administrator \u2022 at your institution who can consolidate your Institution\u2019s required forms (from all registrants from your institution) After that you will have Rice NetID and access to Rice Canvas \u2022",
    "source": "Deep Machine Learning - Slide 2",
    "source_detail": "ELEC576-Lec01.pdf, Page 2",
    "lecture": "Deep Machine Learning",
    "lecture_number": "576",
    "page": 2,
    "content_type": "text",
    "doc_id": "slide_576_2",
    "doc_type": "slide",
    "is_definition": false,
    "contains_equation": false,
    "importance": "medium",
    "tags": [
      "Rice NetID",
      "Rice Canvas",
      "email communication",
      "Special Registration Forms",
      "administrator coordination"
    ]
  },
  {
    "text": "About Me \u2022 Education Ph.D in Applied Mathematics/Computer Science (Harvard 2008) \u2022 Industry (building real-time inference systems) \u2022 \u2022 MIT Lincoln Laboratory: Ballistic Missile Defense (2 years) \u2022 High-Frequency Trading (4 years): fast inference on extremely large datasets Return to Academia \u2022 Postdoc (Rich Baraniuk): theory of deep learning \u2022 \u2022 New Faculty at Baylor College of Medicine (Neuroscience), joint with Rice ECE: check out ankitlab.co for more details about my lab\u2019s mission at the intersection of deep learning and computational neuroscience",
    "source": "Deep Machine Learning - Slide 3",
    "source_detail": "ELEC576-Lec01.pdf, Page 3",
    "lecture": "Deep Machine Learning",
    "lecture_number": "576",
    "page": 3,
    "content_type": "text",
    "doc_id": "slide_576_3",
    "doc_type": "slide",
    "is_definition": false,
    "contains_equation": false,
    "importance": "high",
    "tags": [
      "Computer Science",
      "High-Frequency Trading",
      "Neuroscience",
      "Deep Learning",
      "Applied Mathematics"
    ]
  },
  {
    "text": "Adapting to a Fully Online Course Motivation: It can wane more easily. Attention spans can shorten. \u2022 Need for more Interaction: active participants should be even more active if possible; especially helpful \u2022 to the less active Via Chat if not Voice: one TA will be \u201cVoice of the Chat\u201d \u2022 Piazza (introduce yourself with a short blurb!) \u2022 Considering a Virtual gathering to facilitate formation of final project teams \u2022 More Diversity: I will try to \u2022 Mix in diverse types of media \u2022 More interactive exercises \u2022 More breaks (if needed) \u2022",
    "source": "Deep Machine Learning - Slide 4",
    "source_detail": "ELEC576-Lec01.pdf, Page 4",
    "lecture": "Deep Machine Learning",
    "lecture_number": "576",
    "page": 4,
    "content_type": "text",
    "doc_id": "slide_576_4",
    "doc_type": "slide",
    "is_definition": false,
    "contains_equation": false,
    "importance": "medium",
    "tags": [
      "attention"
    ]
  },
  {
    "text": "Deep Learning: A Short Preview",
    "source": "Deep Machine Learning - Slide 5",
    "source_detail": "ELEC576-Lec01.pdf, Page 5",
    "lecture": "Deep Machine Learning",
    "lecture_number": "576",
    "page": 5,
    "content_type": "text",
    "doc_id": "slide_576_5",
    "doc_type": "slide",
    "is_definition": false,
    "contains_equation": false,
    "importance": "high",
    "tags": [
      "Deep Learning",
      "Neural Networks",
      "Artificial Intelligence",
      "Machine Learning"
    ]
  },
  {
    "text": "Why do we need Deep Learning? What makes Object Recognition so Hard? aeroplane bicycle bird car [Girshick et al., CVPR 2014] Key Challenge: Object recognition (and sensory perception in general) is plagued by large amounts of nuisance variation. Nuisance Variation: affects sensory input (image) but not the task target (object class) I Ex: Object Recognition, Nuisances = changes in location, pose, viewpoint, lighting, I expression, . . . Ex: Speech Recognition, Nuisances = changes in pitch, volume, pace, accent, . . . I Nuisance variables are task-dependent and can be implicit I 4",
    "source": "Deep Machine Learning - Slide 6",
    "source_detail": "ELEC576-Lec01.pdf, Page 6",
    "lecture": "Deep Machine Learning",
    "lecture_number": "576",
    "page": 6,
    "content_type": "mixed",
    "doc_id": "slide_576_6",
    "doc_type": "slide",
    "is_definition": true,
    "contains_equation": false,
    "importance": "high",
    "tags": [
      "Nuisance Variation",
      "Sensory Perception",
      "Deep Learning",
      "Object Recognition",
      "Speech Recognition"
    ]
  },
  {
    "text": "Neuron Perspective Figure 2. Untangling Object Representations (A) The response pattern of a population of visual neurons (e.g., retinal ganglion cells) to each image (three images shown) is a point in a very high- dimensional space where each axis is the response level of each neuron.",
    "source": "Deep Machine Learning - Slide 7",
    "source_detail": "ELEC576-Lec01.pdf, Page 7",
    "lecture": "Deep Machine Learning",
    "lecture_number": "576",
    "page": 7,
    "content_type": "figure",
    "doc_id": "slide_576_7_chunk1",
    "doc_type": "slide",
    "parent_doc_id": "slide_576_7",
    "chunk_index": 1,
    "total_chunks": 12,
    "is_definition": true,
    "contains_equation": false,
    "importance": "high",
    "tags": [
      "generative models",
      "neural networks"
    ]
  },
  {
    "text": "(B) All possible identity-preserving transforma- tions of an object will form a low-dimensional manifold of points in the population vector space, i.e., a continuous surface (represented here, for simplicity, as a one-dimensional trajectory; see red and blue lines). Neuronal populations in early visual areas (retinal ganglion cells, LGN, V1) contain object identity manifolds that are highly curved and tangled together (see red and blue manifolds in left panel).",
    "source": "Deep Machine Learning - Slide 7",
    "source_detail": "ELEC576-Lec01.pdf, Page 7",
    "lecture": "Deep Machine Learning",
    "lecture_number": "576",
    "page": 7,
    "content_type": "figure",
    "doc_id": "slide_576_7_chunk2",
    "doc_type": "slide",
    "parent_doc_id": "slide_576_7",
    "chunk_index": 2,
    "total_chunks": 12,
    "is_definition": false,
    "contains_equation": false,
    "importance": "high",
    "tags": [
      "generative models",
      "neural networks"
    ]
  },
  {
    "text": "The solution to the recognition problem is conceptualized as a series of successive re-representations along the ventral Why do we need Deep Learning? stream (black arrow) to a new population repre- Disentangling Variation in the Sensory Input sentation (IT) that allows easy separation of one namable object\u2019s manifold (e.g., a car; see red manifold) from all other object identity manifolds (of which the blue manifold is just one example).",
    "source": "Deep Machine Learning - Slide 7",
    "source_detail": "ELEC576-Lec01.pdf, Page 7",
    "lecture": "Deep Machine Learning",
    "lecture_number": "576",
    "page": 7,
    "content_type": "figure",
    "doc_id": "slide_576_7_chunk3",
    "doc_type": "slide",
    "parent_doc_id": "slide_576_7",
    "chunk_index": 3,
    "total_chunks": 12,
    "is_definition": true,
    "contains_equation": false,
    "importance": "high",
    "tags": [
      "generative models",
      "neural networks"
    ]
  },
  {
    "text": "Geometrically, this amounts to remapping the visual images so that the resulting object mani- Problem: How to deal with nuisance folds can be separated by a simple weighted variation in the input? summation rule (i.e., a hyperplane, see black dashed line; see DiCarlo and Cox, 2007).",
    "source": "Deep Machine Learning - Slide 7",
    "source_detail": "ELEC576-Lec01.pdf, Page 7",
    "lecture": "Deep Machine Learning",
    "lecture_number": "576",
    "page": 7,
    "content_type": "figure",
    "doc_id": "slide_576_7_chunk4",
    "doc_type": "slide",
    "parent_doc_id": "slide_576_7",
    "chunk_index": 4,
    "total_chunks": 12,
    "is_definition": false,
    "contains_equation": true,
    "importance": "high",
    "tags": [
      "generative models",
      "neural networks"
    ]
  },
  {
    "text": "(C) The vast majority of naturally experienced Solution: Build representations that are images are not accompanied with labels (e.g., \u2018\u2018car,\u2019\u2019 \u2018\u2018plane\u2019\u2019), and are thus shown as black I Selective: Sensitive to task-relevant points. However, images arising from the same (target) features source (e.g., edge, object) tend to be nearby in time (gray arrows).",
    "source": "Deep Machine Learning - Slide 7",
    "source_detail": "ELEC576-Lec01.pdf, Page 7",
    "lecture": "Deep Machine Learning",
    "lecture_number": "576",
    "page": 7,
    "content_type": "figure",
    "doc_id": "slide_576_7_chunk5",
    "doc_type": "slide",
    "parent_doc_id": "slide_576_7",
    "chunk_index": 5,
    "total_chunks": 12,
    "is_definition": false,
    "contains_equation": false,
    "importance": "medium",
    "tags": [
      "generative models",
      "neural networks"
    ]
  },
  {
    "text": "Recent evidence shows that I Invariant: Robust to task-irrelevant the ventral stream uses that implicit temporal contiguity instruction to build IT neuronal toler- (nuisance) features ance, and we speculate that this is due to an unsupervised learning strategy termed cortical I Multi-task: Useful for many different local subspace untangling (see text). Note that, tasks under this hypothetical strategy, \u2018\u2018shape coding\u2019\u2019 is not the explicit goal\u2014instead, \u2018\u2018shape\u2019\u2019 infor- DiCarlo, J. J. et al.",
    "source": "Deep Machine Learning - Slide 7",
    "source_detail": "ELEC576-Lec01.pdf, Page 7",
    "lecture": "Deep Machine Learning",
    "lecture_number": "576",
    "page": 7,
    "content_type": "figure",
    "doc_id": "slide_576_7_chunk6",
    "doc_type": "slide",
    "parent_doc_id": "slide_576_7",
    "chunk_index": 6,
    "total_chunks": 12,
    "is_definition": false,
    "contains_equation": false,
    "importance": "high",
    "tags": [
      "generative models",
      "neural networks"
    ]
  },
  {
    "text": "How does the brain solve visual object recognition? Neuron (2012). mation emerges as the residual natural image variation that is not specified by naturally occurring temporal contiguity cues. The Holy Grail of Machine Learning Learn a disentangled representation: 2. What Do We Know about the one that factors out variation in the sensory input Brain\u2019s \u2018\u2018Object\u2019\u2019 Representation? The Ventral Visual Stream Houses into meaningful intrinsic degrees of freedom.",
    "source": "Deep Machine Learning - Slide 7",
    "source_detail": "ELEC576-Lec01.pdf, Page 7",
    "lecture": "Deep Machine Learning",
    "lecture_number": "576",
    "page": 7,
    "content_type": "figure",
    "doc_id": "slide_576_7_chunk7",
    "doc_type": "slide",
    "parent_doc_id": "slide_576_7",
    "chunk_index": 7,
    "total_chunks": 12,
    "is_definition": false,
    "contains_equation": false,
    "importance": "high",
    "tags": [
      "generative models",
      "neural networks"
    ]
  },
  {
    "text": "Critical Circuitry for Core Object Recognition Decades of evidence argue that 5 the primate ventral visual processing stream\u2014a set of cortical areas arranged along the occipital and temporal lobes that this perspective is a crucial intermediate level of under- (Figure 3A)\u2014houses key circuits that underlie object recognition standing for the core recognition problem, akin to studying aero- behavior (for reviews, see Gross, 1994; Miyashita, 1993; Orban, dynamics, rather than feathers, to understand flight.",
    "source": "Deep Machine Learning - Slide 7",
    "source_detail": "ELEC576-Lec01.pdf, Page 7",
    "lecture": "Deep Machine Learning",
    "lecture_number": "576",
    "page": 7,
    "content_type": "figure",
    "doc_id": "slide_576_7_chunk8",
    "doc_type": "slide",
    "parent_doc_id": "slide_576_7",
    "chunk_index": 8,
    "total_chunks": 12,
    "is_definition": false,
    "contains_equation": false,
    "importance": "high",
    "tags": [
      "generative models",
      "neural networks"
    ]
  },
  {
    "text": "Importantly, 2008; Rolls, 2000). Object recognition is not the only ventral this perspective suggests the immediate goal of determining stream function, and we refer the reader to others (Kravitz how well each visual area has untangled the neuronal represen- et al., 2010; Logothetis and Sheinberg, 1996; Maunsell and tation, which can be quantified via a simple summation decoding Treue, 2006; Tsao and Livingstone, 2008) for a broader discus- scheme (described above).",
    "source": "Deep Machine Learning - Slide 7",
    "source_detail": "ELEC576-Lec01.pdf, Page 7",
    "lecture": "Deep Machine Learning",
    "lecture_number": "576",
    "page": 7,
    "content_type": "figure",
    "doc_id": "slide_576_7_chunk9",
    "doc_type": "slide",
    "parent_doc_id": "slide_576_7",
    "chunk_index": 9,
    "total_chunks": 12,
    "is_definition": false,
    "contains_equation": true,
    "importance": "high",
    "tags": [
      "generative models",
      "neural networks"
    ]
  },
  {
    "text": "It redirects emphasis toward deter- sion.",
    "source": "Deep Machine Learning - Slide 7",
    "source_detail": "ELEC576-Lec01.pdf, Page 7",
    "lecture": "Deep Machine Learning",
    "lecture_number": "576",
    "page": 7,
    "content_type": "figure",
    "doc_id": "slide_576_7_chunk10",
    "doc_type": "slide",
    "parent_doc_id": "slide_576_7",
    "chunk_index": 10,
    "total_chunks": 12,
    "is_definition": false,
    "contains_equation": false,
    "importance": "low",
    "tags": [
      "generative models",
      "neural networks"
    ]
  },
  {
    "text": "Whereas lesions in the posterior ventral stream produce mining the mechanisms that might contribute to untangling\u2014 complete blindness in part of the visual field (reviewed by Stoerig and dictates what must be \u2018\u2018explained\u2019\u2019 at the single-neuron level, and Cowey, 1997), lesions or inactivation of anterior regions, rather than creating \u2018\u2018just so\u2019\u2019 stories based on the phenomenol- especially the inferior temporal cortex (IT), can produce selective ogies of heterogenous single neurons.",
    "source": "Deep Machine Learning - Slide 7",
    "source_detail": "ELEC576-Lec01.pdf, Page 7",
    "lecture": "Deep Machine Learning",
    "lecture_number": "576",
    "page": 7,
    "content_type": "figure",
    "doc_id": "slide_576_7_chunk11",
    "doc_type": "slide",
    "parent_doc_id": "slide_576_7",
    "chunk_index": 11,
    "total_chunks": 12,
    "is_definition": false,
    "contains_equation": false,
    "importance": "high",
    "tags": [
      "generative models",
      "neural networks"
    ]
  },
  {
    "text": "deficits in the ability to distinguish among complex objects 418 Neuron 73, February 9, 2012 \u00aa2012 Elsevier Inc..",
    "source": "Deep Machine Learning - Slide 7",
    "source_detail": "ELEC576-Lec01.pdf, Page 7",
    "lecture": "Deep Machine Learning",
    "lecture_number": "576",
    "page": 7,
    "content_type": "figure",
    "doc_id": "slide_576_7_chunk12",
    "doc_type": "slide",
    "parent_doc_id": "slide_576_7",
    "chunk_index": 12,
    "total_chunks": 12,
    "is_definition": false,
    "contains_equation": false,
    "importance": "medium",
    "tags": [
      "generative models",
      "neural networks"
    ]
  },
  {
    "text": "Why do we need Deep Learning? Neuron How to Disentangle Nuisance Variation? Perspective Potential Solution: Look to the Brain for guidance. Figure 6.",
    "source": "Deep Machine Learning - Slide 8",
    "source_detail": "ELEC576-Lec01.pdf, Page 8",
    "lecture": "Deep Machine Learning",
    "lecture_number": "576",
    "page": 8,
    "content_type": "figure",
    "doc_id": "slide_576_8_chunk1",
    "doc_type": "slide",
    "parent_doc_id": "slide_576_8",
    "chunk_index": 1,
    "total_chunks": 14,
    "is_definition": false,
    "contains_equation": false,
    "importance": "high",
    "tags": [
      "cnn",
      "neural networks"
    ]
  },
  {
    "text": "Serial-Chain Discriminative Models of Object Recognition Hubel and Wiesel\u2019s discovery of simple/complex cells and their Ascplasseocf biioaloglicaplly rinsopirped emordetlsioef osbjecot f I recognition aims to achieve a gradual untangling of object manifolds by stacking layers of neuronal selectivity and tolerance/invariance units in a largely feedforward hierarchy.",
    "source": "Deep Machine Learning - Slide 8",
    "source_detail": "ELEC576-Lec01.pdf, Page 8",
    "lecture": "Deep Machine Learning",
    "lecture_number": "576",
    "page": 8,
    "content_type": "figure",
    "doc_id": "slide_576_8_chunk2",
    "doc_type": "slide",
    "parent_doc_id": "slide_576_8",
    "chunk_index": 2,
    "total_chunks": 14,
    "is_definition": true,
    "contains_equation": false,
    "importance": "high",
    "tags": [
      "cnn",
      "neural networks"
    ]
  },
  {
    "text": "In this example, units in each layer process their inputs using either AND-like (see red units) and OR-like (e.g.,\u2018\u2018MAX,\u2019\u2019seeblueunits)operations,andthose operations are applied in parallel in alternating layers.",
    "source": "Deep Machine Learning - Slide 8",
    "source_detail": "ELEC576-Lec01.pdf, Page 8",
    "lecture": "Deep Machine Learning",
    "lecture_number": "576",
    "page": 8,
    "content_type": "figure",
    "doc_id": "slide_576_8_chunk3",
    "doc_type": "slide",
    "parent_doc_id": "slide_576_8",
    "chunk_index": 3,
    "total_chunks": 14,
    "is_definition": false,
    "contains_equation": false,
    "importance": "medium",
    "tags": [
      "cnn",
      "neural networks"
    ]
  },
  {
    "text": "The AND-like operation constructs some tuning for combinations of visual features (e.g., simple cells in V1), and the OR-like operation constructs some tolerance to changes in, e.g., position and size by pooling over AND-like units with identical feature tuning, but having receptive fields with slightly different retinal locations and sizes.",
    "source": "Deep Machine Learning - Slide 8",
    "source_detail": "ELEC576-Lec01.pdf, Page 8",
    "lecture": "Deep Machine Learning",
    "lecture_number": "576",
    "page": 8,
    "content_type": "figure",
    "doc_id": "slide_576_8_chunk4",
    "doc_type": "slide",
    "parent_doc_id": "slide_576_8",
    "chunk_index": 4,
    "total_chunks": 14,
    "is_definition": false,
    "contains_equation": false,
    "importance": "high",
    "tags": [
      "cnn",
      "neural networks"
    ]
  },
  {
    "text": "This can produce a gradual increase of the tolerance to variation in object appearance along thehierarchy(e.g.,Fukushima,1980;Riesenhuber and Poggio, 1999b; Serre et al., 2007a). AND-like operations and OR-like operations can each be formulated(KouhandPoggio,2008)asavariantof a standard LN neuronal model with nonlinear gain control mechanisms (e.g., a type of NLN model, see dashed frame). model which has the same capability for DiCarlo, J. J. et al.",
    "source": "Deep Machine Learning - Slide 8",
    "source_detail": "ELEC576-Lec01.pdf, Page 8",
    "lecture": "Deep Machine Learning",
    "lecture_number": "576",
    "page": 8,
    "content_type": "figure",
    "doc_id": "slide_576_8_chunk5",
    "doc_type": "slide",
    "parent_doc_id": "slide_576_8",
    "chunk_index": 5,
    "total_chunks": 14,
    "is_definition": false,
    "contains_equation": true,
    "importance": "high",
    "tags": [
      "cnn",
      "neural networks"
    ]
  },
  {
    "text": "How does the brain solve visual object recognition? Neuropnatte(r2n0re1c2o)g.nition as a human being, it would give us a powerful clue to the understanding of the neural mechanism Key Inspiration from Neuroscience in the brain\u2019\u2019 (Fukushima, 1980).",
    "source": "Deep Machine Learning - Slide 8",
    "source_detail": "ELEC576-Lec01.pdf, Page 8",
    "lecture": "Deep Machine Learning",
    "lecture_number": "576",
    "page": 8,
    "content_type": "figure",
    "doc_id": "slide_576_8_chunk6",
    "doc_type": "slide",
    "parent_doc_id": "slide_576_8",
    "chunk_index": 6,
    "total_chunks": 14,
    "is_definition": true,
    "contains_equation": false,
    "importance": "high",
    "tags": [
      "cnn",
      "neural networks"
    ]
  },
  {
    "text": "More recent modeling efforts have significantly refined and extended this approach (e.g., Build up feature selectivity and tolerance over multiple layersLeciunn etaal.,h20ie04r; aMerl,c1h99y7; Riesen- huber and Poggio, 1999b; Serre)et al., ML architectures: Neocognitron, HMAX, SIFT, and modern200 D 7a).",
    "source": "Deep Machine Learning - Slide 8",
    "source_detail": "ELEC576-Lec01.pdf, Page 8",
    "lecture": "Deep Machine Learning",
    "lecture_number": "576",
    "page": 8,
    "content_type": "figure",
    "doc_id": "slide_576_8_chunk7",
    "doc_type": "slide",
    "parent_doc_id": "slide_576_8",
    "chunk_index": 7,
    "total_chunks": 14,
    "is_definition": false,
    "contains_equation": true,
    "importance": "high",
    "tags": [
      "cnn",
      "neural networks"
    ]
  },
  {
    "text": "e W e hil p e we C ca o nn n ot v re n view et all s the computer vision or neural network models that have relevance to object recognition in primates here, we refer 6 Testing Hypotheses: Instantiated Models of the Ventral the reader to reviews by Bengio (2009), Edelman (1999), Riesen- Stream huber and Poggio (2000), and Zhu and Mumford (2006).",
    "source": "Deep Machine Learning - Slide 8",
    "source_detail": "ELEC576-Lec01.pdf, Page 8",
    "lecture": "Deep Machine Learning",
    "lecture_number": "576",
    "page": 8,
    "content_type": "figure",
    "doc_id": "slide_576_8_chunk8",
    "doc_type": "slide",
    "parent_doc_id": "slide_576_8",
    "chunk_index": 8,
    "total_chunks": 14,
    "is_definition": false,
    "contains_equation": false,
    "importance": "high",
    "tags": [
      "cnn",
      "neural networks"
    ]
  },
  {
    "text": "Experimental approaches are effective at describing undocu- Commensurate with the serial chain, cascaded untangling mented behaviors of ventral stream neurons, but alone they discussion above, some ventral-stream-inspired models imple- cannot indicate when that search is complete. Similarly, \u2018\u2018word ment a canonical, iterated computation, with the overall goal of models\u2019\u2019 (including ours, above) are not falsifiable algorithms.",
    "source": "Deep Machine Learning - Slide 8",
    "source_detail": "ELEC576-Lec01.pdf, Page 8",
    "lecture": "Deep Machine Learning",
    "lecture_number": "576",
    "page": 8,
    "content_type": "figure",
    "doc_id": "slide_576_8_chunk9",
    "doc_type": "slide",
    "parent_doc_id": "slide_576_8",
    "chunk_index": 9,
    "total_chunks": 14,
    "is_definition": false,
    "contains_equation": false,
    "importance": "high",
    "tags": [
      "cnn",
      "neural networks"
    ]
  },
  {
    "text": "producing a good object representation at their highest stage To make progress, we need to construct ventral-stream- (Fukushima, 1980; Riesenhuber and Poggio, 1999b; Serre inspired, instantiated computational models and compare their et al., 2007a). These models include a handful of hierarchically performance with neuronal data and human performance on arranged layers, each implementing AND-like operations tobuild object recognition tasks.",
    "source": "Deep Machine Learning - Slide 8",
    "source_detail": "ELEC576-Lec01.pdf, Page 8",
    "lecture": "Deep Machine Learning",
    "lecture_number": "576",
    "page": 8,
    "content_type": "figure",
    "doc_id": "slide_576_8_chunk10",
    "doc_type": "slide",
    "parent_doc_id": "slide_576_8",
    "chunk_index": 10,
    "total_chunks": 14,
    "is_definition": false,
    "contains_equation": false,
    "importance": "high",
    "tags": [
      "cnn",
      "neural networks"
    ]
  },
  {
    "text": "Thus, computational modeling cannot selectivity followed by OR-like operations to build tolerance to be taken lightly. Together, the set of alternative models define identity preserving transformations (Figure 6).",
    "source": "Deep Machine Learning - Slide 8",
    "source_detail": "ELEC576-Lec01.pdf, Page 8",
    "lecture": "Deep Machine Learning",
    "lecture_number": "576",
    "page": 8,
    "content_type": "figure",
    "doc_id": "slide_576_8_chunk11",
    "doc_type": "slide",
    "parent_doc_id": "slide_576_8",
    "chunk_index": 11,
    "total_chunks": 14,
    "is_definition": true,
    "contains_equation": false,
    "importance": "high",
    "tags": [
      "cnn",
      "neural networks"
    ]
  },
  {
    "text": "Notably, both the space of falsifiable alternative hypotheses in the field, and AND-like and OR-like computations can be formulated as vari- the success of some such algorithms will be among our first indi- ants of the NLN model class described above (Kouh and Poggio, cations that we are on the path to understanding visual object 2008), illustrating the link to canonical cortical models (see inset recognition in the brain. in Figure 6).",
    "source": "Deep Machine Learning - Slide 8",
    "source_detail": "ELEC576-Lec01.pdf, Page 8",
    "lecture": "Deep Machine Learning",
    "lecture_number": "576",
    "page": 8,
    "content_type": "figure",
    "doc_id": "slide_576_8_chunk12",
    "doc_type": "slide",
    "parent_doc_id": "slide_576_8",
    "chunk_index": 12,
    "total_chunks": 14,
    "is_definition": false,
    "contains_equation": true,
    "importance": "high",
    "tags": [
      "cnn",
      "neural networks"
    ]
  },
  {
    "text": "Moreover, these relatively simple hierarchical The idea of using biologically inspired, hierarchical computa- models can produce model neurons that signal object identity, tionalalgorithms tounderstand theneuronalmechanismsunder- are somewhat tolerant to identity-preserving transformations, lying invariant object recognition tasks is not new: \u2018\u2018The mecha- and can rival human performance for ultrashort, backward- nism of pattern recognition in the brain is little known, and it masked image presentations (Serre et al., 2007a).",
    "source": "Deep Machine Learning - Slide 8",
    "source_detail": "ELEC576-Lec01.pdf, Page 8",
    "lecture": "Deep Machine Learning",
    "lecture_number": "576",
    "page": 8,
    "content_type": "figure",
    "doc_id": "slide_576_8_chunk13",
    "doc_type": "slide",
    "parent_doc_id": "slide_576_8",
    "chunk_index": 13,
    "total_chunks": 14,
    "is_definition": false,
    "contains_equation": false,
    "importance": "high",
    "tags": [
      "cnn",
      "neural networks"
    ]
  },
  {
    "text": "seems to be almost impossible to reveal it only by conventional The surprising power of such models substantially demystifies physiological experiments.. If we could make a neural network the problem of invariant object recognition, but also points out Neuron 73, February 9, 2012 \u00aa2012 Elsevier Inc. 427.",
    "source": "Deep Machine Learning - Slide 8",
    "source_detail": "ELEC576-Lec01.pdf, Page 8",
    "lecture": "Deep Machine Learning",
    "lecture_number": "576",
    "page": 8,
    "content_type": "figure",
    "doc_id": "slide_576_8_chunk14",
    "doc_type": "slide",
    "parent_doc_id": "slide_576_8",
    "chunk_index": 14,
    "total_chunks": 14,
    "is_definition": false,
    "contains_equation": false,
    "importance": "medium",
    "tags": [
      "cnn",
      "neural networks"
    ]
  },
  {
    "text": "Neural Networks Takes in inputs and returns outputs \u2022 Layers of processing: alternates between linear and nonlinear \u2022 transformations typically High expressive power / can be trained to learn complex functions \u2022 (Loosely) Inspired by the brain \u2022",
    "source": "Deep Machine Learning - Slide 9",
    "source_detail": "ELEC576-Lec01.pdf, Page 9",
    "lecture": "Deep Machine Learning",
    "lecture_number": "576",
    "page": 9,
    "content_type": "text",
    "doc_id": "slide_576_9",
    "doc_type": "slide",
    "is_definition": true,
    "contains_equation": false,
    "importance": "high",
    "tags": [
      "neural networks"
    ]
  },
  {
    "text": "Object Recognition with Convnets Deep Learning: The Current State of the Art A. Krizhevsky et al. ImageNet classification with deep convolutional neural networks (NIPS 2012) Deep Convnets I 2012: Krizhevsky et al advanced state-of-the-art in object recognition in the I ImageNet Challenge (1.2 million labeled images of objects) Subsequently benchmarks in many other vision tasks were pushed forward many I years Transfer Learning ) Recently, Google\u2019s and MSR\u2019s latest DCNs have achieved 95% accuracy, with I superhuman performance in most categories Deployed commercially in Google and Baidu Personal Image Search I 8",
    "source": "Deep Machine Learning - Slide 10",
    "source_detail": "ELEC576-Lec01.pdf, Page 10",
    "lecture": "Deep Machine Learning",
    "lecture_number": "576",
    "page": 10,
    "content_type": "figure",
    "doc_id": "slide_576_10",
    "doc_type": "slide",
    "is_definition": false,
    "contains_equation": false,
    "importance": "high",
    "tags": [
      "cnn",
      "transfer learning",
      "neural networks"
    ]
  },
  {
    "text": "Object Recognition with Convnets",
    "source": "Deep Machine Learning - Slide 11",
    "source_detail": "ELEC576-Lec01.pdf, Page 11",
    "lecture": "Deep Machine Learning",
    "lecture_number": "576",
    "page": 11,
    "content_type": "text",
    "doc_id": "slide_576_11",
    "doc_type": "slide",
    "is_definition": false,
    "contains_equation": false,
    "importance": "high",
    "tags": [
      "cnn"
    ]
  },
  {
    "text": "Facial Recognition/Verification",
    "source": "Deep Machine Learning - Slide 12",
    "source_detail": "ELEC576-Lec01.pdf, Page 12",
    "lecture": "Deep Machine Learning",
    "lecture_number": "576",
    "page": 12,
    "content_type": "text",
    "doc_id": "slide_576_12",
    "doc_type": "slide",
    "is_definition": false,
    "contains_equation": false,
    "importance": "high",
    "tags": [
      "Biometrics",
      "Facial Recognition",
      "Facial Verification"
    ]
  },
  {
    "text": "Deep Art: Combining Content and Style The Power of Deep Representations: from Different Images Separating Content from Style in Art Coarse-scale Content I from one image, Fine-scale Style from another image Observation: DCNs I learn sophisticated multi-scale representations Theoretical Result: I Mathematical formulation of separation of length scales levels of L. Gatys, A. Ecker, M.",
    "source": "Deep Machine Learning - Slide 13",
    "source_detail": "ELEC576-Lec01.pdf, Page 13",
    "lecture": "Deep Machine Learning",
    "lecture_number": "576",
    "page": 13,
    "content_type": "figure",
    "doc_id": "slide_576_13_chunk1",
    "doc_type": "slide",
    "parent_doc_id": "slide_576_13",
    "chunk_index": 1,
    "total_chunks": 3,
    "is_definition": false,
    "contains_equation": true,
    "importance": "high",
    "tags": [
      "Mathematical formulation",
      "Content and Style",
      "Deep Art",
      "DCNs",
      "Deep Representations"
    ]
  },
  {
    "text": "Bethge ) abstraction A Neural Algorithm of Artistic Style (ArXiV 2015: eprint arXiv:1508.06576) 25 Figure 2: Images that combine the content of a photograph with the style of several well-known artworks. The images were created by finding an image that simultaneously matches the content representation of the photograph and the style representation of the artwork (see Methods). The original photograph depicting the Neckarfront in Tu\u00a8bingen, Germany, is shown in A (Photo: Andreas Praefcke).",
    "source": "Deep Machine Learning - Slide 13",
    "source_detail": "ELEC576-Lec01.pdf, Page 13",
    "lecture": "Deep Machine Learning",
    "lecture_number": "576",
    "page": 13,
    "content_type": "figure",
    "doc_id": "slide_576_13_chunk2",
    "doc_type": "slide",
    "parent_doc_id": "slide_576_13",
    "chunk_index": 2,
    "total_chunks": 3,
    "is_definition": false,
    "contains_equation": false,
    "importance": "high",
    "tags": [
      "content representation",
      "Neural Algorithm of Artistic Style",
      "style representation",
      "photograph",
      "artworks"
    ]
  },
  {
    "text": "The painting that provided the style for the respective generated image is shown in the bottom left corner of each panel. B The Shipwreck of the Minotaur by J.M.W. 5 Turner, 1805. C The Starry Night by Vincent van Gogh, 1889. D Der Schrei by Edvard Munch, 1893. E Femme nue assise by Pablo Picasso, 1910. F Composition VII by Wassily Kandinsky, 1913..",
    "source": "Deep Machine Learning - Slide 13",
    "source_detail": "ELEC576-Lec01.pdf, Page 13",
    "lecture": "Deep Machine Learning",
    "lecture_number": "576",
    "page": 13,
    "content_type": "figure",
    "doc_id": "slide_576_13_chunk3",
    "doc_type": "slide",
    "parent_doc_id": "slide_576_13",
    "chunk_index": 3,
    "total_chunks": 3,
    "is_definition": false,
    "contains_equation": false,
    "importance": "low",
    "tags": [
      "Vincent van Gogh",
      "Pablo Picasso",
      "Wassily Kandinsky",
      "Edvard Munch",
      "J.M.W. Turner"
    ]
  },
  {
    "text": "Many Medical Applications",
    "source": "Deep Machine Learning - Slide 14",
    "source_detail": "ELEC576-Lec01.pdf, Page 14",
    "lecture": "Deep Machine Learning",
    "lecture_number": "576",
    "page": 14,
    "content_type": "text",
    "doc_id": "slide_576_14",
    "doc_type": "slide",
    "is_definition": false,
    "contains_equation": false,
    "importance": "high",
    "tags": [
      "Innovation",
      "Healthcare",
      "Medical Applications",
      "Technology",
      "Biomedicine"
    ]
  },
  {
    "text": "Playing Video Games https://www.youtube.com/watch?v=V1eYniJ0Rnk",
    "source": "Deep Machine Learning - Slide 15",
    "source_detail": "ELEC576-Lec01.pdf, Page 15",
    "lecture": "Deep Machine Learning",
    "lecture_number": "576",
    "page": 15,
    "content_type": "text",
    "doc_id": "slide_576_15",
    "doc_type": "slide",
    "is_definition": false,
    "contains_equation": false,
    "importance": "medium",
    "tags": [
      "Video Games",
      "Educational Value",
      "Cognitive Skills",
      "Gaming Benefits",
      "Social Interaction"
    ]
  },
  {
    "text": "Self-Driving Cars https://www.youtube.com/watch?v=QpWTyFIUvYk",
    "source": "Deep Machine Learning - Slide 17",
    "source_detail": "ELEC576-Lec01.pdf, Page 17",
    "lecture": "Deep Machine Learning",
    "lecture_number": "576",
    "page": 17,
    "content_type": "text",
    "doc_id": "slide_576_17",
    "doc_type": "slide",
    "is_definition": false,
    "contains_equation": false,
    "importance": "high",
    "tags": [
      "Autonomous Vehicles",
      "Self-Driving Cars",
      "Transportation",
      "Safety",
      "Technology"
    ]
  },
  {
    "text": "Deep Sensorimotor Learning for Robotics https://www.youtube.com/watch?v=Es83Co_Vz78",
    "source": "Deep Machine Learning - Slide 18",
    "source_detail": "ELEC576-Lec01.pdf, Page 18",
    "lecture": "Deep Machine Learning",
    "lecture_number": "576",
    "page": 18,
    "content_type": "text",
    "doc_id": "slide_576_18",
    "doc_type": "slide",
    "is_definition": false,
    "contains_equation": false,
    "importance": "high",
    "tags": [
      "Machine Learning",
      "Sensorimotor Learning",
      "Robotics",
      "Artificial Intelligence",
      "Deep Learning"
    ]
  },
  {
    "text": "Generative Models for Natural Images",
    "source": "Deep Machine Learning - Slide 19",
    "source_detail": "ELEC576-Lec01.pdf, Page 19",
    "lecture": "Deep Machine Learning",
    "lecture_number": "576",
    "page": 19,
    "content_type": "figure",
    "doc_id": "slide_576_19",
    "doc_type": "slide",
    "is_definition": false,
    "contains_equation": false,
    "importance": "high",
    "tags": [
      "generative models"
    ]
  },
  {
    "text": "Generative Adversarial Nets (GANs) for Natural Image Translation https://arxiv.org/pdf/1703.10593.pdf",
    "source": "Deep Machine Learning - Slide 20",
    "source_detail": "ELEC576-Lec01.pdf, Page 20",
    "lecture": "Deep Machine Learning",
    "lecture_number": "576",
    "page": 20,
    "content_type": "figure",
    "doc_id": "slide_576_20",
    "doc_type": "slide",
    "is_definition": true,
    "contains_equation": true,
    "importance": "high",
    "tags": [
      "generative models"
    ]
  },
  {
    "text": "Progressive Growing of Generative Adversarial Nets (GANs) https://github.com/tkarras/progressive_growing_of_gans Youtube",
    "source": "Deep Machine Learning - Slide 21",
    "source_detail": "ELEC576-Lec01.pdf, Page 21",
    "lecture": "Deep Machine Learning",
    "lecture_number": "576",
    "page": 21,
    "content_type": "text",
    "doc_id": "slide_576_21",
    "doc_type": "slide",
    "is_definition": false,
    "contains_equation": true,
    "importance": "high",
    "tags": [
      "generative models"
    ]
  },
  {
    "text": "Generating Shakespeare",
    "source": "Deep Machine Learning - Slide 22",
    "source_detail": "ELEC576-Lec01.pdf, Page 22",
    "lecture": "Deep Machine Learning",
    "lecture_number": "576",
    "page": 22,
    "content_type": "text",
    "doc_id": "slide_576_22",
    "doc_type": "slide",
    "is_definition": false,
    "contains_equation": false,
    "importance": "medium",
    "tags": [
      "language",
      "drama",
      "Shakespeare",
      "literature",
      "playwriting"
    ]
  },
  {
    "text": "Generating Wiki Markup",
    "source": "Deep Machine Learning - Slide 23",
    "source_detail": "ELEC576-Lec01.pdf, Page 23",
    "lecture": "Deep Machine Learning",
    "lecture_number": "576",
    "page": 23,
    "content_type": "text",
    "doc_id": "slide_576_23",
    "doc_type": "slide",
    "is_definition": false,
    "contains_equation": false,
    "importance": "medium",
    "tags": [
      "Text Formatting",
      "Generating",
      "Wiki Markup"
    ]
  },
  {
    "text": "Generating Linux Source Code",
    "source": "Deep Machine Learning - Slide 24",
    "source_detail": "ELEC576-Lec01.pdf, Page 24",
    "lecture": "Deep Machine Learning",
    "lecture_number": "576",
    "page": 24,
    "content_type": "text",
    "doc_id": "slide_576_24",
    "doc_type": "slide",
    "is_definition": false,
    "contains_equation": false,
    "importance": "medium",
    "tags": [
      "Linux",
      "Source Code",
      "Generating"
    ]
  },
  {
    "text": "Generating Algebraic Topology",
    "source": "Deep Machine Learning - Slide 25",
    "source_detail": "ELEC576-Lec01.pdf, Page 25",
    "lecture": "Deep Machine Learning",
    "lecture_number": "576",
    "page": 25,
    "content_type": "text",
    "doc_id": "slide_576_25",
    "doc_type": "slide",
    "is_definition": false,
    "contains_equation": true,
    "importance": "high",
    "tags": [
      "Geometry",
      "Algebraic Topology",
      "Mathematics",
      "Topology"
    ]
  },
  {
    "text": "Face Representation in the Brain A B C Able to predict specific face from Neural Data using a linear decoder. Last layer in CNN has the same distribution of activations as the last layer in visual cortex Figure 3. Reconstruction of Facial Images Using Linear Regression (A) Using facial features decoded by linear regression in Figure 2, facial images could be reconstructed. Predicted faces by three neuronal populations and the corresponding actual stimuli presented in the experiment are shown.",
    "source": "Deep Machine Learning - Slide 26",
    "source_detail": "ELEC576-Lec01.pdf, Page 26",
    "lecture": "Deep Machine Learning",
    "lecture_number": "576",
    "page": 26,
    "content_type": "figure",
    "doc_id": "slide_576_26_chunk1",
    "doc_type": "slide",
    "parent_doc_id": "slide_576_26",
    "chunk_index": 1,
    "total_chunks": 10,
    "is_definition": false,
    "contains_equation": true,
    "importance": "high",
    "tags": [
      "cnn",
      "neural networks"
    ]
  },
  {
    "text": "(B) Decoding accuracy as function of number of faces, using a Euclidean distance model (black solid line). Decoding accuracy based on two alternative models, nearest neighbor in the space of population response (gray dashed line, see STAR Methods) and average of nearest 50 neighbors (gray solid line), were much lower. The black dashed line represents chance level.",
    "source": "Deep Machine Learning - Slide 26",
    "source_detail": "ELEC576-Lec01.pdf, Page 26",
    "lecture": "Deep Machine Learning",
    "lecture_number": "576",
    "page": 26,
    "content_type": "figure",
    "doc_id": "slide_576_26_chunk2",
    "doc_type": "slide",
    "parent_doc_id": "slide_576_26",
    "chunk_index": 2,
    "total_chunks": 10,
    "is_definition": false,
    "contains_equation": true,
    "importance": "high",
    "tags": [
      "cnn",
      "neural networks"
    ]
  },
  {
    "text": "Results based on three neuronal populations are shown separately (black solid lines for ML/MF and AM are the same as the black solid lines for corresponding patches in Figure 2D, except here they are not shown with variability estimated by bootstrapping). In the left panel, boxes and error bars represent mean and SEM of subjective (human-based) decoding accuracy based on 78 human participants (see STAR Methods: Human psychophysics).",
    "source": "Deep Machine Learning - Slide 26",
    "source_detail": "ELEC576-Lec01.pdf, Page 26",
    "lecture": "Deep Machine Learning",
    "lecture_number": "576",
    "page": 26,
    "content_type": "figure",
    "doc_id": "slide_576_26_chunk3",
    "doc_type": "slide",
    "parent_doc_id": "slide_576_26",
    "chunk_index": 3,
    "total_chunks": 10,
    "is_definition": false,
    "contains_equation": false,
    "importance": "high",
    "tags": [
      "cnn",
      "neural networks"
    ]
  },
  {
    "text": "(C) Decoding accuracy for 40 faces plotted against different numbers of cells randomly drawn from three populations (black, all; blue, ML/MF; red, AM). Error bar represents SD. values explained by the linear model to quantify the decoding reconstruct the face that the monkey saw. Examples of the re- quality.",
    "source": "Deep Machine Learning - Slide 26",
    "source_detail": "ELEC576-Lec01.pdf, Page 26",
    "lecture": "Deep Machine Learning",
    "lecture_number": "576",
    "page": 26,
    "content_type": "figure",
    "doc_id": "slide_576_26_chunk4",
    "doc_type": "slide",
    "parent_doc_id": "slide_576_26",
    "chunk_index": 4,
    "total_chunks": 10,
    "is_definition": false,
    "contains_equation": true,
    "importance": "high",
    "tags": [
      "cnn",
      "neural networks"
    ]
  },
  {
    "text": "Overall, the decoding quality for appearance features constructed faces are shown in Figure 3A next to the actual was better than that for shape features for AM neurons, while faces, using ML/MF data, AM data, and combined data from the opposite was true for ML/MF neurons (Figures 2C and 2D), both patches. The reconstructions using AM data strongly consistent with our analysis using STA (Figure 1F).",
    "source": "Deep Machine Learning - Slide 26",
    "source_detail": "ELEC576-Lec01.pdf, Page 26",
    "lecture": "Deep Machine Learning",
    "lecture_number": "576",
    "page": 26,
    "content_type": "figure",
    "doc_id": "slide_576_26_chunk5",
    "doc_type": "slide",
    "parent_doc_id": "slide_576_26",
    "chunk_index": 5,
    "total_chunks": 10,
    "is_definition": false,
    "contains_equation": false,
    "importance": "high",
    "tags": [
      "cnn",
      "neural networks"
    ]
  },
  {
    "text": "By combining resemble the actual faces the monkey saw, and the resemblance the predicted feature values across all 50 dimensions, we could was further improved by adding ML/MF data. Cell 169, 1013\u20131028, June 1, 2017 1017 Figure S7. Convolutional Neural Net Trained for View-Invariant Identification Supports Axis Coding, Related to Figure 4 (A) Architecture of convolutional neural network. Two convolution/max pooling layers are followed by two fully connected layers.",
    "source": "Deep Machine Learning - Slide 26",
    "source_detail": "ELEC576-Lec01.pdf, Page 26",
    "lecture": "Deep Machine Learning",
    "lecture_number": "576",
    "page": 26,
    "content_type": "figure",
    "doc_id": "slide_576_26_chunk6",
    "doc_type": "slide",
    "parent_doc_id": "slide_576_26",
    "chunk_index": 6,
    "total_chunks": 10,
    "is_definition": false,
    "contains_equation": false,
    "importance": "high",
    "tags": [
      "cnn",
      "neural networks"
    ]
  },
  {
    "text": "Inputs were images of 500 identities, each at 9 views and 9 positions. The output compares the features of the 500 units in the final layer and determines the identity in the image. (B) After training, 2,000 parameterized facial images were loaded to the network, and the STA for each unit was computed. The distribution of feature preference indices for the final layer are shown alongside the distribution for AM and ML/MF.",
    "source": "Deep Machine Learning - Slide 26",
    "source_detail": "ELEC576-Lec01.pdf, Page 26",
    "lecture": "Deep Machine Learning",
    "lecture_number": "576",
    "page": 26,
    "content_type": "figure",
    "doc_id": "slide_576_26_chunk7",
    "doc_type": "slide",
    "parent_doc_id": "slide_576_26",
    "chunk_index": 7,
    "total_chunks": 10,
    "is_definition": false,
    "contains_equation": false,
    "importance": "high",
    "tags": [
      "cnn",
      "neural networks"
    ]
  },
  {
    "text": "(C) Same as Figure 4A, but for the final layer of the convolutional neural network. Sparseness and noise were matched to AM neurons. (D) The strength of nonlinearity, quantified by the ratio between surround and center of the Gaussian fit (c.f. Figure 4F), is plotted against sparseness for the final layer of the neural network and two other models (same as Figure 4). Box and error bar represent mean and s.e. for three sparseness levels.",
    "source": "Deep Machine Learning - Slide 26",
    "source_detail": "ELEC576-Lec01.pdf, Page 26",
    "lecture": "Deep Machine Learning",
    "lecture_number": "576",
    "page": 26,
    "content_type": "figure",
    "doc_id": "slide_576_26_chunk8",
    "doc_type": "slide",
    "parent_doc_id": "slide_576_26",
    "chunk_index": 8,
    "total_chunks": 10,
    "is_definition": false,
    "contains_equation": true,
    "importance": "high",
    "tags": [
      "cnn",
      "neural networks"
    ]
  },
  {
    "text": "(E) Same as (D) but for the absolute difference between the ratio and 1. (F) Responses of units in the final layer were fitted either by an \u2018\u2018axis\u2019\u2019 model or an \u2018\u2018exemplar\u2019\u2019 model (Figure 4G). Percentage explained variance by each model are plotted against each other. The axis model explained a high percentage of variance of unit responses (mean = 80.0%), significantly higher than the exemplar model (mean = 67.5%, p < 0.001, Student\u2019s t test).",
    "source": "Deep Machine Learning - Slide 26",
    "source_detail": "ELEC576-Lec01.pdf, Page 26",
    "lecture": "Deep Machine Learning",
    "lecture_number": "576",
    "page": 26,
    "content_type": "figure",
    "doc_id": "slide_576_26_chunk9",
    "doc_type": "slide",
    "parent_doc_id": "slide_576_26",
    "chunk_index": 9,
    "total_chunks": 10,
    "is_definition": false,
    "contains_equation": true,
    "importance": "high",
    "tags": [
      "cnn",
      "neural networks"
    ]
  },
  {
    "text": "This is surprising since we did not give any information to the network about face space axes; one might have expected each output unit to show spherical tuning around each of the 500 target faces, given that the job of each output unit was to identify one of the 500 target faces..",
    "source": "Deep Machine Learning - Slide 26",
    "source_detail": "ELEC576-Lec01.pdf, Page 26",
    "lecture": "Deep Machine Learning",
    "lecture_number": "576",
    "page": 26,
    "content_type": "figure",
    "doc_id": "slide_576_26_chunk10",
    "doc_type": "slide",
    "parent_doc_id": "slide_576_26",
    "chunk_index": 10,
    "total_chunks": 10,
    "is_definition": false,
    "contains_equation": false,
    "importance": "medium",
    "tags": [
      "cnn",
      "neural networks"
    ]
  },
  {
    "text": "Formal Language Representations in trained NNs https://pair-code.github.io/interpretability/bert-tree/ Studying the hidden state space of trained NNs can lead to insights about how NNs solve tasks. Michalenko et al. ICLR 2019",
    "source": "Deep Machine Learning - Slide 27",
    "source_detail": "ELEC576-Lec01.pdf, Page 27",
    "lecture": "Deep Machine Learning",
    "lecture_number": "576",
    "page": 27,
    "content_type": "text",
    "doc_id": "slide_576_27",
    "doc_type": "slide",
    "is_definition": false,
    "contains_equation": false,
    "importance": "high",
    "tags": [
      "neural networks"
    ]
  },
  {
    "text": "Natural Language Representations in trained NNs https://pair-code.github.io/interpretability/bert-tree/ Studying the hidden state space of SotA trained NNs can lead to insights about how NNs solve tasks. We will discuss later in the course about how BERT Seems to represent parse trees via Pythagorean embeddings.",
    "source": "Deep Machine Learning - Slide 28",
    "source_detail": "ELEC576-Lec01.pdf, Page 28",
    "lecture": "Deep Machine Learning",
    "lecture_number": "576",
    "page": 28,
    "content_type": "text",
    "doc_id": "slide_576_28",
    "doc_type": "slide",
    "is_definition": false,
    "contains_equation": true,
    "importance": "high",
    "tags": [
      "neural networks"
    ]
  },
  {
    "text": "Cracking open the Blackbox: Probing,Visualizing & Theorizing about Neural Networks",
    "source": "Deep Machine Learning - Slide 29",
    "source_detail": "ELEC576-Lec01.pdf, Page 29",
    "lecture": "Deep Machine Learning",
    "lecture_number": "576",
    "page": 29,
    "content_type": "text",
    "doc_id": "slide_576_29",
    "doc_type": "slide",
    "is_definition": false,
    "contains_equation": false,
    "importance": "high",
    "tags": [
      "neural networks"
    ]
  },
  {
    "text": "Implicit Reg.: Impact of Width for Two Lines Width = 20 units Width = 40 units Width = 200 units Ryan Pyle, Justin Sahs, Aneel Damarajju, Ankit Patel",
    "source": "Deep Machine Learning - Slide 30",
    "source_detail": "ELEC576-Lec01.pdf, Page 30",
    "lecture": "Deep Machine Learning",
    "lecture_number": "576",
    "page": 30,
    "content_type": "text",
    "doc_id": "slide_576_30",
    "doc_type": "slide",
    "is_definition": false,
    "contains_equation": false,
    "importance": "medium",
    "tags": [
      "Width Measurements",
      "Ryan Pyle",
      "Two Lines",
      "Impact of Width",
      "Implicit Registration"
    ]
  },
  {
    "text": "Implicit Reg.: Impact of Width for Smooth Target Ryan Pyle, Justin Sahs, Aneel Damarajju, Ankit Patel",
    "source": "Deep Machine Learning - Slide 31",
    "source_detail": "ELEC576-Lec01.pdf, Page 31",
    "lecture": "Deep Machine Learning",
    "lecture_number": "576",
    "page": 31,
    "content_type": "text",
    "doc_id": "slide_576_31",
    "doc_type": "slide",
    "is_definition": false,
    "contains_equation": true,
    "importance": "high",
    "tags": [
      "Justin Sahs",
      "Ryan Pyle",
      "Impact of Width",
      "Smooth Target",
      "Implicit Regulation"
    ]
  },
  {
    "text": "Implicit Reg.: Impact of Width for Sharp Target Ryan Pyle, Justin Sahs, Aneel Damarajju, Ankit Patel",
    "source": "Deep Machine Learning - Slide 32",
    "source_detail": "ELEC576-Lec01.pdf, Page 32",
    "lecture": "Deep Machine Learning",
    "lecture_number": "576",
    "page": 32,
    "content_type": "text",
    "doc_id": "slide_576_32",
    "doc_type": "slide",
    "is_definition": false,
    "contains_equation": true,
    "importance": "high",
    "tags": [
      "Implicit Regularization",
      "Justin Sahs",
      "Ryan Pyle",
      "Impact of Width",
      "Sharp Target"
    ]
  },
  {
    "text": "A Theoretical Explanation for Implicit Reg. in Kernel Regime: 3. Compare Predicted Spline to Trained NN Ryan Pyle, Justin Sahs, Aneel Damarajju, Ankit Patel",
    "source": "Deep Machine Learning - Slide 33",
    "source_detail": "ELEC576-Lec01.pdf, Page 33",
    "lecture": "Deep Machine Learning",
    "lecture_number": "576",
    "page": 33,
    "content_type": "text",
    "doc_id": "slide_576_33",
    "doc_type": "slide",
    "is_definition": false,
    "contains_equation": true,
    "importance": "high",
    "tags": [
      "neural networks"
    ]
  },
  {
    "text": "Learning Dynamics in GANs: Combining MiniMax + Preconditioning together \u2014> Adaptive Regularization \u2014> Discontinuities approximated more sharply and quickly \u2014> greatly improved mode coverage very early on. Yilong Ju, Weili Nie, Ankit Patel",
    "source": "Deep Machine Learning - Slide 34",
    "source_detail": "ELEC576-Lec01.pdf, Page 34",
    "lecture": "Deep Machine Learning",
    "lecture_number": "576",
    "page": 34,
    "content_type": "text",
    "doc_id": "slide_576_34",
    "doc_type": "slide",
    "is_definition": false,
    "contains_equation": true,
    "importance": "high",
    "tags": [
      "regularization",
      "generative models"
    ]
  },
  {
    "text": "Visualizing GoogLeNet Beautiful work from Chris Olah and Circuits team at OpenAI: \u2022 https://distill.pub/2020/circuits/early-vision/ \u2022",
    "source": "Deep Machine Learning - Slide 35",
    "source_detail": "ELEC576-Lec01.pdf, Page 35",
    "lecture": "Deep Machine Learning",
    "lecture_number": "576",
    "page": 35,
    "content_type": "text",
    "doc_id": "slide_576_35",
    "doc_type": "slide",
    "is_definition": false,
    "contains_equation": false,
    "importance": "medium",
    "tags": [
      "OpenAI",
      "Chris Olah",
      "GoogLeNet",
      "visualization",
      "early vision"
    ]
  },
  {
    "text": "The Mission Observations about Deep Learning (DL) \u2022 1. It works. (Kind of. Finally.) 2. It has an enormous number of potential applications in a wide variety of fields, many of which are just beginning to see DL\u2019s influence. 3. There is a steep learning curve at the beginning. 4. You are young and agile. If you invest now, you will reap the benefits. Main Goal of this Course: To jumpstart your ability to use Deep Learning in your \u2022 research. And to provide you a glimpse of whats going on inside the Blackbox\u2026",
    "source": "Deep Machine Learning - Slide 37",
    "source_detail": "ELEC576-Lec01.pdf, Page 37",
    "lecture": "Deep Machine Learning",
    "lecture_number": "576",
    "page": 37,
    "content_type": "text",
    "doc_id": "slide_576_37",
    "doc_type": "slide",
    "is_definition": false,
    "contains_equation": false,
    "importance": "high",
    "tags": [
      "neural networks"
    ]
  },
  {
    "text": "The Mission Main Goal of this Course: To jumpstart your ability to use Deep \u2022 Learning in your research. Designed for students who want to start using DL in their research \u2022 Myriad applications of DL in many many fields \u2022 Less Theory, More Doing: This is not a math class (though we will \u2022 cover some exciting aspects of DL theory near the end and some potentially large implications)",
    "source": "Deep Machine Learning - Slide 38",
    "source_detail": "ELEC576-Lec01.pdf, Page 38",
    "lecture": "Deep Machine Learning",
    "lecture_number": "576",
    "page": 38,
    "content_type": "text",
    "doc_id": "slide_576_38",
    "doc_type": "slide",
    "is_definition": false,
    "contains_equation": false,
    "importance": "high",
    "tags": [
      "course objectives",
      "theory in DL",
      "Deep Learning",
      "research applications",
      "practical learning"
    ]
  },
  {
    "text": "Course Information Course Website: elec576.rice.edu + Piazza (Discussion Forum) \u2022",
    "source": "Deep Machine Learning - Slide 39",
    "source_detail": "ELEC576-Lec01.pdf, Page 39",
    "lecture": "Deep Machine Learning",
    "lecture_number": "576",
    "page": 39,
    "content_type": "text",
    "doc_id": "slide_576_39",
    "doc_type": "slide",
    "is_definition": false,
    "contains_equation": false,
    "importance": "low",
    "tags": [
      "Discussion Forum",
      "Course Information",
      "Piazza",
      "Course Website"
    ]
  },
  {
    "text": "A Brief History of Neural Networks",
    "source": "Deep Machine Learning - Slide 2",
    "source_detail": "ELEC576-Lec02.pdf, Page 2",
    "lecture": "Deep Machine Learning",
    "lecture_number": "576",
    "page": 2,
    "content_type": "text",
    "doc_id": "slide_576_2",
    "doc_type": "slide",
    "is_definition": false,
    "contains_equation": false,
    "importance": "high",
    "tags": [
      "neural networks"
    ]
  },
  {
    "text": "How do neurons communicate? Animations of excitatory and inhibitory neuron: \u2022 https://nba.uth.tmc.edu/neuroscience/s1/introduction.html \u2022",
    "source": "Deep Machine Learning - Slide 5",
    "source_detail": "ELEC576-Lec02.pdf, Page 5",
    "lecture": "Deep Machine Learning",
    "lecture_number": "576",
    "page": 5,
    "content_type": "text",
    "doc_id": "slide_576_5",
    "doc_type": "slide",
    "is_definition": false,
    "contains_equation": false,
    "importance": "medium",
    "tags": [
      "neurons",
      "excitatory",
      "animations",
      "communication",
      "inhibitory"
    ]
  },
  {
    "text": "McCulloch-Pitts Neurons (1943) Bulletin of Mathematical Biophysics 5:115-133 (1943)",
    "source": "Deep Machine Learning - Slide 6",
    "source_detail": "ELEC576-Lec02.pdf, Page 6",
    "lecture": "Deep Machine Learning",
    "lecture_number": "576",
    "page": 6,
    "content_type": "text",
    "doc_id": "slide_576_6",
    "doc_type": "slide",
    "is_definition": true,
    "contains_equation": true,
    "importance": "high",
    "tags": [
      "McCulloch-Pitts Neurons",
      "Bulletin of Mathematical Biophysics",
      "biophysics",
      "1943",
      "neural networks"
    ]
  },
  {
    "text": "Assumptions (drawn from Empirical Observations)",
    "source": "Deep Machine Learning - Slide 7",
    "source_detail": "ELEC576-Lec02.pdf, Page 7",
    "lecture": "Deep Machine Learning",
    "lecture_number": "576",
    "page": 7,
    "content_type": "text",
    "doc_id": "slide_576_7",
    "doc_type": "slide",
    "is_definition": false,
    "contains_equation": false,
    "importance": "medium",
    "tags": [
      "Empirical Observations",
      "Educational Text",
      "Assumptions"
    ]
  },
  {
    "text": "McCulloch-Pitts Neurons",
    "source": "Deep Machine Learning - Slide 8",
    "source_detail": "ELEC576-Lec02.pdf, Page 8",
    "lecture": "Deep Machine Learning",
    "lecture_number": "576",
    "page": 8,
    "content_type": "text",
    "doc_id": "slide_576_8",
    "doc_type": "slide",
    "is_definition": true,
    "contains_equation": false,
    "importance": "high",
    "tags": [
      "computational models",
      "McCulloch-Pitts Neurons",
      "artificial intelligence",
      "neural networks"
    ]
  },
  {
    "text": "McCulloch-Pitts Nets",
    "source": "Deep Machine Learning - Slide 9",
    "source_detail": "ELEC576-Lec02.pdf, Page 9",
    "lecture": "Deep Machine Learning",
    "lecture_number": "576",
    "page": 9,
    "content_type": "text",
    "doc_id": "slide_576_9",
    "doc_type": "slide",
    "is_definition": true,
    "contains_equation": false,
    "importance": "high",
    "tags": [
      "Computational Models",
      "Neural Networks",
      "McCulloch-Pitts",
      "Nets"
    ]
  },
  {
    "text": "Expressive Power of McCulloch-Pitts Nets",
    "source": "Deep Machine Learning - Slide 10",
    "source_detail": "ELEC576-Lec02.pdf, Page 10",
    "lecture": "Deep Machine Learning",
    "lecture_number": "576",
    "page": 10,
    "content_type": "text",
    "doc_id": "slide_576_10",
    "doc_type": "slide",
    "is_definition": false,
    "contains_equation": false,
    "importance": "high",
    "tags": [
      "Expressive Power",
      "Neural Networks",
      "McCulloch-Pitts Nets"
    ]
  },
  {
    "text": "Why is it important?",
    "source": "Deep Machine Learning - Slide 11",
    "source_detail": "ELEC576-Lec02.pdf, Page 11",
    "lecture": "Deep Machine Learning",
    "lecture_number": "576",
    "page": 11,
    "content_type": "text",
    "doc_id": "slide_576_11",
    "doc_type": "slide",
    "is_definition": false,
    "contains_equation": false,
    "importance": "low",
    "tags": [
      "education",
      "importance",
      "significance"
    ]
  },
  {
    "text": "Aside: The Tragic Story of Walter Pitts Must read: http://nautil.us/issue/21/information/the-man- \u2022 who-tried-to-redeem-the-world-with-logic The downfall of universal expressive power: it does not \u2022 provide any constraint on the microscopic mechanisms by which a NN computes.",
    "source": "Deep Machine Learning - Slide 12",
    "source_detail": "ELEC576-Lec02.pdf, Page 12",
    "lecture": "Deep Machine Learning",
    "lecture_number": "576",
    "page": 12,
    "content_type": "text",
    "doc_id": "slide_576_12",
    "doc_type": "slide",
    "is_definition": false,
    "contains_equation": false,
    "importance": "medium",
    "tags": [
      "neural networks"
    ]
  },
  {
    "text": "Question: What are the problems/limitations of expressive power? (1-2 min)",
    "source": "Deep Machine Learning - Slide 13",
    "source_detail": "ELEC576-Lec02.pdf, Page 13",
    "lecture": "Deep Machine Learning",
    "lecture_number": "576",
    "page": 13,
    "content_type": "text",
    "doc_id": "slide_576_13",
    "doc_type": "slide",
    "is_definition": false,
    "contains_equation": false,
    "importance": "medium",
    "tags": [
      "limitations",
      "problems",
      "expressive power"
    ]
  },
  {
    "text": "Question: What are the problems/limitations of expressive power? (1-2 min) Answer: Expressability does not imply Learnability",
    "source": "Deep Machine Learning - Slide 14",
    "source_detail": "ELEC576-Lec02.pdf, Page 14",
    "lecture": "Deep Machine Learning",
    "lecture_number": "576",
    "page": 14,
    "content_type": "text",
    "doc_id": "slide_576_14",
    "doc_type": "slide",
    "is_definition": false,
    "contains_equation": false,
    "importance": "high",
    "tags": [
      "limitations",
      "learnability",
      "expressability",
      "expressive power",
      "problems"
    ]
  },
  {
    "text": "Expressability vs. Learnability Can easily express function But difficult to learn/optimize (not enough breakpoints nearby and not able to move them)",
    "source": "Deep Machine Learning - Slide 15",
    "source_detail": "ELEC576-Lec02.pdf, Page 15",
    "lecture": "Deep Machine Learning",
    "lecture_number": "576",
    "page": 15,
    "content_type": "text",
    "doc_id": "slide_576_15",
    "doc_type": "slide",
    "is_definition": false,
    "contains_equation": false,
    "importance": "medium",
    "tags": [
      "Breakpoints",
      "Expressability",
      "Function Optimization",
      "Learnability"
    ]
  },
  {
    "text": "How can Neurons learn? Hebb\u2019s Postulate",
    "source": "Deep Machine Learning - Slide 16",
    "source_detail": "ELEC576-Lec02.pdf, Page 16",
    "lecture": "Deep Machine Learning",
    "lecture_number": "576",
    "page": 16,
    "content_type": "text",
    "doc_id": "slide_576_16",
    "doc_type": "slide",
    "is_definition": true,
    "contains_equation": false,
    "importance": "high",
    "tags": [
      "Hebb's Postulate",
      "Neurons",
      "Learning",
      "Neurobiology"
    ]
  },
  {
    "text": "How do neurons process visual input? Hubel and Wiesel\u2019s incredible discovery (1962): \u2022 https://www.youtube.com/watch?v=IOHayh06LJ4 \u2022 Awarded Nobel Prize in Physiology and Medicine \u2022",
    "source": "Deep Machine Learning - Slide 17",
    "source_detail": "ELEC576-Lec02.pdf, Page 17",
    "lecture": "Deep Machine Learning",
    "lecture_number": "576",
    "page": 17,
    "content_type": "text",
    "doc_id": "slide_576_17",
    "doc_type": "slide",
    "is_definition": false,
    "contains_equation": false,
    "importance": "high",
    "tags": [
      "neurons",
      "Nobel Prize",
      "Physiology and Medicine",
      "Hubel and Wiesel",
      "visual input"
    ]
  },
  {
    "text": "The Perceptron (Rosenblatt 1957) First architecture to \u2022 have a learning algorithm:",
    "source": "Deep Machine Learning - Slide 18",
    "source_detail": "ELEC576-Lec02.pdf, Page 18",
    "lecture": "Deep Machine Learning",
    "lecture_number": "576",
    "page": 18,
    "content_type": "text",
    "doc_id": "slide_576_18",
    "doc_type": "slide",
    "is_definition": true,
    "contains_equation": false,
    "importance": "high",
    "tags": [
      "neural networks"
    ]
  },
  {
    "text": "Minsky & Papert Deal a \u201cDeathblow\u201d to the Perceptron: The XOR Problem Linear Separable or Not?",
    "source": "Deep Machine Learning - Slide 19",
    "source_detail": "ELEC576-Lec02.pdf, Page 19",
    "lecture": "Deep Machine Learning",
    "lecture_number": "576",
    "page": 19,
    "content_type": "text",
    "doc_id": "slide_576_19",
    "doc_type": "slide",
    "is_definition": false,
    "contains_equation": true,
    "importance": "high",
    "tags": [
      "neural networks"
    ]
  },
  {
    "text": "Question: How can you prove that the XOR Problem is not linearly separable? (4 min)",
    "source": "Deep Machine Learning - Slide 20",
    "source_detail": "ELEC576-Lec02.pdf, Page 20",
    "lecture": "Deep Machine Learning",
    "lecture_number": "576",
    "page": 20,
    "content_type": "text",
    "doc_id": "slide_576_20",
    "doc_type": "slide",
    "is_definition": false,
    "contains_equation": true,
    "importance": "high",
    "tags": [
      "proof",
      "linearly separable",
      "machine learning",
      "XOR Problem"
    ]
  },
  {
    "text": "Answer: Proof by Contradiction",
    "source": "Deep Machine Learning - Slide 21",
    "source_detail": "ELEC576-Lec02.pdf, Page 21",
    "lecture": "Deep Machine Learning",
    "lecture_number": "576",
    "page": 21,
    "content_type": "text",
    "doc_id": "slide_576_21",
    "doc_type": "slide",
    "is_definition": true,
    "contains_equation": false,
    "importance": "high",
    "tags": [
      "Logic",
      "Proof by Contradiction",
      "Mathematical Proof",
      "Argumentation"
    ]
  },
  {
    "text": "Final Project Idea: MicroNetwork Motifs https://nba.uth.tmc.edu/neuroscience/s1/introduction.html \u2022",
    "source": "Deep Machine Learning - Slide 22",
    "source_detail": "ELEC576-Lec02.pdf, Page 22",
    "lecture": "Deep Machine Learning",
    "lecture_number": "576",
    "page": 22,
    "content_type": "text",
    "doc_id": "slide_576_22",
    "doc_type": "slide",
    "is_definition": false,
    "contains_equation": false,
    "importance": "medium",
    "tags": [
      "Neuroscience",
      "Final Project",
      "Motifs",
      "MicroNetwork"
    ]
  },
  {
    "text": "Neocognitron: Precursor to Modern Convnets",
    "source": "Deep Machine Learning - Slide 24",
    "source_detail": "ELEC576-Lec02.pdf, Page 24",
    "lecture": "Deep Machine Learning",
    "lecture_number": "576",
    "page": 24,
    "content_type": "text",
    "doc_id": "slide_576_24",
    "doc_type": "slide",
    "is_definition": true,
    "contains_equation": false,
    "importance": "high",
    "tags": [
      "cnn"
    ]
  },
  {
    "text": "Neuron How to Disentangle Nuisance Variation? Perspective Key Idea: Alternating Selectivity and Invariance Potential Solution: Look to the Brain for guidance. Figure 6.",
    "source": "Deep Machine Learning - Slide 25",
    "source_detail": "ELEC576-Lec02.pdf, Page 25",
    "lecture": "Deep Machine Learning",
    "lecture_number": "576",
    "page": 25,
    "content_type": "figure",
    "doc_id": "slide_576_25_chunk1",
    "doc_type": "slide",
    "parent_doc_id": "slide_576_25",
    "chunk_index": 1,
    "total_chunks": 14,
    "is_definition": false,
    "contains_equation": false,
    "importance": "high",
    "tags": [
      "cnn",
      "neural networks"
    ]
  },
  {
    "text": "Serial-Chain Discriminative Models of Object Recognition A class of biologically inspired models of object Hubel and Wiesel\u2019s discovery of simple/complex cells and their special properties of I recognition aims to achieve a gradual untangling of object manifolds by stacking layers of neuronal selectivity and tolerance/invariance units in a largely feedforward hierarchy.",
    "source": "Deep Machine Learning - Slide 25",
    "source_detail": "ELEC576-Lec02.pdf, Page 25",
    "lecture": "Deep Machine Learning",
    "lecture_number": "576",
    "page": 25,
    "content_type": "figure",
    "doc_id": "slide_576_25_chunk2",
    "doc_type": "slide",
    "parent_doc_id": "slide_576_25",
    "chunk_index": 2,
    "total_chunks": 14,
    "is_definition": true,
    "contains_equation": false,
    "importance": "high",
    "tags": [
      "cnn",
      "neural networks"
    ]
  },
  {
    "text": "In this example, units in each layer process their inputs using either AND-like (see red units) and OR-like (e.g.,\u2018\u2018MAX,\u2019\u2019seeblueunits)operations,andthose operations are applied in parallel in alternating layers.",
    "source": "Deep Machine Learning - Slide 25",
    "source_detail": "ELEC576-Lec02.pdf, Page 25",
    "lecture": "Deep Machine Learning",
    "lecture_number": "576",
    "page": 25,
    "content_type": "figure",
    "doc_id": "slide_576_25_chunk3",
    "doc_type": "slide",
    "parent_doc_id": "slide_576_25",
    "chunk_index": 3,
    "total_chunks": 14,
    "is_definition": false,
    "contains_equation": false,
    "importance": "medium",
    "tags": [
      "cnn",
      "neural networks"
    ]
  },
  {
    "text": "The AND-like operation constructs some tuning for combinations of visual features (e.g., simple cells in V1), and the OR-like operation constructs some tolerance to changes in, e.g., position and size by pooling over AND-like units with identical feature tuning, but having receptive fields with slightly different retinal locations and sizes.",
    "source": "Deep Machine Learning - Slide 25",
    "source_detail": "ELEC576-Lec02.pdf, Page 25",
    "lecture": "Deep Machine Learning",
    "lecture_number": "576",
    "page": 25,
    "content_type": "figure",
    "doc_id": "slide_576_25_chunk4",
    "doc_type": "slide",
    "parent_doc_id": "slide_576_25",
    "chunk_index": 4,
    "total_chunks": 14,
    "is_definition": false,
    "contains_equation": false,
    "importance": "high",
    "tags": [
      "cnn",
      "neural networks"
    ]
  },
  {
    "text": "This can produce a gradual increase of the tolerance to variation in object appearance along the hierarchy (e.g., Fukushima,1980;Riesenhuber and Poggio, 1999b; Serre et al., 2007a). AND-like operations and OR-like operations can each be formulated(KouhandPoggio,2008)asavariantof a standard LN neuronal model with nonlinear gain control mechanisms (e.g., a type of NLN model, see dashed frame). model which has the same capability for DiCarlo, J. J. et al.",
    "source": "Deep Machine Learning - Slide 25",
    "source_detail": "ELEC576-Lec02.pdf, Page 25",
    "lecture": "Deep Machine Learning",
    "lecture_number": "576",
    "page": 25,
    "content_type": "figure",
    "doc_id": "slide_576_25_chunk5",
    "doc_type": "slide",
    "parent_doc_id": "slide_576_25",
    "chunk_index": 5,
    "total_chunks": 14,
    "is_definition": false,
    "contains_equation": true,
    "importance": "high",
    "tags": [
      "cnn",
      "neural networks"
    ]
  },
  {
    "text": "How does the brain solve visual object recognition? Neuropnatte(r2n0re1c2o)g.nition as a human being, it would give us a powerful clue to the understanding of the neural mechanism Key Inspiration from Neuroscience in the brain\u2019\u2019 (Fukushima, 1980).",
    "source": "Deep Machine Learning - Slide 25",
    "source_detail": "ELEC576-Lec02.pdf, Page 25",
    "lecture": "Deep Machine Learning",
    "lecture_number": "576",
    "page": 25,
    "content_type": "figure",
    "doc_id": "slide_576_25_chunk6",
    "doc_type": "slide",
    "parent_doc_id": "slide_576_25",
    "chunk_index": 6,
    "total_chunks": 14,
    "is_definition": false,
    "contains_equation": true,
    "importance": "high",
    "tags": [
      "cnn",
      "neural networks"
    ]
  },
  {
    "text": "More recent modeling efforts have significantly refined and extended this approach (e.g., Build up feature selectivity and tolerance over multiple layersLeciunn etaal.,h20ie04r; aMerl,c1h99y7; Riesen- huber and Poggio, 1999b; Serre)et al., ML architectures: Neocognitron, HMAX, SIFT, and modern200 D 7a).",
    "source": "Deep Machine Learning - Slide 25",
    "source_detail": "ELEC576-Lec02.pdf, Page 25",
    "lecture": "Deep Machine Learning",
    "lecture_number": "576",
    "page": 25,
    "content_type": "figure",
    "doc_id": "slide_576_25_chunk7",
    "doc_type": "slide",
    "parent_doc_id": "slide_576_25",
    "chunk_index": 7,
    "total_chunks": 14,
    "is_definition": false,
    "contains_equation": true,
    "importance": "high",
    "tags": [
      "cnn",
      "neural networks"
    ]
  },
  {
    "text": "e W e hil p e we C ca o nn n ot v re n view et all s the computer vision or neural network models that have relevance to object recognition in primates here, we refer 6 Testing Hypotheses: Instantiated Models of the Ventral the reader to reviews by Bengio (2009), Edelman (1999), Riesen- Stream huber and Poggio (2000), and Zhu and Mumford (2006).",
    "source": "Deep Machine Learning - Slide 25",
    "source_detail": "ELEC576-Lec02.pdf, Page 25",
    "lecture": "Deep Machine Learning",
    "lecture_number": "576",
    "page": 25,
    "content_type": "figure",
    "doc_id": "slide_576_25_chunk8",
    "doc_type": "slide",
    "parent_doc_id": "slide_576_25",
    "chunk_index": 8,
    "total_chunks": 14,
    "is_definition": false,
    "contains_equation": false,
    "importance": "high",
    "tags": [
      "cnn",
      "neural networks"
    ]
  },
  {
    "text": "Experimental approaches are effective at describing undocu- Commensurate with the serial chain, cascaded untangling mented behaviors of ventral stream neurons, but alone they discussion above, some ventral-stream-inspired models imple- cannot indicate when that search is complete. Similarly, \u2018\u2018word ment a canonical, iterated computation, with the overall goal of models\u2019\u2019 (including ours, above) are not falsifiable algorithms.",
    "source": "Deep Machine Learning - Slide 25",
    "source_detail": "ELEC576-Lec02.pdf, Page 25",
    "lecture": "Deep Machine Learning",
    "lecture_number": "576",
    "page": 25,
    "content_type": "figure",
    "doc_id": "slide_576_25_chunk9",
    "doc_type": "slide",
    "parent_doc_id": "slide_576_25",
    "chunk_index": 9,
    "total_chunks": 14,
    "is_definition": false,
    "contains_equation": false,
    "importance": "high",
    "tags": [
      "cnn",
      "neural networks"
    ]
  },
  {
    "text": "producing a good object representation at their highest stage To make progress, we need to construct ventral-stream- (Fukushima, 1980; Riesenhuber and Poggio, 1999b; Serre inspired, instantiated computational models and compare their et al., 2007a). These models include a handful of hierarchically performance with neuronal data and human performance on arranged layers, each implementing AND-like operations to build object recognition tasks.",
    "source": "Deep Machine Learning - Slide 25",
    "source_detail": "ELEC576-Lec02.pdf, Page 25",
    "lecture": "Deep Machine Learning",
    "lecture_number": "576",
    "page": 25,
    "content_type": "figure",
    "doc_id": "slide_576_25_chunk10",
    "doc_type": "slide",
    "parent_doc_id": "slide_576_25",
    "chunk_index": 10,
    "total_chunks": 14,
    "is_definition": false,
    "contains_equation": false,
    "importance": "high",
    "tags": [
      "cnn",
      "neural networks"
    ]
  },
  {
    "text": "Thus, computational modeling cannot selectivity followed by OR-like operations to build tolerance to be taken lightly. Together, the set of alternative models define identity preserving transformations (Figure 6).",
    "source": "Deep Machine Learning - Slide 25",
    "source_detail": "ELEC576-Lec02.pdf, Page 25",
    "lecture": "Deep Machine Learning",
    "lecture_number": "576",
    "page": 25,
    "content_type": "figure",
    "doc_id": "slide_576_25_chunk11",
    "doc_type": "slide",
    "parent_doc_id": "slide_576_25",
    "chunk_index": 11,
    "total_chunks": 14,
    "is_definition": true,
    "contains_equation": false,
    "importance": "high",
    "tags": [
      "cnn",
      "neural networks"
    ]
  },
  {
    "text": "Notably, both the space of falsifiable alternative hypotheses in the field, and AND-like and OR-like computations can be formulated as vari- the success of some such algorithms will be among our first indi- ants of the NLN model class described above (Kouh and Poggio, cations that we are on the path to understanding visual object 2008), illustrating the link to canonical cortical models (see inset recognition in the brain. in Figure 6).",
    "source": "Deep Machine Learning - Slide 25",
    "source_detail": "ELEC576-Lec02.pdf, Page 25",
    "lecture": "Deep Machine Learning",
    "lecture_number": "576",
    "page": 25,
    "content_type": "figure",
    "doc_id": "slide_576_25_chunk12",
    "doc_type": "slide",
    "parent_doc_id": "slide_576_25",
    "chunk_index": 12,
    "total_chunks": 14,
    "is_definition": false,
    "contains_equation": true,
    "importance": "high",
    "tags": [
      "cnn",
      "neural networks"
    ]
  },
  {
    "text": "Moreover, these relatively simple hierarchical The idea of using biologically inspired, hierarchical computa- models can produce model neurons that signal object identity, tional algorithms tounderstand the neuronal mechanisms under- are somewhat tolerant to identity-preserving transformations, lying invariant object recognition tasks is not new: \u2018\u2018The mecha- and can rival human performance for ultrashort, backward- nism of pattern recognition in the brain is little known, and it masked image presentations (Serre et al., 2007a).",
    "source": "Deep Machine Learning - Slide 25",
    "source_detail": "ELEC576-Lec02.pdf, Page 25",
    "lecture": "Deep Machine Learning",
    "lecture_number": "576",
    "page": 25,
    "content_type": "figure",
    "doc_id": "slide_576_25_chunk13",
    "doc_type": "slide",
    "parent_doc_id": "slide_576_25",
    "chunk_index": 13,
    "total_chunks": 14,
    "is_definition": false,
    "contains_equation": false,
    "importance": "high",
    "tags": [
      "cnn",
      "neural networks"
    ]
  },
  {
    "text": "seems to be almost impossible to reveal it only by conventional The surprising power of such models substantially demystifies physiological experiments.. If we could make a neural network the problem of invariant object recognition, but also points out Neuron 73, February 9, 2012 \u00aa2012 Elsevier Inc. 427.",
    "source": "Deep Machine Learning - Slide 25",
    "source_detail": "ELEC576-Lec02.pdf, Page 25",
    "lecture": "Deep Machine Learning",
    "lecture_number": "576",
    "page": 25,
    "content_type": "figure",
    "doc_id": "slide_576_25_chunk14",
    "doc_type": "slide",
    "parent_doc_id": "slide_576_25",
    "chunk_index": 14,
    "total_chunks": 14,
    "is_definition": false,
    "contains_equation": false,
    "importance": "medium",
    "tags": [
      "cnn",
      "neural networks"
    ]
  },
  {
    "text": "Recurrent Neural Networks: Hopfield Nets",
    "source": "Deep Machine Learning - Slide 26",
    "source_detail": "ELEC576-Lec02.pdf, Page 26",
    "lecture": "Deep Machine Learning",
    "lecture_number": "576",
    "page": 26,
    "content_type": "text",
    "doc_id": "slide_576_26",
    "doc_type": "slide",
    "is_definition": true,
    "contains_equation": false,
    "importance": "high",
    "tags": [
      "rnn",
      "neural networks"
    ]
  },
  {
    "text": "Hopfield Nets: Mathematical Definition",
    "source": "Deep Machine Learning - Slide 27",
    "source_detail": "ELEC576-Lec02.pdf, Page 27",
    "lecture": "Deep Machine Learning",
    "lecture_number": "576",
    "page": 27,
    "content_type": "text",
    "doc_id": "slide_576_27",
    "doc_type": "slide",
    "is_definition": true,
    "contains_equation": true,
    "importance": "high",
    "tags": [
      "Mathematical Definition",
      "Computational Models",
      "Neural Networks",
      "Hopfield Nets"
    ]
  },
  {
    "text": "Hopfield Nets: Engineering the Attractor",
    "source": "Deep Machine Learning - Slide 28",
    "source_detail": "ELEC576-Lec02.pdf, Page 28",
    "lecture": "Deep Machine Learning",
    "lecture_number": "576",
    "page": 28,
    "content_type": "text",
    "doc_id": "slide_576_28",
    "doc_type": "slide",
    "is_definition": false,
    "contains_equation": false,
    "importance": "high",
    "tags": [
      "Attractor",
      "Computational Models",
      "Hopfield Nets",
      "Neural Networks",
      "Engineering"
    ]
  },
  {
    "text": "Hopfield Nets as Associative Memory",
    "source": "Deep Machine Learning - Slide 29",
    "source_detail": "ELEC576-Lec02.pdf, Page 29",
    "lecture": "Deep Machine Learning",
    "lecture_number": "576",
    "page": 29,
    "content_type": "text",
    "doc_id": "slide_576_29",
    "doc_type": "slide",
    "is_definition": true,
    "contains_equation": false,
    "importance": "high",
    "tags": [
      "Neural Networks",
      "Associative Memory",
      "Hopfield Nets"
    ]
  },
  {
    "text": "How to Learn NNs? The Backpropagation Algorithm (1960-86) Net Input Activation + Nonlinearity",
    "source": "Deep Machine Learning - Slide 30",
    "source_detail": "ELEC576-Lec02.pdf, Page 30",
    "lecture": "Deep Machine Learning",
    "lecture_number": "576",
    "page": 30,
    "content_type": "text",
    "doc_id": "slide_576_30",
    "doc_type": "slide",
    "is_definition": false,
    "contains_equation": true,
    "importance": "high",
    "tags": [
      "backpropagation",
      "neural networks"
    ]
  },
  {
    "text": "How to Learn NNs? The Backpropagation Algorithm (1960-86)",
    "source": "Deep Machine Learning - Slide 31",
    "source_detail": "ELEC576-Lec02.pdf, Page 31",
    "lecture": "Deep Machine Learning",
    "lecture_number": "576",
    "page": 31,
    "content_type": "text",
    "doc_id": "slide_576_31",
    "doc_type": "slide",
    "is_definition": false,
    "contains_equation": true,
    "importance": "high",
    "tags": [
      "backpropagation",
      "neural networks"
    ]
  },
  {
    "text": "The History of the Backpropagation Algorithm (1960-86) Introduced in Control Theory, via Dynamic Programming [Henrey J. Kelley (1960) \u2022 & Arthur Bryson (1961)] Simpler derivation using Chain Rule [Stephen Dreyfus (1962)] \u2022 General method for Automatic Differentiation [Seppo Linnainamaa (1970)] \u2022 Using Backprop to estimating parameters of controllers with objective of \u2022 minimizing error [Stuart Dreyfus (1973)] Backprop brought into NN world [Paul Werbos (1974)] \u2022 Used BP to learn representations in hidden layers of NNs [Rumelhart, Hinton & \u2022 Williams (1986)]",
    "source": "Deep Machine Learning - Slide 32",
    "source_detail": "ELEC576-Lec02.pdf, Page 32",
    "lecture": "Deep Machine Learning",
    "lecture_number": "576",
    "page": 32,
    "content_type": "text",
    "doc_id": "slide_576_32",
    "doc_type": "slide",
    "is_definition": false,
    "contains_equation": false,
    "importance": "high",
    "tags": [
      "backpropagation",
      "neural networks"
    ]
  },
  {
    "text": "Solving Digit Recognition for the US Post Office: (Yann Lecun 1989)",
    "source": "Deep Machine Learning - Slide 33",
    "source_detail": "ELEC576-Lec02.pdf, Page 33",
    "lecture": "Deep Machine Learning",
    "lecture_number": "576",
    "page": 33,
    "content_type": "text",
    "doc_id": "slide_576_33",
    "doc_type": "slide",
    "is_definition": false,
    "contains_equation": false,
    "importance": "high",
    "tags": [
      "neural networks"
    ]
  },
  {
    "text": "Long Short-Term Memory Recurrent Neural Networks (Hochreiter & Schmidhuber,1992)",
    "source": "Deep Machine Learning - Slide 34",
    "source_detail": "ELEC576-Lec02.pdf, Page 34",
    "lecture": "Deep Machine Learning",
    "lecture_number": "576",
    "page": 34,
    "content_type": "text",
    "doc_id": "slide_576_34",
    "doc_type": "slide",
    "is_definition": true,
    "contains_equation": false,
    "importance": "high",
    "tags": [
      "rnn",
      "neural networks"
    ]
  },
  {
    "text": "Graphical Processing Units (GPUs) revolutionize Deep Learning GPUs first introduced in 2006 for DL \u2022 Order of magnitude increase in \u2022 speed of training Nvidia is the major player; Intel and \u2022 others lagging behind. New Tensor Processing Units \u2022 (TPUs) being offered by Google",
    "source": "Deep Machine Learning - Slide 37",
    "source_detail": "ELEC576-Lec02.pdf, Page 37",
    "lecture": "Deep Machine Learning",
    "lecture_number": "576",
    "page": 37,
    "content_type": "figure",
    "doc_id": "slide_576_37",
    "doc_type": "slide",
    "is_definition": false,
    "contains_equation": false,
    "importance": "high",
    "tags": [
      "Tensor Processing Units",
      "Google",
      "Deep Learning",
      "Nvidia",
      "Graphical Processing Units"
    ]
  },
  {
    "text": "ImageNet Dataset (2011): The Largest Hand- Labeled Dataset in the World",
    "source": "Deep Machine Learning - Slide 38",
    "source_detail": "ELEC576-Lec02.pdf, Page 38",
    "lecture": "Deep Machine Learning",
    "lecture_number": "576",
    "page": 38,
    "content_type": "figure",
    "doc_id": "slide_576_38",
    "doc_type": "slide",
    "is_definition": true,
    "contains_equation": false,
    "importance": "high",
    "tags": [
      "Hand-Labeled",
      "Dataset",
      "Largest",
      "2011",
      "ImageNet"
    ]
  },
  {
    "text": "Convnets dominate ImageNet Challenge (2012)",
    "source": "Deep Machine Learning - Slide 39",
    "source_detail": "ELEC576-Lec02.pdf, Page 39",
    "lecture": "Deep Machine Learning",
    "lecture_number": "576",
    "page": 39,
    "content_type": "figure",
    "doc_id": "slide_576_39",
    "doc_type": "slide",
    "is_definition": false,
    "contains_equation": false,
    "importance": "high",
    "tags": [
      "cnn"
    ]
  },
  {
    "text": "Deep Learning: Recent Applications to Neuroscience",
    "source": "Deep Machine Learning - Slide 40",
    "source_detail": "ELEC576-Lec02.pdf, Page 40",
    "lecture": "Deep Machine Learning",
    "lecture_number": "576",
    "page": 40,
    "content_type": "text",
    "doc_id": "slide_576_40",
    "doc_type": "slide",
    "is_definition": false,
    "contains_equation": true,
    "importance": "high",
    "tags": [
      "Deep Learning",
      "Recent Advances",
      "Neuroscience",
      "Applications"
    ]
  },
  {
    "text": "Deep Learning: Recent Applications to Neuroscience",
    "source": "Deep Machine Learning - Slide 41",
    "source_detail": "ELEC576-Lec02.pdf, Page 41",
    "lecture": "Deep Machine Learning",
    "lecture_number": "576",
    "page": 41,
    "content_type": "text",
    "doc_id": "slide_576_41",
    "doc_type": "slide",
    "is_definition": false,
    "contains_equation": true,
    "importance": "high",
    "tags": [
      "Deep Learning",
      "Recent Advances",
      "Neuroscience",
      "Applications"
    ]
  },
  {
    "text": "Conclusions History of NNs touches upon many different fields and ideas: \u2022 Neuroscience, Cognitive Science, Mind-Body problem \u2022 Boolean functions, logic, expressive power \u2022 \u201cMachine\u201d Learning, Optimization \u2022 Chock full of interesting ideas that were far ahead of their time: \u2022 Many of them are resurging now \u2014> Final Projects or your own \u2022 research?",
    "source": "Deep Machine Learning - Slide 42",
    "source_detail": "ELEC576-Lec02.pdf, Page 42",
    "lecture": "Deep Machine Learning",
    "lecture_number": "576",
    "page": 42,
    "content_type": "text",
    "doc_id": "slide_576_42",
    "doc_type": "slide",
    "is_definition": false,
    "contains_equation": false,
    "importance": "high",
    "tags": [
      "optimization",
      "neural networks"
    ]
  },
  {
    "text": "Outline Neural Networks \u2022 Definition of NN and terminology \u2022 Review of (Old) Theoretical Results about NNs \u2022 Intuition for why compositions of nonlinear functions are more expressive \u2022 Expressive power theorems [McC-Pitts, Rosenblatt, Cybenko] \u2022 Backpropagation algorithm (Gradient Descent + Chain Rule) \u2022 History of backprop summary \u2022 Gradient descent (Review). \u2022 Chain Rule (Review). \u2022 Backprop \u2022 Intro to Convnets \u2022 Convolutional Layer, ReLu, Max-Pooling \u2022",
    "source": "ELEC 576: - Slide 2",
    "source_detail": "ELEC576-Lec03.pdf, Page 2",
    "lecture": "ELEC 576:",
    "lecture_number": "576",
    "page": 2,
    "content_type": "text",
    "doc_id": "slide_576_2",
    "doc_type": "slide",
    "is_definition": true,
    "contains_equation": true,
    "importance": "high",
    "tags": [
      "cnn",
      "backpropagation",
      "neural networks"
    ]
  },
  {
    "text": "Neural Network: Definitions Net (Output) Input Activation Input Output Units Units http://ufldl.stanford.edu/tutorial/supervised/MultiLayerNeuralNetworks/",
    "source": "ELEC 576: - Slide 4",
    "source_detail": "ELEC576-Lec03.pdf, Page 4",
    "lecture": "ELEC 576:",
    "lecture_number": "576",
    "page": 4,
    "content_type": "text",
    "doc_id": "slide_576_4",
    "doc_type": "slide",
    "is_definition": true,
    "contains_equation": false,
    "importance": "high",
    "tags": [
      "neural networks"
    ]
  },
  {
    "text": "Neural Networks: Activation Functions http://ufldl.stanford.edu/tutorial/supervised/MultiLayerNeuralNetworks/",
    "source": "ELEC 576: - Slide 5",
    "source_detail": "ELEC576-Lec03.pdf, Page 5",
    "lecture": "ELEC 576:",
    "lecture_number": "576",
    "page": 5,
    "content_type": "text",
    "doc_id": "slide_576_5",
    "doc_type": "slide",
    "is_definition": true,
    "contains_equation": true,
    "importance": "high",
    "tags": [
      "neural networks"
    ]
  },
  {
    "text": "Neural Networks: Definitions Hidden Units Feedforward Propagation: Scalar Form Output Input Units Units (Output) Net Activation Input http://ufldl.stanford.edu/tutorial/supervised/MultiLayerNeuralNetworks/",
    "source": "ELEC 576: - Slide 6",
    "source_detail": "ELEC576-Lec03.pdf, Page 6",
    "lecture": "ELEC 576:",
    "lecture_number": "576",
    "page": 6,
    "content_type": "text",
    "doc_id": "slide_576_6",
    "doc_type": "slide",
    "is_definition": true,
    "contains_equation": true,
    "importance": "high",
    "tags": [
      "neural networks"
    ]
  },
  {
    "text": "Neural Networks: Definitions Hidden Units Feedforward Propagation: Vector Form Output Input Units Units (Output) Net Activation Input http://ufldl.stanford.edu/tutorial/supervised/MultiLayerNeuralNetworks/",
    "source": "ELEC 576: - Slide 7",
    "source_detail": "ELEC576-Lec03.pdf, Page 7",
    "lecture": "ELEC 576:",
    "lecture_number": "576",
    "page": 7,
    "content_type": "text",
    "doc_id": "slide_576_7",
    "doc_type": "slide",
    "is_definition": true,
    "contains_equation": true,
    "importance": "high",
    "tags": [
      "neural networks"
    ]
  },
  {
    "text": "Neural Networks: Definitions Deep Feedforward Propagation: Vector Form http://ufldl.stanford.edu/tutorial/supervised/MultiLayerNeuralNetworks/",
    "source": "ELEC 576: - Slide 8",
    "source_detail": "ELEC576-Lec03.pdf, Page 8",
    "lecture": "ELEC 576:",
    "lecture_number": "576",
    "page": 8,
    "content_type": "text",
    "doc_id": "slide_576_8",
    "doc_type": "slide",
    "is_definition": true,
    "contains_equation": true,
    "importance": "high",
    "tags": [
      "neural networks"
    ]
  },
  {
    "text": "Neural Networks: Definitions The Training Objective http://ufldl.stanford.edu/tutorial/supervised/MultiLayerNeuralNetworks/",
    "source": "ELEC 576: - Slide 9",
    "source_detail": "ELEC576-Lec03.pdf, Page 9",
    "lecture": "ELEC 576:",
    "lecture_number": "576",
    "page": 9,
    "content_type": "text",
    "doc_id": "slide_576_9",
    "doc_type": "slide",
    "is_definition": true,
    "contains_equation": true,
    "importance": "high",
    "tags": [
      "neural networks"
    ]
  },
  {
    "text": "Expressive Power Theorems",
    "source": "ELEC 576: - Slide 10",
    "source_detail": "ELEC576-Lec03.pdf, Page 10",
    "lecture": "ELEC 576:",
    "lecture_number": "576",
    "page": 10,
    "content_type": "text",
    "doc_id": "slide_576_10",
    "doc_type": "slide",
    "is_definition": false,
    "contains_equation": false,
    "importance": "high",
    "tags": [
      "Computational Models",
      "Formal Languages",
      "Expressive Power",
      "Theorems"
    ]
  },
  {
    "text": "Compositions of Nonlinear Functions are more expressive [Yoshua Bengio]",
    "source": "ELEC 576: - Slide 11",
    "source_detail": "ELEC576-Lec03.pdf, Page 11",
    "lecture": "ELEC 576:",
    "lecture_number": "576",
    "page": 11,
    "content_type": "text",
    "doc_id": "slide_576_11",
    "doc_type": "slide",
    "is_definition": false,
    "contains_equation": false,
    "importance": "medium",
    "tags": [
      "Yoshua Bengio",
      "Compositions",
      "Nonlinear Functions",
      "Expressiveness"
    ]
  },
  {
    "text": "McCulloch-Pitts Neurons",
    "source": "ELEC 576: - Slide 12",
    "source_detail": "ELEC576-Lec03.pdf, Page 12",
    "lecture": "ELEC 576:",
    "lecture_number": "576",
    "page": 12,
    "content_type": "text",
    "doc_id": "slide_576_12",
    "doc_type": "slide",
    "is_definition": true,
    "contains_equation": false,
    "importance": "high",
    "tags": [
      "computational models",
      "McCulloch-Pitts Neurons",
      "artificial intelligence",
      "neural networks"
    ]
  },
  {
    "text": "Expressive Power of McCulloch-Pitts Nets",
    "source": "ELEC 576: - Slide 13",
    "source_detail": "ELEC576-Lec03.pdf, Page 13",
    "lecture": "ELEC 576:",
    "lecture_number": "576",
    "page": 13,
    "content_type": "text",
    "doc_id": "slide_576_13",
    "doc_type": "slide",
    "is_definition": false,
    "contains_equation": false,
    "importance": "high",
    "tags": [
      "Expressive Power",
      "Neural Networks",
      "McCulloch-Pitts Nets"
    ]
  },
  {
    "text": "The Perceptron (Rosenblatt)",
    "source": "ELEC 576: - Slide 14",
    "source_detail": "ELEC576-Lec03.pdf, Page 14",
    "lecture": "ELEC 576:",
    "lecture_number": "576",
    "page": 14,
    "content_type": "text",
    "doc_id": "slide_576_14",
    "doc_type": "slide",
    "is_definition": true,
    "contains_equation": false,
    "importance": "high",
    "tags": [
      "neural networks"
    ]
  },
  {
    "text": "Limitations of Perceptron Rosenblatt was overly enthusiastic about the perceptron and made the ill-timed \u2022 proclamation that: \"Given an elementary \u03b1-perceptron, a stimulus world W, and any classification C(W) for \u2022 which a solution exists; let all stimuli in W occur in any sequence, provided that each stimulus must reoccur in finite time; then beginning from an arbitrary initial state, an error correction procedure will always yield a solution to C(W) in finite time\u2026\u201d [4] In 1969, Marvin Minsky and Seymour Papert showed that the perceptron could only \u2022 solve linearly separable functions. Of particular interest was the fact that the perceptron still could not solve the XOR and NXOR functions. Problem outlined by Minsky and Papert can be solved by deep NNs. However, many of \u2022 the artificial neural networks in use today still stem from the early advances of the McCulloch-Pitts neuron and the Rosenblatt perceptron.",
    "source": "ELEC 576: - Slide 15",
    "source_detail": "ELEC576-Lec03.pdf, Page 15",
    "lecture": "ELEC 576:",
    "lecture_number": "576",
    "page": 15,
    "content_type": "text",
    "doc_id": "slide_576_15",
    "doc_type": "slide",
    "is_definition": false,
    "contains_equation": true,
    "importance": "high",
    "tags": [
      "neural networks"
    ]
  },
  {
    "text": "Universal Approximation Theorem [Cybenko 1989, Hornik 1991] https://en.wikipedia.org/wiki/Universal_approximation_theorem \u2022",
    "source": "ELEC 576: - Slide 16",
    "source_detail": "ELEC576-Lec03.pdf, Page 16",
    "lecture": "ELEC 576:",
    "lecture_number": "576",
    "page": 16,
    "content_type": "text",
    "doc_id": "slide_576_16",
    "doc_type": "slide",
    "is_definition": true,
    "contains_equation": false,
    "importance": "high",
    "tags": [
      "Universal Approximation Theorem",
      "Cybenko 1989",
      "Hornik 1991",
      "approximation theory",
      "neural networks"
    ]
  },
  {
    "text": "Universal Approximation Theorem https://en.wikipedia.org/wiki/Universal_approximation_theorem \u2022 Shallow neural networks can represent a wide variety of interesting \u2022 functions when given appropriate parameters; however, it does not touch upon the algorithmic learnability of those parameters. Proved by George Cybenko in 1989 for sigmoid activation functions.[2] \u2022 Kurt Hornik showed in 1991[3] that it is not the specific choice of the \u2022 activation function, but rather the multilayer feedforward architecture itself which gives neural networks the potential of being universal approximators.",
    "source": "ELEC 576: - Slide 17",
    "source_detail": "ELEC576-Lec03.pdf, Page 17",
    "lecture": "ELEC 576:",
    "lecture_number": "576",
    "page": 17,
    "content_type": "text",
    "doc_id": "slide_576_17",
    "doc_type": "slide",
    "is_definition": true,
    "contains_equation": false,
    "importance": "high",
    "tags": [
      "neural networks"
    ]
  },
  {
    "text": "Question (5 min): Why is the theorem true? What is the intuition? What happens when you go deep? Try iterating f(x) = x^2 vs. f(x) = ax+b",
    "source": "ELEC 576: - Slide 18",
    "source_detail": "ELEC576-Lec03.pdf, Page 18",
    "lecture": "ELEC 576:",
    "lecture_number": "576",
    "page": 18,
    "content_type": "equation",
    "doc_id": "slide_576_18",
    "doc_type": "slide",
    "is_definition": false,
    "contains_equation": true,
    "importance": "high",
    "tags": [
      "theorem intuition",
      "iterating functions",
      "f(x) = ax+b",
      "deep exploration",
      "f(x) = x^2"
    ]
  },
  {
    "text": "Training Neural Networks Via Gradient Descent",
    "source": "ELEC 576: - Slide 19",
    "source_detail": "ELEC576-Lec03.pdf, Page 19",
    "lecture": "ELEC 576:",
    "lecture_number": "576",
    "page": 19,
    "content_type": "text",
    "doc_id": "slide_576_19",
    "doc_type": "slide",
    "is_definition": false,
    "contains_equation": true,
    "importance": "high",
    "tags": [
      "backpropagation",
      "neural networks"
    ]
  },
  {
    "text": "Gradient Descent [Fei-Fei Li, Andrej Karpathy, Justin Johnson]",
    "source": "ELEC 576: - Slide 20",
    "source_detail": "ELEC576-Lec03.pdf, Page 20",
    "lecture": "ELEC 576:",
    "lecture_number": "576",
    "page": 20,
    "content_type": "text",
    "doc_id": "slide_576_20",
    "doc_type": "slide",
    "is_definition": false,
    "contains_equation": true,
    "importance": "high",
    "tags": [
      "backpropagation"
    ]
  },
  {
    "text": "Question: What kind of problems might you run into with Gradient Descent? (4 min)",
    "source": "ELEC 576: - Slide 23",
    "source_detail": "ELEC576-Lec03.pdf, Page 23",
    "lecture": "ELEC 576:",
    "lecture_number": "576",
    "page": 23,
    "content_type": "text",
    "doc_id": "slide_576_23",
    "doc_type": "slide",
    "is_definition": false,
    "contains_equation": false,
    "importance": "medium",
    "tags": [
      "backpropagation"
    ]
  },
  {
    "text": "Global Optima is not Guaranteed",
    "source": "ELEC 576: - Slide 24",
    "source_detail": "ELEC576-Lec03.pdf, Page 24",
    "lecture": "ELEC 576:",
    "lecture_number": "576",
    "page": 24,
    "content_type": "text",
    "doc_id": "slide_576_24",
    "doc_type": "slide",
    "is_definition": false,
    "contains_equation": false,
    "importance": "high",
    "tags": [
      "Global Optima",
      "Optimization",
      "Guaranteed"
    ]
  },
  {
    "text": "Learning Rate Needs to Be Carefully Chosen",
    "source": "ELEC 576: - Slide 25",
    "source_detail": "ELEC576-Lec03.pdf, Page 25",
    "lecture": "ELEC 576:",
    "lecture_number": "576",
    "page": 25,
    "content_type": "text",
    "doc_id": "slide_576_25",
    "doc_type": "slide",
    "is_definition": false,
    "contains_equation": false,
    "importance": "high",
    "tags": [
      "optimization"
    ]
  },
  {
    "text": "Training Neural Networks: Computing Gradients Efficiently with the Backpropagation Algorithm",
    "source": "ELEC 576: - Slide 26",
    "source_detail": "ELEC576-Lec03.pdf, Page 26",
    "lecture": "ELEC 576:",
    "lecture_number": "576",
    "page": 26,
    "content_type": "text",
    "doc_id": "slide_576_26",
    "doc_type": "slide",
    "is_definition": true,
    "contains_equation": true,
    "importance": "high",
    "tags": [
      "backpropagation",
      "neural networks"
    ]
  },
  {
    "text": "Exercise: Do Chain Rule on a nested function (2 min)",
    "source": "ELEC 576: - Slide 30",
    "source_detail": "ELEC576-Lec03.pdf, Page 30",
    "lecture": "ELEC 576:",
    "lecture_number": "576",
    "page": 30,
    "content_type": "text",
    "doc_id": "slide_576_30",
    "doc_type": "slide",
    "is_definition": false,
    "contains_equation": true,
    "importance": "high",
    "tags": [
      "Chain Rule",
      "calculus",
      "exercise",
      "nested function"
    ]
  },
  {
    "text": "Backpropagation is an efficient way to compute gradients a.k.a. Reverse Mode Automatic Differentiation (AD), and based on a \u2022 systematic application of the chain rule. It is fast for low-dimensional outputs. For one output (e.g. a scalar loss function), time to compute gradients with respect to ALL inputs is proportional to the time to compute the output. An explicit mathematical expression of the output is not required, only an algorithm to compute it. it is NOT the same as symbolic differentiation (e.g. mathematica). \u2022 Numerical/Finite Differences are slow for high-dimensional inputs (e.g. \u2022 model parameters) and outputs. For a single output, time to compute gradients scales as the number of inputs. May suffer from issues of floating point precision and requires a choice of a parameter increment. Geometrical Centered Finite Difference Secant https://www.cs.cmu.edu/~mgormley/courses/10601-s17/slides/lecture20-backprop.pdf",
    "source": "ELEC 576: - Slide 31",
    "source_detail": "ELEC576-Lec03.pdf, Page 31",
    "lecture": "ELEC 576:",
    "lecture_number": "576",
    "page": 31,
    "content_type": "text",
    "doc_id": "slide_576_31",
    "doc_type": "slide",
    "is_definition": true,
    "contains_equation": true,
    "importance": "high",
    "tags": [
      "backpropagation",
      "loss functions"
    ]
  },
  {
    "text": "The Cheap Gradient Principle in Backpropagation: The time complexity scales up to the number of operations performed in the forward pass \ud835\ude7e\ud835\ude7f\ud835\ude82 { \u2207 \ud835\ude8f(x)} \u2264 \u03c9 \ud835\ude7e\ud835\ude7f\ud835\ude82 {\ud835\ude8f(x)} x \u03c9 \u223c 5 Is a multidimensional input, for polynomial operations and OPS counting the number of multiplications \u03c9 = 3 m More generally, for an -dimensional output F(x) \ud835\ude7e\ud835\ude7f\ud835\ude82 F\u2032(x) \u2264 \ud835\ude96 \u03c9 \ud835\ude7e\ud835\ude7f\ud835\ude82 F(x) { } { } \u0000 There is no equivalent Cheap Jacobian Principle or Cheap Hessian Principle https://www.math.uni-bielefeld.de/documenta/vol-ismp/52_griewank-andreas-b.pdf",
    "source": "ELEC 576: - Slide 32",
    "source_detail": "ELEC576-Lec03.pdf, Page 32",
    "lecture": "ELEC 576:",
    "lecture_number": "576",
    "page": 32,
    "content_type": "equation",
    "doc_id": "slide_576_32",
    "doc_type": "slide",
    "is_definition": false,
    "contains_equation": true,
    "importance": "high",
    "tags": [
      "backpropagation"
    ]
  },
  {
    "text": "The Spatial Complexity of Backpropagation scales with the number of operations performed in the forward pass \ud835\ude7c\ud835\ude74\ud835\ude7c F\u2032(x) \u223c \ud835\ude7e\ud835\ude7f\ud835\ude82 F(x) \u2273 \ud835\ude7c\ud835\ude74\ud835\ude7c F(x) { } { } { } \u0000 https://www.math.uni-bielefeld.de/documenta/vol-ismp/52_griewank-andreas-b.pdf",
    "source": "ELEC 576: - Slide 33",
    "source_detail": "ELEC576-Lec03.pdf, Page 33",
    "lecture": "ELEC 576:",
    "lecture_number": "576",
    "page": 33,
    "content_type": "text",
    "doc_id": "slide_576_33",
    "doc_type": "slide",
    "is_definition": false,
    "contains_equation": true,
    "importance": "high",
    "tags": [
      "backpropagation"
    ]
  },
  {
    "text": "Temporal Complexity in Automatic Differentiation F(x) n m x Is a -dimensional input, Is an -dimensional output Reverse Mode: \ud835\ude7e\ud835\ude7f\ud835\ude82 F\u2032(x) \u2264 \ud835\ude96 \u03c9 \ud835\ude7e\ud835\ude7f\ud835\ude82 F(x) { } { } \u0000 Forward Mode: \ud835\ude7e\ud835\ude7f\ud835\ude82 F\u2032(x) \u2264 \ud835\ude97 \u03c9 \ud835\ude7e\ud835\ude7f\ud835\ude82 F(x) { } { } \u0000 \u03c9 < 6 There is no Cheap Jacobian Principle or Cheap Hessian Principle but a Jacobian- vector product can be computed as efficiently as the gradient, and a Hessian-vector product can be computed efficiently in O(n) instead of O(nxn) https://arxiv.org/pdf/1502.05767.pdf https://www.math.uni-bielefeld.de/documenta/vol-ismp/52_griewank-andreas-b.pdf",
    "source": "ELEC 576: - Slide 34",
    "source_detail": "ELEC576-Lec03.pdf, Page 34",
    "lecture": "ELEC 576:",
    "lecture_number": "576",
    "page": 34,
    "content_type": "text",
    "doc_id": "slide_576_34",
    "doc_type": "slide",
    "is_definition": false,
    "contains_equation": true,
    "importance": "high",
    "tags": [
      "Jacobian-vector product",
      "Reverse Mode",
      "Temporal Complexity",
      "Forward Mode",
      "Automatic Differentiation"
    ]
  },
  {
    "text": "How to Learn NNs? History of the Backpropagation Algorithm (1960-86) Introduced by Henrey J. Kelley (1960) and Arthur Bryson (1961) in control theory, \u2022 using Dynamic Programming Simpler derivation using Chain Rule by Stephen Dreyfus (1962) \u2022 General method for Automatic Differentiation by Seppo Linnainamaa (1970) \u2022 Using backdrop for parameters of controllers minimizing error by Stuart Dreyfus \u2022 (1973) Backprop brought into NN world by Paul Werbos (1974) \u2022 Used it to learn representations in hidden layers of NNs by Rumelhart, Hinton & \u2022 Williams (1986)",
    "source": "ELEC 576: - Slide 35",
    "source_detail": "ELEC576-Lec03.pdf, Page 35",
    "lecture": "ELEC 576:",
    "lecture_number": "576",
    "page": 35,
    "content_type": "text",
    "doc_id": "slide_576_35",
    "doc_type": "slide",
    "is_definition": false,
    "contains_equation": false,
    "importance": "high",
    "tags": [
      "backpropagation",
      "neural networks"
    ]
  },
  {
    "text": "Backpropagation Example (5 min) Output calculation Pass Pass Modified from https://www.cs.cmu.edu/~mgormley/courses/10601-s17/slides/lecture20-backprop.pdf",
    "source": "ELEC 576: - Slide 36",
    "source_detail": "ELEC576-Lec03.pdf, Page 36",
    "lecture": "ELEC 576:",
    "lecture_number": "576",
    "page": 36,
    "content_type": "text",
    "doc_id": "slide_576_36",
    "doc_type": "slide",
    "is_definition": false,
    "contains_equation": true,
    "importance": "high",
    "tags": [
      "backpropagation"
    ]
  },
  {
    "text": "Backpropagation Example Output calculation Pass Pass Gradient calculation Linked by the chain rule Modified from https://www.cs.cmu.edu/~mgormley/courses/10601-s17/slides/lecture20-backprop.pdf",
    "source": "ELEC 576: - Slide 37",
    "source_detail": "ELEC576-Lec03.pdf, Page 37",
    "lecture": "ELEC 576:",
    "lecture_number": "576",
    "page": 37,
    "content_type": "text",
    "doc_id": "slide_576_37",
    "doc_type": "slide",
    "is_definition": false,
    "contains_equation": true,
    "importance": "high",
    "tags": [
      "backpropagation"
    ]
  },
  {
    "text": "Backpropagation Example The backward pass computes the derivative of the single output J wrt all inputs efficiently x , \u2713 , a, y j j <<<<llllaaaatttteeeexxxxiiiitttt sssshhhhaaaa1111____bbbbaaaasssseeee66664444====\"\"\"\"ccccrrrrddddFFFFHHHHbbbbUUUUXXXXSSSSssssnnnnvvvvTTTTGGGGKKKKUUUUccccKKKKBBBBVVVVccccxxxxaaaaFFFFffffddddMMMM====\"\"\"\">>>>AAAAAAAAAAAABBBB++++XXXXiiiiccccbbbbZZZZDDDDLLLLSSSSssssNNNNAAAAFFFFIIIIYYYYnnnn9999VVVVbbbbrrrrLLLLeeeerrrrSSSSzzzzWWWWAAAARRRRXXXXJJJJSSSSSSSSiiiiKKKKDDDDLLLLoooohhhhuuuuXXXXFFFFeeeewwwwFFFF2222hhhhAAAAmmmm00000000kkkk7777ddddjjjjIIIIJJJJMMMMyyyyffffFFFFEEEEPPPPoooommmmbbbbllllwwwwoooo4444ttttYYYY3333cccceeeeffffbbbbOOOOGGGG2222zzzz0000NNNNYYYYffffBBBBjjjj7777++++ccccwwww7777nnnnzzzzBBBB8888kkkkggggmmmmttttwwwwnnnnGGGG++++rrrrttttLLLLaaaa++++ssssbbbbllllVVVV3333qqqq7777ssss7777OOOO7777ttttHHHH9999iiiiHHHHRRRR22220000ddddpppp4444qqqqyyyyFFFFoooo1111FFFFrrrrLLLLooooBBBB0000UUUUxxxxwwwwyyyyVVVVrrrrAAAAQQQQbbbbBBBBuuuuoooohhhhiiiiJJJJAAAAssssEEEE6666wwwwffffhhhh2222VVVVuuuu9999MMMMmmmmNNNNIIII8888llllgggg++++QQQQJJJJccccyyyyLLLLyyyyFFFFDDDDyyyykkkkFFFFMMMMCCCCxxxxvvvvJJJJtttt++++8888llll////rrrrPPPPVVVVhhhhxxxxIIIIAAAAYYYYIIIILLLLXXXXMMMMtttt6666ttttOOOO3333ZZZZkkkkLLLLrrrr4444JJJJbbbbQQQQBBBBUUUUVVVVaaaavvvvrrrr2222VVVV33338888QQQQ0000zzzzRRRRiiiiEEEEqqqqggggggggWWWWvvvvddddccccJJJJwwwwEEEEvvvvJJJJwwwwoooo4444FFFFWWWWxxxxaaaa6666aaaaeeeeaaaaJJJJYYYYSSSSOOOOyyyyZZZZDDDD1111DDDDEEEEooooSSSSMMMMeeee3333llll88888888uuuunnnn++++MMMMwwww4444AAAAxxxxzzzzGGGGyyyyjjjjwwwwJJJJeeeeOOOO7777++++nnnnsssshhhhJJJJppppHHHHUUUUWWWWBBBBaaaaYYYYzzzzIIIIjjjjDDDDSSSSyyyy7777WWWWZZZZ++++VVVV++++ttttllll0000JJJJ44447777eeeeVVVVccccJJJJiiiikkkkwwwwSSSSRRRReeeeLLLLwwwwllllRRRRggggiiiiPPPPEEEEssssBBBBjjjjzzzzggggiiiillllEEEEQQQQmmmmQQQQFFFFCCCCFFFFTTTTeeee3333YYYYjjjjooooiiiiiiiillllAAAAwwwwYYYYVVVVVVVVMMMMCCCCOOOO7777yyyyllll1111eeeehhhhffffVVVVFFFF3333nnnnbbbbpppp7777ffff1111lllltttt3333BBBBRRRRxxxxllllNNNNEEEEJJJJOOOOkkkkXXXXnnnnyyyyEEEEVVVVXXXXqqqqIIIIHHHHuuuuUUUUBBBBOOOO1111EEEEEEEEUUUUTTTT9999IIIIxxxxeeee0000ZZZZuuuuVVVVWWWWyyyy////WWWWuuuu////WWWWxxxxaaaaCCCC1111ZZZZxxxxccccwwwwxxxx++++iiiiPPPPrrrr8888wwwwffffeeeexxxx5555MMMMllll<<<<////llllaaaatttteeeexxxxiiiitttt>>>> Pass Pass Modified from https://www.cs.cmu.edu/~mgormley/courses/10601-s17/slides/lecture20-backprop.pdf..",
    "source": "ELEC 576: - Slide 38",
    "source_detail": "ELEC576-Lec03.pdf, Page 38",
    "lecture": "ELEC 576:",
    "lecture_number": "576",
    "page": 38,
    "content_type": "equation",
    "doc_id": "slide_576_38_chunk1_chunk1",
    "doc_type": "slide",
    "parent_doc_id": "slide_576_38_chunk1",
    "chunk_index": 1,
    "total_chunks": 1,
    "is_definition": false,
    "contains_equation": true,
    "importance": "high",
    "tags": [
      "regularization",
      "backpropagation",
      "neural networks"
    ]
  },
  {
    "text": "Backpropagation Example How efficient? The backward pass takes time proportional to making the forward pass. Pass Pass Modified from https://www.cs.cmu.edu/~mgormley/courses/10601-s17/slides/lecture20-backprop.pdf",
    "source": "ELEC 576: - Slide 39",
    "source_detail": "ELEC576-Lec03.pdf, Page 39",
    "lecture": "ELEC 576:",
    "lecture_number": "576",
    "page": 39,
    "content_type": "text",
    "doc_id": "slide_576_39",
    "doc_type": "slide",
    "is_definition": false,
    "contains_equation": false,
    "importance": "medium",
    "tags": [
      "backpropagation"
    ]
  },
  {
    "text": "Backpropagation Example The values of the derivatives are computed at each step. Backprop does not store their mathematical expressions, unlike in symbolic differentiation Pass Pass Modified from https://www.cs.cmu.edu/~mgormley/courses/10601-s17/slides/lecture20-backprop.pdf",
    "source": "ELEC 576: - Slide 40",
    "source_detail": "ELEC576-Lec03.pdf, Page 40",
    "lecture": "ELEC 576:",
    "lecture_number": "576",
    "page": 40,
    "content_type": "text",
    "doc_id": "slide_576_40",
    "doc_type": "slide",
    "is_definition": false,
    "contains_equation": true,
    "importance": "high",
    "tags": [
      "backpropagation"
    ]
  },
  {
    "text": "When is Backpropagation efficient? High-dimensional inputs High-dimensional outputs Efficient? @J( \u2713 , x ) @J( \u2713 , x ) @J ( \u2713 , x ) @J ( \u2713 , x ) i j i j 1 i j 2 i j { } { } , { } { } , ... { } { } , { } { } , ...",
    "source": "ELEC 576: - Slide 41",
    "source_detail": "ELEC576-Lec03.pdf, Page 41",
    "lecture": "ELEC 576:",
    "lecture_number": "576",
    "page": 41,
    "content_type": "equation",
    "doc_id": "slide_576_41_chunk1",
    "doc_type": "slide",
    "parent_doc_id": "slide_576_41",
    "chunk_index": 1,
    "total_chunks": 2,
    "is_definition": false,
    "contains_equation": true,
    "importance": "high",
    "tags": [
      "regularization",
      "backpropagation",
      "rnn",
      "neural networks",
      "cnn"
    ]
  },
  {
    "text": "@\u2713 @\u2713 @\u2713 @\u2713 1 2 <<<<llllaaaatttteeeexxxxiiiitttt sssshhhhaaaa1111____bbbbaaaasssseeee66664444====\"\"\"\"TTTTVVVViiiicccc7777qqqqeeeeEEEEwwww4444LLLLNNNNEEEE1111ZZZZBBBBpppp++++bbbbQQQQmmmmDDDDBBBBddddDDDDppppMMMM====\"\"\"\">>>>AAAAAAAAAAAACCCCZZZZHHHHiiiiccccnnnnVVVVHHHHLLLLSSSS8888MMMMwwwwHHHHEEEE7777rrrreeee77776666qqqq4444kkkkmmmmQQQQ4444BBBBAAAAmmmmSSSSGGGGmmmmHHHHooooEEEEffffRRRRiiii3333iiiiaaaa4444FFFFRRRRYYYYSSSSkkkkmmmmzzzz1111MMMMWWWWllllDDDD5555JJJJffffxxxxVVVVHHHH6666TTTT3333rrrrzzzz6666MMMMWWWW////wwww2222wwwwWWWW1111MMMM2222TTTTPPPPwwwwhhhh8888ffffIIII88888888vvvvkkkkSSSS5555FFFFBBBBoooo8888777788882222yyyy5555++++YYYYXXXXFFFFppppeeeeWWWWVVVVxxxxqqqqrrrraaaa++++ssssbbbbmmmm88887777WWWW9999pppp3333OOOOCCCCssssVVVV4444llll2222UUUUyyyyUUUUwwww8888RRRR1111VVVVyyyyKKKKllllHHHHddddBBBBggggOOOOQQQQPPPPuuuueeeeIIII0000iiiiSSSSSSSS////jjjj4444aaaaXXXXYYYY////3333++++mmmmSSSSssssttttssssvvvvQQQQWWWWRRRRjjjjkkkkPPPPEEEEvvvvqqqqYYYYiiiillllggggwwwwCCCCooooYYYYKKKKnnnnZZZZLLLLEEEEiiiirrrrKKKKSSSS5555FFFFSSSSBBBBooooBBBBJJJJfffftttt0000hhhhJJJJYYYYMMMMCCCCBBBBhhhhooooJJJJUUUUxxxx6666RRRR8888CCCCZZZZ9999IIIIddddVVVVRRRR9999OOOO2222rrrrVVVVrrrr44447777xxxxffff7777NNNNttttkkkk3333VVVVddddNNNN3333SSSSaaaannnnuuuuttttNNNNBBBBssss8888CCCCvvvvwwwwZZZZNNNNVVVVEEEE8888nnnnddddFFFF5555JJJJPPPP2222NNNNFFFFwwwwllllNNNNggggkkkkmmmmrrrrdddd888877770000ccccggggnnnnKKKK8888OOOOZZZZOOOO8888aaaappppBBBBCCCC88885555yyyyyyyyIIIIXXXX3333kkkkPPPPQQQQNNNNTTTTmmmmnnnnAAAAddddllllJJJJOOOOSSSSKKKKnnnnxxxxoooommmmDDDD6666OOOOMMMM2222VVVVWWWWCCCCnnnnjjjjCCCC////kkkkyyyyUUUUNNNNNNNNFFFF6666llllEEEETTTTGGGGmmmmVVVVAAAAYYYY6666GGGGllllttttTTTTPPPP6666llll9999QQQQqqqqIIIIzzzz4444JJJJSSSSppppHHHHkkkkBBBBPPPPGGGGVVVVffffBBBB8888WWWWFFFFxxxxJJJJDDDDhhhhcccceeeeOOOO4444LLLLxxxxRRRRnnnnIIIIEEEEccccGGGGUUUUKKKKaaaaEEEEuuuuSSSSttttmmmmAAAA2222qqqqaaaaAAAA////MMMMvvvvDDDDVVVVOOOOCCCCPPPP////3333kkkkWWWWXXXXDDDDXXXXddddnnnn3333PPPP9999WWWW9999OOOOmmmmuuuuccccXXXXddddRRRR3333LLLLaaaaAAAA8888ddddooooBBBBbbbbyyyy0000SSSSkkkk6666RRRR1111eeeeoooogggg7777qqqqIIIIooooXXXXddddrrrryyyyXXXXKKKKssssLLLLeeeevvvvDDDDXXXXrrrrNNNN33337777NNNN0000vvvvqqqq22223333VVVVmmmmRRRR33330000aaaa++++zzzz9999TTTT1111SSSSSSSSuuuuFFFF8888====<<<<////llllaaaatttteeeexxxxiiiitttt>>>> <<<<llllaaaatttteeeexxxxiiiitttt sssshhhhaaaa1111____bbbbaaaasssseeee66664444====\"\"\"\"nnnnvvvv0000ssssEEEERRRRYYYYZZZZssssqqqqDDDD++++bbbbDDDDsssshhhhzzzzooooYYYY4444ppppppppppppSSSSDDDDmmmmMMMM====\"\"\"\">>>>AAAAAAAAAAAACCCCZZZZHHHHiiiiccccjjjjVVVVFFFFJJJJSSSSwwwwMMMMxxxxGGGGMMMM2222MMMMeeee99991111GGGGiiiiyyyyddddBBBBggggkkkkVVVVQQQQKKKKMMMMOOOOMMMMCCCCHHHHooooUUUUvvvvYYYYiiiinnnnCCCCnnnnaaaaBBBBppppggggyyyyZZZZNNNNNNNNNNNNGGGGMMMMwwwwvvvvJJJJNNNN2222IIIIZZZZ5555kkkk999966668888++++jjjjFFFF33332222GGGG6666ggggNNNNpppp66668888IIIIPPPPAAAA4444yyyy1111ZZZZXXXXssssJJJJMMMMCCCCgggg2222eeee999922227777ZZZZSSSS8888ssssrrrrqqqq2222vvvvrrrrGGGG5555XXXXNNNNrrrreeee2222ddddXXXXWWWWddddvvvvvvvv6666XXXXTTTTXXXXDDDDHHHHeeeeZZZZKKKKllllMMMMVVVVSSSSeeeekkkkmmmmkkkkuuuuRRRR8888CCCCYYYYIIIIkkkkLLLLyyyyTTTTKKKKUUUU7777jjjjUUUUPPPPJJJJ2222++++HHHHwwww77771111ttttssssvvvvXXXXGGGGmmmmRRRRJJJJoooo8888wwwwyyyynnnnggggvvvvppppooooNNNNEEEERRRRIIIIJJJJRRRRMMMMFFFFTTTTggggFFFFCCCCRRRRSSSSllllBBBBUUUUkkkkoooowwwwooooEEEEllllffffgggg++++8888EEEE9999JJJJQQQQWWWWDDDDIIIIggggQQQQaaaaCCCCllllHHHHVVVVSSSSvvvvAAAAZZZZPPPPppppDDDDwwwwrrrrvvvvzzzz1111TTTTttttaaaazzzzjjjjhhhheeeezzzz5555////7777OOOOuuuu6666wwwwZZZZOOOOzzzzXXXXOOOO9999yyyyeeeeBBBBFFFF4444MMMM9999AAAADDDDcccc2222mmmmEEEETTTThhhhvvvvppppJJJJ++++yyyyPPPPOOOOYYYYJJJJMMMMEEEEmmmm11117777vvvvppppeeeeBBBBrrrr1111iiiivvvvDDDDWWWWTTTTvvvvKKKKyyyyQQQQXXXXPPPPOOOOMMMMssssmmmmcccc66664444FFFF0000DDDDEEEExxxxppppzzzz3333SSSSssssmmmmJJJJZZZZXXXX4444xxxxDDDDBBBB9999HHHHKKKKXXXXKKKKrrrrAAAATTTTwwwwhhhhPPPP2222ZZZZKKKKGGGGiiiissss9999SSSSggggOOOOjjjjTTTTOOOOmmmmMMMMNNNNTTTTzzzz2222ppppjjjj8888SSSS++++vvvvmmmmEEEEFFFF33331111CCCCppppFFFFkkkkOOOOffffCCCCEEEETTTTQQQQ++++KKKKccccooookkkkhhhhxxxxeeeePPPPGGGGccccVVVV8888oooozzzzkkkkCCCCOOOODDDDKKKKBBBBMMMMCCCCXXXXNNNNXXXXzzzzIIIIbbbbUUUUNNNNAAAAffffmmmmXXXXyyyyqqqqmmmmBBBBHHHH////++++yyyyYYYYuuuuggggddddeeee77776666nnnnuuuussss////XXXXNNNNSSSSuuuubbbb2222ZZZZ1111rrrrKKKKNNNNDDDDddddIIIIxxxxOOOOkkkkYYYY8888uuuu0000TTTTWWWW6666QQQQwwww3333UUUURRRRAAAAxxxx9999WWWWGGGGuuuuWWWWYYYY++++1111ZZZZnnnn////aaaaWWWWXXXXbbbbUUUUPPPPppppllllbbbbbbbbmmmmmmmmWWWWqqqq6666NNNNffffYYYYRRRR11119999DDDD7777bbbbhhhhffff<<<<////llllaaaatttteeeexxxxiiiitttt>>>> May not be YES Backprop Unless common subexpressions are leveraged Cheap Gradient Principle (Reverse Mode AD) time cost ~ one forward pass Forward Mode AD NO YES NO NO FD time cost is multiple forward passes; 2 PER input Symbolic May not be May not be Formula for J can grow exponentially in size, Differentiation aka Expression Swell (https://arxiv.org/pdf/1502.05767.pdf)..",
    "source": "ELEC 576: - Slide 41",
    "source_detail": "ELEC576-Lec03.pdf, Page 41",
    "lecture": "ELEC 576:",
    "lecture_number": "576",
    "page": 41,
    "content_type": "equation",
    "doc_id": "slide_576_41_chunk2_chunk1",
    "doc_type": "slide",
    "parent_doc_id": "slide_576_41_chunk2",
    "chunk_index": 1,
    "total_chunks": 1,
    "is_definition": false,
    "contains_equation": true,
    "importance": "high",
    "tags": [
      "regularization",
      "backpropagation",
      "rnn",
      "neural networks",
      "cnn"
    ]
  },
  {
    "text": "Pseudo-Code for Backprop: Scalar Form http://ufldl.stanford.edu/tutorial/supervised/MultiLayerNeuralNetworks/",
    "source": "ELEC 576: - Slide 42",
    "source_detail": "ELEC576-Lec03.pdf, Page 42",
    "lecture": "ELEC 576:",
    "lecture_number": "576",
    "page": 42,
    "content_type": "text",
    "doc_id": "slide_576_42",
    "doc_type": "slide",
    "is_definition": false,
    "contains_equation": true,
    "importance": "high",
    "tags": [
      "backpropagation"
    ]
  },
  {
    "text": "Pseudo-Code for Backprop: Matrix-Vector Form http://ufldl.stanford.edu/tutorial/supervised/MultiLayerNeuralNetworks/",
    "source": "ELEC 576: - Slide 43",
    "source_detail": "ELEC576-Lec03.pdf, Page 43",
    "lecture": "ELEC 576:",
    "lecture_number": "576",
    "page": 43,
    "content_type": "text",
    "doc_id": "slide_576_43",
    "doc_type": "slide",
    "is_definition": false,
    "contains_equation": true,
    "importance": "high",
    "tags": [
      "backpropagation"
    ]
  },
  {
    "text": "Gradient Descent for Neural Networks http://ufldl.stanford.edu/tutorial/supervised/MultiLayerNeuralNetworks/",
    "source": "ELEC 576: - Slide 44",
    "source_detail": "ELEC576-Lec03.pdf, Page 44",
    "lecture": "ELEC 576:",
    "lecture_number": "576",
    "page": 44,
    "content_type": "text",
    "doc_id": "slide_576_44",
    "doc_type": "slide",
    "is_definition": false,
    "contains_equation": true,
    "importance": "high",
    "tags": [
      "backpropagation",
      "neural networks"
    ]
  },
  {
    "text": "Backpropagation: Network View",
    "source": "ELEC 576: - Slide 45",
    "source_detail": "ELEC576-Lec03.pdf, Page 45",
    "lecture": "ELEC 576:",
    "lecture_number": "576",
    "page": 45,
    "content_type": "text",
    "doc_id": "slide_576_45",
    "doc_type": "slide",
    "is_definition": false,
    "contains_equation": false,
    "importance": "high",
    "tags": [
      "backpropagation"
    ]
  },
  {
    "text": "Another Deeper Example (for practice)",
    "source": "ELEC 576: - Slide 46",
    "source_detail": "ELEC576-Lec03.pdf, Page 46",
    "lecture": "ELEC 576:",
    "lecture_number": "576",
    "page": 46,
    "content_type": "text",
    "doc_id": "slide_576_46",
    "doc_type": "slide",
    "is_definition": false,
    "contains_equation": false,
    "importance": "low",
    "tags": [
      "Deeper Example",
      "practice",
      "educational text"
    ]
  },
  {
    "text": "Example [Fei-Fei Li, Andrej Karpathy, Justin Johnson]",
    "source": "ELEC 576: - Slide 47",
    "source_detail": "ELEC576-Lec03.pdf, Page 47",
    "lecture": "ELEC 576:",
    "lecture_number": "576",
    "page": 47,
    "content_type": "text",
    "doc_id": "slide_576_47",
    "doc_type": "slide",
    "is_definition": false,
    "contains_equation": false,
    "importance": "low",
    "tags": [
      "Andrej Karpathy",
      "Justin Johnson",
      "Fei-Fei Li"
    ]
  },
  {
    "text": "Example [Fei-Fei Li, Andrej Karpathy, Justin Johnson]",
    "source": "ELEC 576: - Slide 48",
    "source_detail": "ELEC576-Lec03.pdf, Page 48",
    "lecture": "ELEC 576:",
    "lecture_number": "576",
    "page": 48,
    "content_type": "text",
    "doc_id": "slide_576_48",
    "doc_type": "slide",
    "is_definition": false,
    "contains_equation": false,
    "importance": "low",
    "tags": [
      "Andrej Karpathy",
      "Justin Johnson",
      "Fei-Fei Li"
    ]
  },
  {
    "text": "Example [Fei-Fei Li, Andrej Karpathy, Justin Johnson]",
    "source": "ELEC 576: - Slide 49",
    "source_detail": "ELEC576-Lec03.pdf, Page 49",
    "lecture": "ELEC 576:",
    "lecture_number": "576",
    "page": 49,
    "content_type": "text",
    "doc_id": "slide_576_49",
    "doc_type": "slide",
    "is_definition": false,
    "contains_equation": false,
    "importance": "low",
    "tags": [
      "Andrej Karpathy",
      "Justin Johnson",
      "Fei-Fei Li"
    ]
  },
  {
    "text": "Example [Fei-Fei Li, Andrej Karpathy, Justin Johnson]",
    "source": "ELEC 576: - Slide 50",
    "source_detail": "ELEC576-Lec03.pdf, Page 50",
    "lecture": "ELEC 576:",
    "lecture_number": "576",
    "page": 50,
    "content_type": "text",
    "doc_id": "slide_576_50",
    "doc_type": "slide",
    "is_definition": false,
    "contains_equation": false,
    "importance": "low",
    "tags": [
      "Andrej Karpathy",
      "Justin Johnson",
      "Fei-Fei Li"
    ]
  },
  {
    "text": "Example [Fei-Fei Li, Andrej Karpathy, Justin Johnson]",
    "source": "ELEC 576: - Slide 51",
    "source_detail": "ELEC576-Lec03.pdf, Page 51",
    "lecture": "ELEC 576:",
    "lecture_number": "576",
    "page": 51,
    "content_type": "text",
    "doc_id": "slide_576_51",
    "doc_type": "slide",
    "is_definition": false,
    "contains_equation": false,
    "importance": "low",
    "tags": [
      "Andrej Karpathy",
      "Justin Johnson",
      "Fei-Fei Li"
    ]
  },
  {
    "text": "Example [Fei-Fei Li, Andrej Karpathy, Justin Johnson]",
    "source": "ELEC 576: - Slide 52",
    "source_detail": "ELEC576-Lec03.pdf, Page 52",
    "lecture": "ELEC 576:",
    "lecture_number": "576",
    "page": 52,
    "content_type": "text",
    "doc_id": "slide_576_52",
    "doc_type": "slide",
    "is_definition": false,
    "contains_equation": false,
    "importance": "low",
    "tags": [
      "Andrej Karpathy",
      "Justin Johnson",
      "Fei-Fei Li"
    ]
  },
  {
    "text": "Example [Fei-Fei Li, Andrej Karpathy, Justin Johnson]",
    "source": "ELEC 576: - Slide 53",
    "source_detail": "ELEC576-Lec03.pdf, Page 53",
    "lecture": "ELEC 576:",
    "lecture_number": "576",
    "page": 53,
    "content_type": "text",
    "doc_id": "slide_576_53",
    "doc_type": "slide",
    "is_definition": false,
    "contains_equation": false,
    "importance": "low",
    "tags": [
      "Andrej Karpathy",
      "Justin Johnson",
      "Fei-Fei Li"
    ]
  },
  {
    "text": "Example [Fei-Fei Li, Andrej Karpathy, Justin Johnson]",
    "source": "ELEC 576: - Slide 54",
    "source_detail": "ELEC576-Lec03.pdf, Page 54",
    "lecture": "ELEC 576:",
    "lecture_number": "576",
    "page": 54,
    "content_type": "text",
    "doc_id": "slide_576_54",
    "doc_type": "slide",
    "is_definition": false,
    "contains_equation": false,
    "importance": "low",
    "tags": [
      "Andrej Karpathy",
      "Justin Johnson",
      "Fei-Fei Li"
    ]
  },
  {
    "text": "Example [Fei-Fei Li, Andrej Karpathy, Justin Johnson]",
    "source": "ELEC 576: - Slide 55",
    "source_detail": "ELEC576-Lec03.pdf, Page 55",
    "lecture": "ELEC 576:",
    "lecture_number": "576",
    "page": 55,
    "content_type": "text",
    "doc_id": "slide_576_55",
    "doc_type": "slide",
    "is_definition": false,
    "contains_equation": false,
    "importance": "low",
    "tags": [
      "Andrej Karpathy",
      "Justin Johnson",
      "Fei-Fei Li"
    ]
  },
  {
    "text": "Example [Fei-Fei Li, Andrej Karpathy, Justin Johnson]",
    "source": "ELEC 576: - Slide 56",
    "source_detail": "ELEC576-Lec03.pdf, Page 56",
    "lecture": "ELEC 576:",
    "lecture_number": "576",
    "page": 56,
    "content_type": "text",
    "doc_id": "slide_576_56",
    "doc_type": "slide",
    "is_definition": false,
    "contains_equation": false,
    "importance": "low",
    "tags": [
      "Andrej Karpathy",
      "Justin Johnson",
      "Fei-Fei Li"
    ]
  },
  {
    "text": "Example [Fei-Fei Li, Andrej Karpathy, Justin Johnson]",
    "source": "ELEC 576: - Slide 57",
    "source_detail": "ELEC576-Lec03.pdf, Page 57",
    "lecture": "ELEC 576:",
    "lecture_number": "576",
    "page": 57,
    "content_type": "text",
    "doc_id": "slide_576_57",
    "doc_type": "slide",
    "is_definition": false,
    "contains_equation": false,
    "importance": "low",
    "tags": [
      "Andrej Karpathy",
      "Justin Johnson",
      "Fei-Fei Li"
    ]
  },
  {
    "text": "Example [Fei-Fei Li, Andrej Karpathy, Justin Johnson]",
    "source": "ELEC 576: - Slide 58",
    "source_detail": "ELEC576-Lec03.pdf, Page 58",
    "lecture": "ELEC 576:",
    "lecture_number": "576",
    "page": 58,
    "content_type": "text",
    "doc_id": "slide_576_58",
    "doc_type": "slide",
    "is_definition": false,
    "contains_equation": false,
    "importance": "low",
    "tags": [
      "Andrej Karpathy",
      "Justin Johnson",
      "Fei-Fei Li"
    ]
  },
  {
    "text": "Example [Fei-Fei Li, Andrej Karpathy, Justin Johnson]",
    "source": "ELEC 576: - Slide 59",
    "source_detail": "ELEC576-Lec03.pdf, Page 59",
    "lecture": "ELEC 576:",
    "lecture_number": "576",
    "page": 59,
    "content_type": "text",
    "doc_id": "slide_576_59",
    "doc_type": "slide",
    "is_definition": false,
    "contains_equation": false,
    "importance": "low",
    "tags": [
      "Andrej Karpathy",
      "Justin Johnson",
      "Fei-Fei Li"
    ]
  },
  {
    "text": "Example [Fei-Fei Li, Andrej Karpathy, Justin Johnson]",
    "source": "ELEC 576: - Slide 60",
    "source_detail": "ELEC576-Lec03.pdf, Page 60",
    "lecture": "ELEC 576:",
    "lecture_number": "576",
    "page": 60,
    "content_type": "text",
    "doc_id": "slide_576_60",
    "doc_type": "slide",
    "is_definition": false,
    "contains_equation": false,
    "importance": "low",
    "tags": [
      "Andrej Karpathy",
      "Justin Johnson",
      "Fei-Fei Li"
    ]
  },
  {
    "text": "Example [Fei-Fei Li, Andrej Karpathy, Justin Johnson]",
    "source": "ELEC 576: - Slide 61",
    "source_detail": "ELEC576-Lec03.pdf, Page 61",
    "lecture": "ELEC 576:",
    "lecture_number": "576",
    "page": 61,
    "content_type": "text",
    "doc_id": "slide_576_61",
    "doc_type": "slide",
    "is_definition": false,
    "contains_equation": false,
    "importance": "low",
    "tags": [
      "Andrej Karpathy",
      "Justin Johnson",
      "Fei-Fei Li"
    ]
  },
  {
    "text": "Example [Fei-Fei Li, Andrej Karpathy, Justin Johnson]",
    "source": "ELEC 576: - Slide 62",
    "source_detail": "ELEC576-Lec03.pdf, Page 62",
    "lecture": "ELEC 576:",
    "lecture_number": "576",
    "page": 62,
    "content_type": "text",
    "doc_id": "slide_576_62",
    "doc_type": "slide",
    "is_definition": false,
    "contains_equation": false,
    "importance": "low",
    "tags": [
      "Andrej Karpathy",
      "Justin Johnson",
      "Fei-Fei Li"
    ]
  },
  {
    "text": "Example [Fei-Fei Li, Andrej Karpathy, Justin Johnson]",
    "source": "ELEC 576: - Slide 63",
    "source_detail": "ELEC576-Lec03.pdf, Page 63",
    "lecture": "ELEC 576:",
    "lecture_number": "576",
    "page": 63,
    "content_type": "text",
    "doc_id": "slide_576_63",
    "doc_type": "slide",
    "is_definition": false,
    "contains_equation": false,
    "importance": "low",
    "tags": [
      "Andrej Karpathy",
      "Justin Johnson",
      "Fei-Fei Li"
    ]
  },
  {
    "text": "Question: What problems might you encounter with deeply nested functions? (3 min)",
    "source": "ELEC 576: - Slide 64",
    "source_detail": "ELEC576-Lec03.pdf, Page 64",
    "lecture": "ELEC 576:",
    "lecture_number": "576",
    "page": 64,
    "content_type": "text",
    "doc_id": "slide_576_64",
    "doc_type": "slide",
    "is_definition": false,
    "contains_equation": false,
    "importance": "medium",
    "tags": [
      "code complexity",
      "debugging",
      "nested functions",
      "programming",
      "problems"
    ]
  },
  {
    "text": "Visualizing Backprop during Training: Classification with 2-Layer Neural Network http://cs.stanford.edu/people/karpathy/convnetjs/demo/ \u2022 classify2d.html Try playing around with this app to build intuition: \u2022 change datapoints to see how decision boundaries change \u2022 change network layer types, widths, activation functions, etc. \u2022 try shallower vs deeper \u2022",
    "source": "ELEC 576: - Slide 65",
    "source_detail": "ELEC576-Lec03.pdf, Page 65",
    "lecture": "ELEC 576:",
    "lecture_number": "576",
    "page": 65,
    "content_type": "text",
    "doc_id": "slide_576_65",
    "doc_type": "slide",
    "is_definition": false,
    "contains_equation": false,
    "importance": "medium",
    "tags": [
      "cnn",
      "backpropagation",
      "neural networks"
    ]
  },
  {
    "text": "Outline Build a ConvNet Convolutional layer \u2022 Activation functions \u2022 Pooling layer \u2022 Training a ConvNet Pre-processing and Augmentation \u2022 Optimization in ConvNet \u2022 Regularization \u2022 Normalization \u2022 Hyperparameter Search \u2022",
    "source": "ELEC/COMP 576: - Slide 2",
    "source_detail": "ELEC576-Lec05.pdf, Page 2",
    "lecture": "ELEC/COMP 576:",
    "lecture_number": "576",
    "page": 2,
    "content_type": "text",
    "doc_id": "slide_576_2",
    "doc_type": "slide",
    "is_definition": false,
    "contains_equation": false,
    "importance": "high",
    "tags": [
      "regularization",
      "cnn",
      "optimization",
      "neural networks"
    ]
  },
  {
    "text": "Convolutional Networks (Convnets)",
    "source": "ELEC/COMP 576: - Slide 3",
    "source_detail": "ELEC576-Lec05.pdf, Page 3",
    "lecture": "ELEC/COMP 576:",
    "lecture_number": "576",
    "page": 3,
    "content_type": "text",
    "doc_id": "slide_576_3",
    "doc_type": "slide",
    "is_definition": true,
    "contains_equation": false,
    "importance": "high",
    "tags": [
      "cnn"
    ]
  },
  {
    "text": "Convolutional Neural Network",
    "source": "ELEC/COMP 576: - Slide 4",
    "source_detail": "ELEC576-Lec05.pdf, Page 4",
    "lecture": "ELEC/COMP 576:",
    "lecture_number": "576",
    "page": 4,
    "content_type": "text",
    "doc_id": "slide_576_4",
    "doc_type": "slide",
    "is_definition": true,
    "contains_equation": false,
    "importance": "high",
    "tags": [
      "cnn",
      "neural networks"
    ]
  },
  {
    "text": "History of Convolutional Neural Network In 1962, Hubel and Wiesel describe simple and complex cells in visual area V1 \u2022 (inspiration for later NNs: S-->template matching for pattern specificity and C-- >pooling for robustness to nuisances) In 1979, Fukushima introduces the Neocognitron. It foreshadows current deep \u2022 NNs: convolutional layers, weight replication, and WTA-subsampling. However its unsupervised In 1989, LeCun applies Backprop to Fukushima\u2019s Neocognitron to do supervised \u2022 learning. This is the first incarnation of modern convolutional neural nets (CNNs) and subsequently used by US Post Office for address reading. In 1999, Riesenhuber and Poggio introduce HMAX, a computational model that \u2022 summarizes the basic facts about the ventral visual stream In 2012, Krizhevsky introduces AlexNet which is implemented in GPUs and win the \u2022 ImageNet Challenge",
    "source": "ELEC/COMP 576: - Slide 5",
    "source_detail": "ELEC576-Lec05.pdf, Page 5",
    "lecture": "ELEC/COMP 576:",
    "lecture_number": "576",
    "page": 5,
    "content_type": "figure",
    "doc_id": "slide_576_5",
    "doc_type": "slide",
    "is_definition": false,
    "contains_equation": false,
    "importance": "high",
    "tags": [
      "cnn",
      "backpropagation",
      "neural networks"
    ]
  },
  {
    "text": "Convolutional Layer [Fei-Fei Li, Andrej Karpathy, Justin Johnson]",
    "source": "ELEC/COMP 576: - Slide 7",
    "source_detail": "ELEC576-Lec05.pdf, Page 7",
    "lecture": "ELEC/COMP 576:",
    "lecture_number": "576",
    "page": 7,
    "content_type": "text",
    "doc_id": "slide_576_7",
    "doc_type": "slide",
    "is_definition": true,
    "contains_equation": false,
    "importance": "high",
    "tags": [
      "cnn"
    ]
  },
  {
    "text": "Convolutional Layer [Fei-Fei Li, Andrej Karpathy, Justin Johnson]",
    "source": "ELEC/COMP 576: - Slide 8",
    "source_detail": "ELEC576-Lec05.pdf, Page 8",
    "lecture": "ELEC/COMP 576:",
    "lecture_number": "576",
    "page": 8,
    "content_type": "text",
    "doc_id": "slide_576_8",
    "doc_type": "slide",
    "is_definition": true,
    "contains_equation": false,
    "importance": "high",
    "tags": [
      "cnn"
    ]
  },
  {
    "text": "Convolutional Layer [Fei-Fei Li, Andrej Karpathy, Justin Johnson]",
    "source": "ELEC/COMP 576: - Slide 9",
    "source_detail": "ELEC576-Lec05.pdf, Page 9",
    "lecture": "ELEC/COMP 576:",
    "lecture_number": "576",
    "page": 9,
    "content_type": "text",
    "doc_id": "slide_576_9",
    "doc_type": "slide",
    "is_definition": true,
    "contains_equation": false,
    "importance": "high",
    "tags": [
      "cnn"
    ]
  },
  {
    "text": "Convolutional Layer [Fei-Fei Li, Andrej Karpathy, Justin Johnson]",
    "source": "ELEC/COMP 576: - Slide 10",
    "source_detail": "ELEC576-Lec05.pdf, Page 10",
    "lecture": "ELEC/COMP 576:",
    "lecture_number": "576",
    "page": 10,
    "content_type": "text",
    "doc_id": "slide_576_10",
    "doc_type": "slide",
    "is_definition": true,
    "contains_equation": false,
    "importance": "high",
    "tags": [
      "cnn"
    ]
  },
  {
    "text": "Convolutional Layer [Fei-Fei Li, Andrej Karpathy, Justin Johnson]",
    "source": "ELEC/COMP 576: - Slide 11",
    "source_detail": "ELEC576-Lec05.pdf, Page 11",
    "lecture": "ELEC/COMP 576:",
    "lecture_number": "576",
    "page": 11,
    "content_type": "text",
    "doc_id": "slide_576_11",
    "doc_type": "slide",
    "is_definition": true,
    "contains_equation": false,
    "importance": "high",
    "tags": [
      "cnn"
    ]
  },
  {
    "text": "Convolutional Layer [Fei-Fei Li, Andrej Karpathy, Justin Johnson]",
    "source": "ELEC/COMP 576: - Slide 12",
    "source_detail": "ELEC576-Lec05.pdf, Page 12",
    "lecture": "ELEC/COMP 576:",
    "lecture_number": "576",
    "page": 12,
    "content_type": "text",
    "doc_id": "slide_576_12",
    "doc_type": "slide",
    "is_definition": true,
    "contains_equation": false,
    "importance": "high",
    "tags": [
      "cnn"
    ]
  },
  {
    "text": "Convolutional Layer Common to zero-pad the border [Fei-Fei Li, Andrej Karpathy, Justin Johnson]",
    "source": "ELEC/COMP 576: - Slide 13",
    "source_detail": "ELEC576-Lec05.pdf, Page 13",
    "lecture": "ELEC/COMP 576:",
    "lecture_number": "576",
    "page": 13,
    "content_type": "text",
    "doc_id": "slide_576_13",
    "doc_type": "slide",
    "is_definition": false,
    "contains_equation": false,
    "importance": "medium",
    "tags": [
      "cnn"
    ]
  },
  {
    "text": "Convolutional Layer Conv layer animation [Fei-Fei Li, Andrej Karpathy, Justin Johnson]",
    "source": "ELEC/COMP 576: - Slide 14",
    "source_detail": "ELEC576-Lec05.pdf, Page 14",
    "lecture": "ELEC/COMP 576:",
    "lecture_number": "576",
    "page": 14,
    "content_type": "text",
    "doc_id": "slide_576_14",
    "doc_type": "slide",
    "is_definition": false,
    "contains_equation": true,
    "importance": "high",
    "tags": [
      "cnn"
    ]
  },
  {
    "text": "Convolutional Layer Motivation for convolutional layers \u2022 Local connectivity \u2013 Most structured high-dimensional signals (e.g. images) are locally correlated \u2022 Parameter sharing \u2013 Using the same filters across the whole image reduces the parameters dramatically (compared to a dense MLP) \u2022 Translation equivariance \u2013 A shift in the input leads to a same shift in the activation",
    "source": "ELEC/COMP 576: - Slide 15",
    "source_detail": "ELEC576-Lec05.pdf, Page 15",
    "lecture": "ELEC/COMP 576:",
    "lecture_number": "576",
    "page": 15,
    "content_type": "figure",
    "doc_id": "slide_576_15",
    "doc_type": "slide",
    "is_definition": true,
    "contains_equation": false,
    "importance": "high",
    "tags": [
      "cnn",
      "neural networks"
    ]
  },
  {
    "text": "Question: What is the special structure of the matrix that corresponds to a Convolution operation? Can you exploit this structure to design a more efficient algorithm for computing the convolution?",
    "source": "ELEC/COMP 576: - Slide 16",
    "source_detail": "ELEC576-Lec05.pdf, Page 16",
    "lecture": "ELEC/COMP 576:",
    "lecture_number": "576",
    "page": 16,
    "content_type": "text",
    "doc_id": "slide_576_16",
    "doc_type": "slide",
    "is_definition": false,
    "contains_equation": false,
    "importance": "high",
    "tags": [
      "cnn"
    ]
  },
  {
    "text": "Convolutional Network [Fei-Fei Li, Andrej Karpathy, Justin Johnson]",
    "source": "ELEC/COMP 576: - Slide 17",
    "source_detail": "ELEC576-Lec05.pdf, Page 17",
    "lecture": "ELEC/COMP 576:",
    "lecture_number": "576",
    "page": 17,
    "content_type": "text",
    "doc_id": "slide_576_17",
    "doc_type": "slide",
    "is_definition": false,
    "contains_equation": false,
    "importance": "high",
    "tags": [
      "cnn"
    ]
  },
  {
    "text": "A Neural View of Convolutional Layer [Fei-Fei Li, Andrej Karpathy, Justin Johnson]",
    "source": "ELEC/COMP 576: - Slide 18",
    "source_detail": "ELEC576-Lec05.pdf, Page 18",
    "lecture": "ELEC/COMP 576:",
    "lecture_number": "576",
    "page": 18,
    "content_type": "text",
    "doc_id": "slide_576_18",
    "doc_type": "slide",
    "is_definition": false,
    "contains_equation": true,
    "importance": "high",
    "tags": [
      "cnn"
    ]
  },
  {
    "text": "Activation Functions [Fei-Fei Li, Andrej Karpathy, Justin Johnson]",
    "source": "ELEC/COMP 576: - Slide 19",
    "source_detail": "ELEC576-Lec05.pdf, Page 19",
    "lecture": "ELEC/COMP 576:",
    "lecture_number": "576",
    "page": 19,
    "content_type": "text",
    "doc_id": "slide_576_19",
    "doc_type": "slide",
    "is_definition": false,
    "contains_equation": true,
    "importance": "high",
    "tags": [
      "neural networks"
    ]
  },
  {
    "text": "Spatial Max-Pooling Layer [Fei-Fei Li, Andrej Karpathy, Justin Johnson]",
    "source": "ELEC/COMP 576: - Slide 20",
    "source_detail": "ELEC576-Lec05.pdf, Page 20",
    "lecture": "ELEC/COMP 576:",
    "lecture_number": "576",
    "page": 20,
    "content_type": "text",
    "doc_id": "slide_576_20",
    "doc_type": "slide",
    "is_definition": false,
    "contains_equation": false,
    "importance": "high",
    "tags": [
      "cnn"
    ]
  },
  {
    "text": "Max-pooling introduces invariance 50% of output remains the same Shift input by 1 pixel Goodfellow et. al 2016",
    "source": "ELEC/COMP 576: - Slide 21",
    "source_detail": "ELEC576-Lec05.pdf, Page 21",
    "lecture": "ELEC/COMP 576:",
    "lecture_number": "576",
    "page": 21,
    "content_type": "text",
    "doc_id": "slide_576_21",
    "doc_type": "slide",
    "is_definition": false,
    "contains_equation": false,
    "importance": "medium",
    "tags": [
      "cnn"
    ]
  },
  {
    "text": "Training on CIFAR10 http://cs.stanford.edu/people/karpathy/convnetjs/dem \u2022 o/cifar10.html [Fei-Fei Li, Andrej Karpathy, Justin Johnson]",
    "source": "ELEC/COMP 576: - Slide 22",
    "source_detail": "ELEC576-Lec05.pdf, Page 22",
    "lecture": "ELEC/COMP 576:",
    "lecture_number": "576",
    "page": 22,
    "content_type": "text",
    "doc_id": "slide_576_22",
    "doc_type": "slide",
    "is_definition": false,
    "contains_equation": false,
    "importance": "medium",
    "tags": [
      "cnn"
    ]
  },
  {
    "text": "Training Convnets: Problems and Solutions",
    "source": "ELEC/COMP 576: - Slide 23",
    "source_detail": "ELEC576-Lec05.pdf, Page 23",
    "lecture": "ELEC/COMP 576:",
    "lecture_number": "576",
    "page": 23,
    "content_type": "text",
    "doc_id": "slide_576_23",
    "doc_type": "slide",
    "is_definition": false,
    "contains_equation": false,
    "importance": "high",
    "tags": [
      "cnn"
    ]
  },
  {
    "text": "First Lesson: Transfer Learning",
    "source": "ELEC/COMP 576: - Slide 24",
    "source_detail": "ELEC576-Lec05.pdf, Page 24",
    "lecture": "ELEC/COMP 576:",
    "lecture_number": "576",
    "page": 24,
    "content_type": "text",
    "doc_id": "slide_576_24",
    "doc_type": "slide",
    "is_definition": false,
    "contains_equation": false,
    "importance": "high",
    "tags": [
      "transfer learning"
    ]
  },
  {
    "text": "Zero-Center & Normalize Data",
    "source": "ELEC/COMP 576: - Slide 28",
    "source_detail": "ELEC576-Lec05.pdf, Page 28",
    "lecture": "ELEC/COMP 576:",
    "lecture_number": "576",
    "page": 28,
    "content_type": "text",
    "doc_id": "slide_576_28",
    "doc_type": "slide",
    "is_definition": true,
    "contains_equation": false,
    "importance": "high",
    "tags": [
      "Zero-Center",
      "Normalize Data",
      "Data Preprocessing"
    ]
  },
  {
    "text": "In Practice, for Images: Center Only",
    "source": "ELEC/COMP 576: - Slide 30",
    "source_detail": "ELEC576-Lec05.pdf, Page 30",
    "lecture": "ELEC/COMP 576:",
    "lecture_number": "576",
    "page": 30,
    "content_type": "figure",
    "doc_id": "slide_576_30",
    "doc_type": "slide",
    "is_definition": false,
    "contains_equation": false,
    "importance": "low",
    "tags": [
      "Centering",
      "Practice",
      "Images"
    ]
  },
  {
    "text": "Data Augmentation During training: Random crops on the original image \u2022 Horizontal reflections \u2022 During testing: Average prediction of image \u2022 augmented by the four corner patches and the center patch + flipped image (10 augmentations of the image Data augmentation reduces overfitting",
    "source": "ELEC/COMP 576: - Slide 31",
    "source_detail": "ELEC576-Lec05.pdf, Page 31",
    "lecture": "ELEC/COMP 576:",
    "lecture_number": "576",
    "page": 31,
    "content_type": "figure",
    "doc_id": "slide_576_31",
    "doc_type": "slide",
    "is_definition": false,
    "contains_equation": false,
    "importance": "high",
    "tags": [
      "Overfitting",
      "Training Techniques",
      "Image Processing",
      "Testing Methods",
      "Data Augmentation"
    ]
  },
  {
    "text": "Choosing an Activation Function that Helps the Training",
    "source": "ELEC/COMP 576: - Slide 32",
    "source_detail": "ELEC576-Lec05.pdf, Page 32",
    "lecture": "ELEC/COMP 576:",
    "lecture_number": "576",
    "page": 32,
    "content_type": "text",
    "doc_id": "slide_576_32",
    "doc_type": "slide",
    "is_definition": false,
    "contains_equation": false,
    "importance": "high",
    "tags": [
      "neural networks"
    ]
  },
  {
    "text": "ReLU \u201cdead\u201d in -region",
    "source": "ELEC/COMP 576: - Slide 35",
    "source_detail": "ELEC576-Lec05.pdf, Page 35",
    "lecture": "ELEC/COMP 576:",
    "lecture_number": "576",
    "page": 35,
    "content_type": "text",
    "doc_id": "slide_576_35",
    "doc_type": "slide",
    "is_definition": false,
    "contains_equation": false,
    "importance": "high",
    "tags": [
      "ReLU",
      "-region",
      "activation function",
      "dead neurons"
    ]
  },
  {
    "text": "Exponential Linear Unit",
    "source": "ELEC/COMP 576: - Slide 37",
    "source_detail": "ELEC576-Lec05.pdf, Page 37",
    "lecture": "ELEC/COMP 576:",
    "lecture_number": "576",
    "page": 37,
    "content_type": "text",
    "doc_id": "slide_576_37",
    "doc_type": "slide",
    "is_definition": true,
    "contains_equation": false,
    "importance": "high",
    "tags": [
      "deep learning",
      "Exponential Linear Unit",
      "activation function",
      "neural networks"
    ]
  },
  {
    "text": "Weight Initialization",
    "source": "ELEC/COMP 576: - Slide 40",
    "source_detail": "ELEC576-Lec05.pdf, Page 40",
    "lecture": "ELEC/COMP 576:",
    "lecture_number": "576",
    "page": 40,
    "content_type": "text",
    "doc_id": "slide_576_40",
    "doc_type": "slide",
    "is_definition": true,
    "contains_equation": false,
    "importance": "high",
    "tags": [
      "Deep Learning",
      "Neural Networks",
      "Machine Learning",
      "Weight Initialization"
    ]
  },
  {
    "text": "Interesting Question: What happens when the weights are initialized to 0? (2 min)",
    "source": "ELEC/COMP 576: - Slide 41",
    "source_detail": "ELEC576-Lec05.pdf, Page 41",
    "lecture": "ELEC/COMP 576:",
    "lecture_number": "576",
    "page": 41,
    "content_type": "text",
    "doc_id": "slide_576_41",
    "doc_type": "slide",
    "is_definition": false,
    "contains_equation": false,
    "importance": "medium",
    "tags": [
      "training process",
      "weights initialization",
      "machine learning",
      "neural networks"
    ]
  },
  {
    "text": "Answer: The gradients in the backward pass will become zero!",
    "source": "ELEC/COMP 576: - Slide 42",
    "source_detail": "ELEC576-Lec05.pdf, Page 42",
    "lecture": "ELEC/COMP 576:",
    "lecture_number": "576",
    "page": 42,
    "content_type": "text",
    "doc_id": "slide_576_42",
    "doc_type": "slide",
    "is_definition": false,
    "contains_equation": false,
    "importance": "high",
    "tags": [
      "zero",
      "backward pass",
      "gradients"
    ]
  },
  {
    "text": "Random Initialization W = 0.01 * np.random.randn(D, H) Works fine for small networks, but can lead to non-homogeneous distributions of activations across the layers of a network.",
    "source": "ELEC/COMP 576: - Slide 43",
    "source_detail": "ELEC576-Lec05.pdf, Page 43",
    "lecture": "ELEC/COMP 576:",
    "lecture_number": "576",
    "page": 43,
    "content_type": "text",
    "doc_id": "slide_576_43",
    "doc_type": "slide",
    "is_definition": false,
    "contains_equation": true,
    "importance": "high",
    "tags": [
      "neural networks"
    ]
  },
  {
    "text": "Look at Some Activation Statistics Setup: 10-layer net with 500 neurons on each layer, using tanh nonlinearities, and initializing as described in last slide.",
    "source": "ELEC/COMP 576: - Slide 44",
    "source_detail": "ELEC576-Lec05.pdf, Page 44",
    "lecture": "ELEC/COMP 576:",
    "lecture_number": "576",
    "page": 44,
    "content_type": "text",
    "doc_id": "slide_576_44",
    "doc_type": "slide",
    "is_definition": false,
    "contains_equation": true,
    "importance": "high",
    "tags": [
      "neural networks"
    ]
  },
  {
    "text": "Random Initialization",
    "source": "ELEC/COMP 576: - Slide 45",
    "source_detail": "ELEC576-Lec05.pdf, Page 45",
    "lecture": "ELEC/COMP 576:",
    "lecture_number": "576",
    "page": 45,
    "content_type": "text",
    "doc_id": "slide_576_45",
    "doc_type": "slide",
    "is_definition": false,
    "contains_equation": false,
    "importance": "medium",
    "tags": [
      "Machine Learning",
      "Training",
      "Random Initialization",
      "Neural Networks",
      "Optimization"
    ]
  },
  {
    "text": "Random Initialization",
    "source": "ELEC/COMP 576: - Slide 46",
    "source_detail": "ELEC576-Lec05.pdf, Page 46",
    "lecture": "ELEC/COMP 576:",
    "lecture_number": "576",
    "page": 46,
    "content_type": "text",
    "doc_id": "slide_576_46",
    "doc_type": "slide",
    "is_definition": false,
    "contains_equation": false,
    "importance": "medium",
    "tags": [
      "Machine Learning",
      "Training",
      "Random Initialization",
      "Neural Networks",
      "Optimization"
    ]
  },
  {
    "text": "Random Initialization Interesting Question: What will the gradients look like in the backward pass when all activations become zero?",
    "source": "ELEC/COMP 576: - Slide 47",
    "source_detail": "ELEC576-Lec05.pdf, Page 47",
    "lecture": "ELEC/COMP 576:",
    "lecture_number": "576",
    "page": 47,
    "content_type": "text",
    "doc_id": "slide_576_47",
    "doc_type": "slide",
    "is_definition": false,
    "contains_equation": false,
    "importance": "medium",
    "tags": [
      "neural networks"
    ]
  },
  {
    "text": "Answer: The gradients in the backward pass will become zero!",
    "source": "ELEC/COMP 576: - Slide 48",
    "source_detail": "ELEC576-Lec05.pdf, Page 48",
    "lecture": "ELEC/COMP 576:",
    "lecture_number": "576",
    "page": 48,
    "content_type": "text",
    "doc_id": "slide_576_48",
    "doc_type": "slide",
    "is_definition": false,
    "contains_equation": false,
    "importance": "high",
    "tags": [
      "zero",
      "backward pass",
      "gradients"
    ]
  },
  {
    "text": "Xavier Initialization W = np.random.randn(D, H) / np.sqrt(fan_in) Reasonable initialization (Mathematical derivation assumes linear activations)",
    "source": "ELEC/COMP 576: - Slide 49",
    "source_detail": "ELEC576-Lec05.pdf, Page 49",
    "lecture": "ELEC/COMP 576:",
    "lecture_number": "576",
    "page": 49,
    "content_type": "text",
    "doc_id": "slide_576_49",
    "doc_type": "slide",
    "is_definition": false,
    "contains_equation": true,
    "importance": "high",
    "tags": [
      "neural networks"
    ]
  },
  {
    "text": "Xavier Initialization Linear activation: fan-in=n Problem: Assumes zero mean inputs (x) => not true for ReLU Assuming Var(s) = Var(x), Var(w) = 1/n",
    "source": "ELEC/COMP 576: - Slide 50",
    "source_detail": "ELEC576-Lec05.pdf, Page 50",
    "lecture": "ELEC/COMP 576:",
    "lecture_number": "576",
    "page": 50,
    "content_type": "equation",
    "doc_id": "slide_576_50",
    "doc_type": "slide",
    "is_definition": true,
    "contains_equation": true,
    "importance": "high",
    "tags": [
      "neural networks"
    ]
  },
  {
    "text": "Xavier Initialization W = np.random.randn(D, H) / np.sqrt(fan_in) but it breaks when using ReLU non-linearity A better initialization for ReLU is Var(w) = 2/fan_in (He at. al. 2015)",
    "source": "ELEC/COMP 576: - Slide 51",
    "source_detail": "ELEC576-Lec05.pdf, Page 51",
    "lecture": "ELEC/COMP 576:",
    "lecture_number": "576",
    "page": 51,
    "content_type": "text",
    "doc_id": "slide_576_51",
    "doc_type": "slide",
    "is_definition": true,
    "contains_equation": true,
    "importance": "high",
    "tags": [
      "He initialization",
      "ReLU non-linearity",
      "Xavier Initialization",
      "weight initialization",
      "fan_in"
    ]
  },
  {
    "text": "More Initialization Techniques Understanding the difficulty of training deep feedforward neural networks by Glorot and Bengio, 2010 Exact solutions to the nonlinear dynamics of learning in deep linear neural networks by Saxe et al, 2013 Random walk initialization for training very deep feedforward networks by Sussillo and Abbott, 2014 Delving deep into rectifiers: Surpassing human-level performance on ImageNet classification by He et al., 2015 Data-dependent Initializations of Convolutional Neural Networks by Kr\u00e4henb\u00fchl et al., 2015 All you need is a good init by Mishkin and Matas, 2015",
    "source": "ELEC/COMP 576: - Slide 52",
    "source_detail": "ELEC576-Lec05.pdf, Page 52",
    "lecture": "ELEC/COMP 576:",
    "lecture_number": "576",
    "page": 52,
    "content_type": "figure",
    "doc_id": "slide_576_52",
    "doc_type": "slide",
    "is_definition": false,
    "contains_equation": true,
    "importance": "high",
    "tags": [
      "cnn",
      "neural networks"
    ]
  },
  {
    "text": "Stochastic Gradient Descent",
    "source": "ELEC/COMP 576: - Slide 54",
    "source_detail": "ELEC576-Lec05.pdf, Page 54",
    "lecture": "ELEC/COMP 576:",
    "lecture_number": "576",
    "page": 54,
    "content_type": "text",
    "doc_id": "slide_576_54",
    "doc_type": "slide",
    "is_definition": true,
    "contains_equation": false,
    "importance": "high",
    "tags": [
      "backpropagation"
    ]
  },
  {
    "text": "Stochastic Gradient Descent",
    "source": "ELEC/COMP 576: - Slide 55",
    "source_detail": "ELEC576-Lec05.pdf, Page 55",
    "lecture": "ELEC/COMP 576:",
    "lecture_number": "576",
    "page": 55,
    "content_type": "text",
    "doc_id": "slide_576_55",
    "doc_type": "slide",
    "is_definition": true,
    "contains_equation": false,
    "importance": "high",
    "tags": [
      "backpropagation"
    ]
  },
  {
    "text": "Stochastic Gradient Descent for Neural Networks",
    "source": "ELEC/COMP 576: - Slide 56",
    "source_detail": "ELEC576-Lec05.pdf, Page 56",
    "lecture": "ELEC/COMP 576:",
    "lecture_number": "576",
    "page": 56,
    "content_type": "text",
    "doc_id": "slide_576_56",
    "doc_type": "slide",
    "is_definition": false,
    "contains_equation": true,
    "importance": "high",
    "tags": [
      "backpropagation",
      "neural networks"
    ]
  },
  {
    "text": "Batch GD vs Stochastic GD",
    "source": "ELEC/COMP 576: - Slide 57",
    "source_detail": "ELEC576-Lec05.pdf, Page 57",
    "lecture": "ELEC/COMP 576:",
    "lecture_number": "576",
    "page": 57,
    "content_type": "text",
    "doc_id": "slide_576_57",
    "doc_type": "slide",
    "is_definition": false,
    "contains_equation": false,
    "importance": "high",
    "tags": [
      "Machine Learning",
      "Optimization Algorithms",
      "Batch Gradient Descent",
      "Stochastic Gradient Descent"
    ]
  },
  {
    "text": "Nesterov Momentum Update",
    "source": "ELEC/COMP 576: - Slide 60",
    "source_detail": "ELEC576-Lec05.pdf, Page 60",
    "lecture": "ELEC/COMP 576:",
    "lecture_number": "576",
    "page": 60,
    "content_type": "text",
    "doc_id": "slide_576_60",
    "doc_type": "slide",
    "is_definition": true,
    "contains_equation": true,
    "importance": "high",
    "tags": [
      "optimization"
    ]
  },
  {
    "text": "Per-parameter adaptive learning rate methods Adagrad Higher grads \u2192 lower lr RMSprop Moving average of squared grads Adam RMSProp + momentum Most recommended",
    "source": "ELEC/COMP 576: - Slide 61",
    "source_detail": "ELEC576-Lec05.pdf, Page 61",
    "lecture": "ELEC/COMP 576:",
    "lecture_number": "576",
    "page": 61,
    "content_type": "text",
    "doc_id": "slide_576_61",
    "doc_type": "slide",
    "is_definition": false,
    "contains_equation": false,
    "importance": "high",
    "tags": [
      "optimization"
    ]
  },
  {
    "text": "Compare Learning Methods http://cs231n.github.io/neural-networks-3/#sgd \u2022",
    "source": "ELEC/COMP 576: - Slide 62",
    "source_detail": "ELEC576-Lec05.pdf, Page 62",
    "lecture": "ELEC/COMP 576:",
    "lecture_number": "576",
    "page": 62,
    "content_type": "text",
    "doc_id": "slide_576_62",
    "doc_type": "slide",
    "is_definition": false,
    "contains_equation": true,
    "importance": "high",
    "tags": [
      "optimization"
    ]
  },
  {
    "text": "Annealing the Learning Rates",
    "source": "ELEC/COMP 576: - Slide 63",
    "source_detail": "ELEC576-Lec05.pdf, Page 63",
    "lecture": "ELEC/COMP 576:",
    "lecture_number": "576",
    "page": 63,
    "content_type": "text",
    "doc_id": "slide_576_63",
    "doc_type": "slide",
    "is_definition": false,
    "contains_equation": true,
    "importance": "high",
    "tags": [
      "optimization",
      "neural networks"
    ]
  },
  {
    "text": "In Practice Adam is the default choice in most cases \u2022 Instead, SGD variants based on (Nesterov\u2019s) \u2022 momentum are more standard than second-order methods because they are simpler and scale more easily. If you can afford to do full batch updates then try out \u2022 L-BFGS (Limited-memory version of Broyden\u2013 Fletcher\u2013Goldfarb\u2013Shanno (BFGS) algorithm). Don\u2019t forget to disable all sources of noise.",
    "source": "ELEC/COMP 576: - Slide 64",
    "source_detail": "ELEC576-Lec05.pdf, Page 64",
    "lecture": "ELEC/COMP 576:",
    "lecture_number": "576",
    "page": 64,
    "content_type": "text",
    "doc_id": "slide_576_64",
    "doc_type": "slide",
    "is_definition": false,
    "contains_equation": false,
    "importance": "high",
    "tags": [
      "optimization",
      "neural networks"
    ]
  },
  {
    "text": "Batch Normalization https://openreview.net/forum?id=rkxQ-nA9FX",
    "source": "ELEC/COMP 576: - Slide 75",
    "source_detail": "ELEC576-Lec05.pdf, Page 75",
    "lecture": "ELEC/COMP 576:",
    "lecture_number": "576",
    "page": 75,
    "content_type": "text",
    "doc_id": "slide_576_75",
    "doc_type": "slide",
    "is_definition": true,
    "contains_equation": true,
    "importance": "high",
    "tags": [
      "regularization"
    ]
  },
  {
    "text": "Model Ensembles Ensembles have another advantage -- estimating uncertainty or confidence in the prediction",
    "source": "ELEC/COMP 576: - Slide 77",
    "source_detail": "ELEC576-Lec05.pdf, Page 77",
    "lecture": "ELEC/COMP 576:",
    "lecture_number": "576",
    "page": 77,
    "content_type": "text",
    "doc_id": "slide_576_77",
    "doc_type": "slide",
    "is_definition": false,
    "contains_equation": false,
    "importance": "medium",
    "tags": [
      "confidence in prediction",
      "Model Ensembles",
      "uncertainty estimation"
    ]
  },
  {
    "text": "Hyperparameter Optimization",
    "source": "ELEC/COMP 576: - Slide 79",
    "source_detail": "ELEC576-Lec05.pdf, Page 79",
    "lecture": "ELEC/COMP 576:",
    "lecture_number": "576",
    "page": 79,
    "content_type": "text",
    "doc_id": "slide_576_79",
    "doc_type": "slide",
    "is_definition": true,
    "contains_equation": false,
    "importance": "high",
    "tags": [
      "optimization"
    ]
  },
  {
    "text": "Hyperparameter Optimization",
    "source": "ELEC/COMP 576: - Slide 80",
    "source_detail": "ELEC576-Lec05.pdf, Page 80",
    "lecture": "ELEC/COMP 576:",
    "lecture_number": "576",
    "page": 80,
    "content_type": "text",
    "doc_id": "slide_576_80",
    "doc_type": "slide",
    "is_definition": true,
    "contains_equation": false,
    "importance": "high",
    "tags": [
      "optimization"
    ]
  },
  {
    "text": "Hyperparameter Optimization",
    "source": "ELEC/COMP 576: - Slide 81",
    "source_detail": "ELEC576-Lec05.pdf, Page 81",
    "lecture": "ELEC/COMP 576:",
    "lecture_number": "576",
    "page": 81,
    "content_type": "text",
    "doc_id": "slide_576_81",
    "doc_type": "slide",
    "is_definition": true,
    "contains_equation": false,
    "importance": "high",
    "tags": [
      "optimization"
    ]
  },
  {
    "text": "Hyperparameter Optimization",
    "source": "ELEC/COMP 576: - Slide 82",
    "source_detail": "ELEC576-Lec05.pdf, Page 82",
    "lecture": "ELEC/COMP 576:",
    "lecture_number": "576",
    "page": 82,
    "content_type": "text",
    "doc_id": "slide_576_82",
    "doc_type": "slide",
    "is_definition": true,
    "contains_equation": false,
    "importance": "high",
    "tags": [
      "optimization"
    ]
  },
  {
    "text": "Hyperparameter Optimization",
    "source": "ELEC/COMP 576: - Slide 83",
    "source_detail": "ELEC576-Lec05.pdf, Page 83",
    "lecture": "ELEC/COMP 576:",
    "lecture_number": "576",
    "page": 83,
    "content_type": "text",
    "doc_id": "slide_576_83",
    "doc_type": "slide",
    "is_definition": true,
    "contains_equation": false,
    "importance": "high",
    "tags": [
      "optimization"
    ]
  },
  {
    "text": "Hyperparameter Optimization",
    "source": "ELEC/COMP 576: - Slide 84",
    "source_detail": "ELEC576-Lec05.pdf, Page 84",
    "lecture": "ELEC/COMP 576:",
    "lecture_number": "576",
    "page": 84,
    "content_type": "text",
    "doc_id": "slide_576_84",
    "doc_type": "slide",
    "is_definition": true,
    "contains_equation": false,
    "importance": "high",
    "tags": [
      "optimization"
    ]
  },
  {
    "text": "Monitoring the Learning Process",
    "source": "ELEC/COMP 576: - Slide 85",
    "source_detail": "ELEC576-Lec05.pdf, Page 85",
    "lecture": "ELEC/COMP 576:",
    "lecture_number": "576",
    "page": 85,
    "content_type": "text",
    "doc_id": "slide_576_85",
    "doc_type": "slide",
    "is_definition": false,
    "contains_equation": false,
    "importance": "medium",
    "tags": [
      "Assessment",
      "Monitoring",
      "Education",
      "Learning Process"
    ]
  },
  {
    "text": "Double-check that the Loss is Reasonable",
    "source": "ELEC/COMP 576: - Slide 86",
    "source_detail": "ELEC576-Lec05.pdf, Page 86",
    "lecture": "ELEC/COMP 576:",
    "lecture_number": "576",
    "page": 86,
    "content_type": "text",
    "doc_id": "slide_576_86",
    "doc_type": "slide",
    "is_definition": false,
    "contains_equation": false,
    "importance": "medium",
    "tags": [
      "loss functions"
    ]
  },
  {
    "text": "Double-check that the Loss is Reasonable",
    "source": "ELEC/COMP 576: - Slide 87",
    "source_detail": "ELEC576-Lec05.pdf, Page 87",
    "lecture": "ELEC/COMP 576:",
    "lecture_number": "576",
    "page": 87,
    "content_type": "text",
    "doc_id": "slide_576_87",
    "doc_type": "slide",
    "is_definition": false,
    "contains_equation": false,
    "importance": "medium",
    "tags": [
      "loss functions"
    ]
  },
  {
    "text": "Overfit Very Small Portion of the Training Data",
    "source": "ELEC/COMP 576: - Slide 88",
    "source_detail": "ELEC576-Lec05.pdf, Page 88",
    "lecture": "ELEC/COMP 576:",
    "lecture_number": "576",
    "page": 88,
    "content_type": "text",
    "doc_id": "slide_576_88",
    "doc_type": "slide",
    "is_definition": false,
    "contains_equation": false,
    "importance": "medium",
    "tags": [
      "training data",
      "machine learning",
      "overfitting"
    ]
  },
  {
    "text": "Different forms of train loss curve Typical training loss curve",
    "source": "ELEC/COMP 576: - Slide 93",
    "source_detail": "ELEC576-Lec05.pdf, Page 93",
    "lecture": "ELEC/COMP 576:",
    "lecture_number": "576",
    "page": 93,
    "content_type": "text",
    "doc_id": "slide_576_93",
    "doc_type": "slide",
    "is_definition": false,
    "contains_equation": false,
    "importance": "medium",
    "tags": [
      "loss functions"
    ]
  },
  {
    "text": "AlexNet Driven by maturity in: \u2022 Large Scale Labelled Datasets (Imagenet 1.2m images) \u2022 GPU computing \u2022 Improved training methods for deep networks Innovations: \u2022 Go Deep 5 Conv layers + 3 FC layer w/ 60M params \u2022 Train on Multiple GPUs (originally trained on 2 GTX 580s) \u2022 ReLU \u2022 DropOut \u2022 Data Augmentation ( ) resizing, random crops, random intensity shifts \u2022 Local Response Normalization",
    "source": "ELEC/COMP 576: - Slide 6",
    "source_detail": "ELEC576-Lec06.pdf, Page 6",
    "lecture": "ELEC/COMP 576:",
    "lecture_number": "576",
    "page": 6,
    "content_type": "figure",
    "doc_id": "slide_576_6",
    "doc_type": "slide",
    "is_definition": false,
    "contains_equation": false,
    "importance": "high",
    "tags": [
      "regularization",
      "cnn",
      "neural networks"
    ]
  },
  {
    "text": "AlexNet vs LeNet AlexNet LeNet",
    "source": "ELEC/COMP 576: - Slide 7",
    "source_detail": "ELEC576-Lec06.pdf, Page 7",
    "lecture": "ELEC/COMP 576:",
    "lecture_number": "576",
    "page": 7,
    "content_type": "text",
    "doc_id": "slide_576_7",
    "doc_type": "slide",
    "is_definition": false,
    "contains_equation": false,
    "importance": "medium",
    "tags": [
      "deep learning",
      "LeNet",
      "AlexNet",
      "neural networks"
    ]
  },
  {
    "text": "VGG Net Key Idea: \u2022 Very deep networks perform better \u2022 Stacking smaller filters is equivalent to one big filter \u2022 E.g. 2x 3x3 has an effective receptive field of one 5x5 with fewer parameters (How?) \u2022 VGG-16 (138M params) and VGG- 19 (144M params) most popular with 16 and 19-layers respectively",
    "source": "ELEC/COMP 576: - Slide 8",
    "source_detail": "ELEC576-Lec06.pdf, Page 8",
    "lecture": "ELEC/COMP 576:",
    "lecture_number": "576",
    "page": 8,
    "content_type": "text",
    "doc_id": "slide_576_8",
    "doc_type": "slide",
    "is_definition": false,
    "contains_equation": true,
    "importance": "high",
    "tags": [
      "VGG-19",
      "deep networks",
      "filters",
      "VGG-16",
      "VGG Net"
    ]
  },
  {
    "text": "GoogLenet Key Idea: \u2022 Wider not just deeper \u2022 Extract features at multiple scale \u2022 1x1 Conv (Dim. Reduction) \u2022 Auxiliary losses What happens if I don\u2019t use 1x1 conv?",
    "source": "ELEC/COMP 576: - Slide 9",
    "source_detail": "ELEC576-Lec06.pdf, Page 9",
    "lecture": "ELEC/COMP 576:",
    "lecture_number": "576",
    "page": 9,
    "content_type": "text",
    "doc_id": "slide_576_9",
    "doc_type": "slide",
    "is_definition": false,
    "contains_equation": false,
    "importance": "high",
    "tags": [
      "cnn",
      "loss functions"
    ]
  },
  {
    "text": "1x1 Conv Dimension Reduction One 1x1x3 filter * Y j,k = \u0dcd\ud835\udc4b \ud835\udc57, \ud835\udc58, \ud835\udc56 \u2299 \ud835\udc3e(1,1, \ud835\udc56) \ud835\udc56",
    "source": "ELEC/COMP 576: - Slide 10",
    "source_detail": "ELEC576-Lec06.pdf, Page 10",
    "lecture": "ELEC/COMP 576:",
    "lecture_number": "576",
    "page": 10,
    "content_type": "text",
    "doc_id": "slide_576_10",
    "doc_type": "slide",
    "is_definition": false,
    "contains_equation": true,
    "importance": "high",
    "tags": [
      "cnn"
    ]
  },
  {
    "text": "ResNet Key Idea: \u2022 Skip connections \u2013 allows forward and backward gradient flow even for small weights \u2022 Can make network deeper w/o vanishing gradient -- a problem when gradients are only multiplied \u2022 50 and 101 layer Resnets exist!",
    "source": "ELEC/COMP 576: - Slide 11",
    "source_detail": "ELEC576-Lec06.pdf, Page 11",
    "lecture": "ELEC/COMP 576:",
    "lecture_number": "576",
    "page": 11,
    "content_type": "text",
    "doc_id": "slide_576_11",
    "doc_type": "slide",
    "is_definition": false,
    "contains_equation": false,
    "importance": "high",
    "tags": [
      "neural networks"
    ]
  },
  {
    "text": "ResNet Output at each layer: Output at a deeper layer L: Gradient at layer l: First term ensures gradient isn\u2019t always zero He et al, \u201cIdentity Mappings in Deep Residual Networks\u201d, 2016",
    "source": "ELEC/COMP 576: - Slide 12",
    "source_detail": "ELEC576-Lec06.pdf, Page 12",
    "lecture": "ELEC/COMP 576:",
    "lecture_number": "576",
    "page": 12,
    "content_type": "text",
    "doc_id": "slide_576_12",
    "doc_type": "slide",
    "is_definition": false,
    "contains_equation": true,
    "importance": "high",
    "tags": [
      "Gradient",
      "ResNet",
      "Identity Mappings",
      "He et al",
      "Deep Residual Networks"
    ]
  },
  {
    "text": "Siamese Networks for Similarity Discrimination/Matching",
    "source": "ELEC/COMP 576: - Slide 14",
    "source_detail": "ELEC576-Lec06.pdf, Page 14",
    "lecture": "ELEC/COMP 576:",
    "lecture_number": "576",
    "page": 14,
    "content_type": "text",
    "doc_id": "slide_576_14",
    "doc_type": "slide",
    "is_definition": false,
    "contains_equation": false,
    "importance": "high",
    "tags": [
      "Similarity Discrimination",
      "Matching",
      "Siamese Networks"
    ]
  },
  {
    "text": "FaceNet \u2022 Labeled Faces in the Wild: No alignment: 98.87% \u00b1 0.15 With alignment: 99.63% \u00b1 0.09 \u2022 Youtube Faces DB: 95.12% \u00b1 0.39 (state-of-the-art) Embeddings can be used to cluster faces",
    "source": "ELEC/COMP 576: - Slide 21",
    "source_detail": "ELEC576-Lec06.pdf, Page 21",
    "lecture": "ELEC/COMP 576:",
    "lecture_number": "576",
    "page": 21,
    "content_type": "text",
    "doc_id": "slide_576_21",
    "doc_type": "slide",
    "is_definition": false,
    "contains_equation": false,
    "importance": "high",
    "tags": [
      "Labeled Faces in the Wild",
      "clustering",
      "FaceNet",
      "Youtube Faces DB",
      "face embeddings"
    ]
  },
  {
    "text": "How should the output layer look like for segmentation compared to a recognition model? Both assign discrete labels to data (Hint: it won\u2019t be a single 1D vector)",
    "source": "ELEC/COMP 576: - Slide 24",
    "source_detail": "ELEC576-Lec06.pdf, Page 24",
    "lecture": "ELEC/COMP 576:",
    "lecture_number": "576",
    "page": 24,
    "content_type": "text",
    "doc_id": "slide_576_24",
    "doc_type": "slide",
    "is_definition": false,
    "contains_equation": false,
    "importance": "medium",
    "tags": [
      "discrete labels",
      "1D vector",
      "segmentation model",
      "recognition model",
      "output layer"
    ]
  },
  {
    "text": "Fully Convolutional Networks for Semantic Segmentation [Jonathan Long, Evan Shelhamer, Yann LeCun]",
    "source": "ELEC/COMP 576: - Slide 25",
    "source_detail": "ELEC576-Lec06.pdf, Page 25",
    "lecture": "ELEC/COMP 576:",
    "lecture_number": "576",
    "page": 25,
    "content_type": "text",
    "doc_id": "slide_576_25",
    "doc_type": "slide",
    "is_definition": false,
    "contains_equation": true,
    "importance": "high",
    "tags": [
      "cnn",
      "neural networks"
    ]
  },
  {
    "text": "Fully Convolutional Networks for Semantic Segmentation Why not just upsample features at the last layer? [Jonathan Long, Evan Shelhamer, Yann LeCun]",
    "source": "ELEC/COMP 576: - Slide 26",
    "source_detail": "ELEC576-Lec06.pdf, Page 26",
    "lecture": "ELEC/COMP 576:",
    "lecture_number": "576",
    "page": 26,
    "content_type": "text",
    "doc_id": "slide_576_26",
    "doc_type": "slide",
    "is_definition": false,
    "contains_equation": false,
    "importance": "high",
    "tags": [
      "cnn",
      "neural networks"
    ]
  },
  {
    "text": "Fully Convolutional Networks for Semantic Segmentation Last layer is very low-res [Jonathan Long, Evan Shelhamer, Yann LeCun]",
    "source": "ELEC/COMP 576: - Slide 27",
    "source_detail": "ELEC576-Lec06.pdf, Page 27",
    "lecture": "ELEC/COMP 576:",
    "lecture_number": "576",
    "page": 27,
    "content_type": "text",
    "doc_id": "slide_576_27",
    "doc_type": "slide",
    "is_definition": false,
    "contains_equation": false,
    "importance": "high",
    "tags": [
      "cnn",
      "neural networks"
    ]
  },
  {
    "text": "Fully Convolutional Networks for Semantic Segmentation [Jonathan Long, Evan Shelhamer, Yann LeCun]",
    "source": "ELEC/COMP 576: - Slide 28",
    "source_detail": "ELEC576-Lec06.pdf, Page 28",
    "lecture": "ELEC/COMP 576:",
    "lecture_number": "576",
    "page": 28,
    "content_type": "text",
    "doc_id": "slide_576_28",
    "doc_type": "slide",
    "is_definition": false,
    "contains_equation": true,
    "importance": "high",
    "tags": [
      "cnn",
      "neural networks"
    ]
  },
  {
    "text": "U-Net: Convnet for Segmentation of Neuronal Structures in Electron Microscopic Stacks (Won the ISBI Cell Tracking Challenge 2015) Encoder has high- res structured data (edges/corners) Decoder has more high-level object concepts",
    "source": "ELEC/COMP 576: - Slide 29",
    "source_detail": "ELEC576-Lec06.pdf, Page 29",
    "lecture": "ELEC/COMP 576:",
    "lecture_number": "576",
    "page": 29,
    "content_type": "text",
    "doc_id": "slide_576_29",
    "doc_type": "slide",
    "is_definition": false,
    "contains_equation": false,
    "importance": "high",
    "tags": [
      "cnn"
    ]
  },
  {
    "text": "Stereo Matching Stereo Pair Disparity (or depth) Goal: For a given patch in left image, find where it is in the right image. The displacement of pixel coordinate (disparity) gives the depth",
    "source": "ELEC/COMP 576: - Slide 31",
    "source_detail": "ELEC576-Lec06.pdf, Page 31",
    "lecture": "ELEC/COMP 576:",
    "lecture_number": "576",
    "page": 31,
    "content_type": "figure",
    "doc_id": "slide_576_31",
    "doc_type": "slide",
    "is_definition": true,
    "contains_equation": false,
    "importance": "high",
    "tags": [
      "Disparity",
      "Image Processing",
      "Stereo Pair",
      "Depth",
      "Stereo Matching"
    ]
  },
  {
    "text": "Stereo Convnets [Jure Zbontar, Yann LeCun]",
    "source": "ELEC/COMP 576: - Slide 32",
    "source_detail": "ELEC576-Lec06.pdf, Page 32",
    "lecture": "ELEC/COMP 576:",
    "lecture_number": "576",
    "page": 32,
    "content_type": "text",
    "doc_id": "slide_576_32",
    "doc_type": "slide",
    "is_definition": false,
    "contains_equation": true,
    "importance": "high",
    "tags": [
      "cnn",
      "neural networks"
    ]
  },
  {
    "text": "WaveNet \u2022 Purpose was to learn a generative model over speech \u2022 Its auto-regressive in nature: predict the next sample in the sequence based on the past samples (P(x |x ,x t t-1 t- ,..x )) 2 1 \u2022 Can be conditioned to control the speech generation \u2013 conditioning with identity/pitch etc. \u2022 The key is dilated causal convolution",
    "source": "ELEC/COMP 576: - Slide 34",
    "source_detail": "ELEC576-Lec06.pdf, Page 34",
    "lecture": "ELEC/COMP 576:",
    "lecture_number": "576",
    "page": 34,
    "content_type": "text",
    "doc_id": "slide_576_34",
    "doc_type": "slide",
    "is_definition": true,
    "contains_equation": true,
    "importance": "high",
    "tags": [
      "cnn",
      "generative models"
    ]
  },
  {
    "text": "WaveNet Subjective preference scores (%) of speech samples",
    "source": "ELEC/COMP 576: - Slide 37",
    "source_detail": "ELEC576-Lec06.pdf, Page 37",
    "lecture": "ELEC/COMP 576:",
    "lecture_number": "576",
    "page": 37,
    "content_type": "text",
    "doc_id": "slide_576_37",
    "doc_type": "slide",
    "is_definition": false,
    "contains_equation": false,
    "importance": "medium",
    "tags": [
      "subjective preference scores",
      "speech samples",
      "WaveNet"
    ]
  },
  {
    "text": "Computer Aided Diagnosis in Medical Imaging",
    "source": "ELEC/COMP 576: - Slide 38",
    "source_detail": "ELEC576-Lec06.pdf, Page 38",
    "lecture": "ELEC/COMP 576:",
    "lecture_number": "576",
    "page": 38,
    "content_type": "text",
    "doc_id": "slide_576_38",
    "doc_type": "slide",
    "is_definition": false,
    "contains_equation": false,
    "importance": "high",
    "tags": [
      "Medical Imaging",
      "Computer Aided Diagnosis",
      "Healthcare Technology",
      "Radiology",
      "Artificial Intelligence"
    ]
  },
  {
    "text": "Convnet for Brain Tumor Segmentation (Top 4 in BRATS 2015)",
    "source": "ELEC/COMP 576: - Slide 39",
    "source_detail": "ELEC576-Lec06.pdf, Page 39",
    "lecture": "ELEC/COMP 576:",
    "lecture_number": "576",
    "page": 39,
    "content_type": "text",
    "doc_id": "slide_576_39",
    "doc_type": "slide",
    "is_definition": false,
    "contains_equation": false,
    "importance": "high",
    "tags": [
      "cnn"
    ]
  },
  {
    "text": "U-Net: Convnet for Segmentation of Neuronal Structures in Electron Microscopic Stacks (Won the ISBI Cell Tracking Challenge 2015)",
    "source": "ELEC/COMP 576: - Slide 40",
    "source_detail": "ELEC576-Lec06.pdf, Page 40",
    "lecture": "ELEC/COMP 576:",
    "lecture_number": "576",
    "page": 40,
    "content_type": "text",
    "doc_id": "slide_576_40",
    "doc_type": "slide",
    "is_definition": false,
    "contains_equation": false,
    "importance": "high",
    "tags": [
      "cnn"
    ]
  },
  {
    "text": "Unsupervised Learning",
    "source": "ELEC/COMP 576: - Slide 41",
    "source_detail": "ELEC576-Lec06.pdf, Page 41",
    "lecture": "ELEC/COMP 576:",
    "lecture_number": "576",
    "page": 41,
    "content_type": "text",
    "doc_id": "slide_576_41",
    "doc_type": "slide",
    "is_definition": true,
    "contains_equation": false,
    "importance": "high",
    "tags": [
      "Machine Learning",
      "Data Analysis",
      "Dimensionality Reduction",
      "Unsupervised Learning",
      "Clustering"
    ]
  },
  {
    "text": "Unsupervised feature learning with a neural network Autoencoder. x x 1 1 Network is trained to x x 2 2 output the input (learn a identify function). 1 x x 3 3 a 2 x x 4 4 a Trivial solution 3 x x 5 5 unless(why?): +1 - Constrain number of x x 6 6 units in Layer 2 (learn compressed Layer 2 Layer 3 +1 representation), or - Constrain Layer 2 to Layer 1 be sparse. Andrew Ng",
    "source": "ELEC/COMP 576: - Slide 42",
    "source_detail": "ELEC576-Lec06.pdf, Page 42",
    "lecture": "ELEC/COMP 576:",
    "lecture_number": "576",
    "page": 42,
    "content_type": "text",
    "doc_id": "slide_576_42",
    "doc_type": "slide",
    "is_definition": true,
    "contains_equation": true,
    "importance": "high",
    "tags": [
      "generative models",
      "neural networks"
    ]
  },
  {
    "text": "Unsupervised feature learning with a neural network Training a sparse autoencoder. a 1 a Given unlabeled training set x , x , \u2026 2 1 2 a 3 Reconstruction error L sparsity term 1 term Andrew Ng",
    "source": "ELEC/COMP 576: - Slide 43",
    "source_detail": "ELEC576-Lec06.pdf, Page 43",
    "lecture": "ELEC/COMP 576:",
    "lecture_number": "576",
    "page": 43,
    "content_type": "text",
    "doc_id": "slide_576_43",
    "doc_type": "slide",
    "is_definition": false,
    "contains_equation": true,
    "importance": "high",
    "tags": [
      "generative models",
      "neural networks"
    ]
  },
  {
    "text": "What happens if the latent dimension is the same as the input dimension?",
    "source": "ELEC/COMP 576: - Slide 44",
    "source_detail": "ELEC576-Lec06.pdf, Page 44",
    "lecture": "ELEC/COMP 576:",
    "lecture_number": "576",
    "page": 44,
    "content_type": "text",
    "doc_id": "slide_576_44",
    "doc_type": "slide",
    "is_definition": false,
    "contains_equation": false,
    "importance": "medium",
    "tags": [
      "dimensionality reduction",
      "input dimension",
      "latent dimension"
    ]
  },
  {
    "text": "What happens if the latent dimension is the same as the input dimension? Can learn identity mapping",
    "source": "ELEC/COMP 576: - Slide 45",
    "source_detail": "ELEC576-Lec06.pdf, Page 45",
    "lecture": "ELEC/COMP 576:",
    "lecture_number": "576",
    "page": 45,
    "content_type": "text",
    "doc_id": "slide_576_45",
    "doc_type": "slide",
    "is_definition": false,
    "contains_equation": false,
    "importance": "high",
    "tags": [
      "input dimension",
      "latent dimension",
      "identity mapping"
    ]
  },
  {
    "text": "Denoising Autoencoders \u2022 Loss is between reconstruction and clean input \u2022 Typically, additive Gaussian noise used \u2022 Assumption: latent representation is robust to nuisance \u2022 Latent representation: output of encoder",
    "source": "ELEC/COMP 576: - Slide 46",
    "source_detail": "ELEC576-Lec06.pdf, Page 46",
    "lecture": "ELEC/COMP 576:",
    "lecture_number": "576",
    "page": 46,
    "content_type": "text",
    "doc_id": "slide_576_46",
    "doc_type": "slide",
    "is_definition": true,
    "contains_equation": false,
    "importance": "high",
    "tags": [
      "generative models",
      "loss functions"
    ]
  },
  {
    "text": "Masked Autoencoders \u2022 Randomly mask-out patches in the image and predict the full image \u2022 Latent representation can be used for downstream task \u201cMasked Autoencoders Are Scalable Vision Learners\u201d, He at. al 2022",
    "source": "ELEC/COMP 576: - Slide 47",
    "source_detail": "ELEC576-Lec06.pdf, Page 47",
    "lecture": "ELEC/COMP 576:",
    "lecture_number": "576",
    "page": 47,
    "content_type": "figure",
    "doc_id": "slide_576_47",
    "doc_type": "slide",
    "is_definition": false,
    "contains_equation": false,
    "importance": "high",
    "tags": [
      "generative models"
    ]
  },
  {
    "text": "Masked Autoencoders Which strategy do you think is preferable?",
    "source": "ELEC/COMP 576: - Slide 48",
    "source_detail": "ELEC576-Lec06.pdf, Page 48",
    "lecture": "ELEC/COMP 576:",
    "lecture_number": "576",
    "page": 48,
    "content_type": "text",
    "doc_id": "slide_576_48",
    "doc_type": "slide",
    "is_definition": false,
    "contains_equation": false,
    "importance": "medium",
    "tags": [
      "generative models"
    ]
  },
  {
    "text": "Masked Autoencoders Which masking strategy is preferable? Grid sampling is too easy to decode -- representations quality is lower",
    "source": "ELEC/COMP 576: - Slide 49",
    "source_detail": "ELEC576-Lec06.pdf, Page 49",
    "lecture": "ELEC/COMP 576:",
    "lecture_number": "576",
    "page": 49,
    "content_type": "text",
    "doc_id": "slide_576_49",
    "doc_type": "slide",
    "is_definition": false,
    "contains_equation": false,
    "importance": "medium",
    "tags": [
      "generative models"
    ]
  },
  {
    "text": "Variational Autoencoder Problem with conventional autoencoder: No explanatory structure in the latent space",
    "source": "ELEC/COMP 576: - Slide 50",
    "source_detail": "ELEC576-Lec06.pdf, Page 50",
    "lecture": "ELEC/COMP 576:",
    "lecture_number": "576",
    "page": 50,
    "content_type": "text",
    "doc_id": "slide_576_50",
    "doc_type": "slide",
    "is_definition": false,
    "contains_equation": false,
    "importance": "high",
    "tags": [
      "cnn",
      "generative models"
    ]
  },
  {
    "text": "Variational Autoencoder \u2022 Learns a continuous latent space easy to sample from \u2022 Can generate new data by sampling from the learned generative model Key Idea: \u2022 x is generated by an underlying latent variable z but we can only observe x from the data \u2022 If I can model this process, I can generate novel x from z \u2022 Will do in two steps: (1) figure out how we can obtain z from x(p(z|x)) and then (2) decode z to generate novel x (p(x|z)) p(x,z): joint distribution, p(z): prior distribution on z, p(x|z): likelihood distribution, p(z|x): posterior distribution",
    "source": "ELEC/COMP 576: - Slide 51",
    "source_detail": "ELEC576-Lec06.pdf, Page 51",
    "lecture": "ELEC/COMP 576:",
    "lecture_number": "576",
    "page": 51,
    "content_type": "text",
    "doc_id": "slide_576_51",
    "doc_type": "slide",
    "is_definition": true,
    "contains_equation": true,
    "importance": "high",
    "tags": [
      "generative models"
    ]
  },
  {
    "text": "Variational Autoencoder",
    "source": "ELEC/COMP 576: - Slide 52",
    "source_detail": "ELEC576-Lec06.pdf, Page 52",
    "lecture": "ELEC/COMP 576:",
    "lecture_number": "576",
    "page": 52,
    "content_type": "text",
    "doc_id": "slide_576_52",
    "doc_type": "slide",
    "is_definition": true,
    "contains_equation": true,
    "importance": "high",
    "tags": [
      "generative models"
    ]
  },
  {
    "text": "Variational Autoencoder",
    "source": "ELEC/COMP 576: - Slide 53",
    "source_detail": "ELEC576-Lec06.pdf, Page 53",
    "lecture": "ELEC/COMP 576:",
    "lecture_number": "576",
    "page": 53,
    "content_type": "text",
    "doc_id": "slide_576_53",
    "doc_type": "slide",
    "is_definition": true,
    "contains_equation": false,
    "importance": "high",
    "tags": [
      "generative models"
    ]
  },
  {
    "text": "Inference/Learning Challenge",
    "source": "ELEC/COMP 576: - Slide 54",
    "source_detail": "ELEC576-Lec06.pdf, Page 54",
    "lecture": "ELEC/COMP 576:",
    "lecture_number": "576",
    "page": 54,
    "content_type": "text",
    "doc_id": "slide_576_54",
    "doc_type": "slide",
    "is_definition": false,
    "contains_equation": false,
    "importance": "medium",
    "tags": [
      "Learning",
      "Challenge",
      "Inference"
    ]
  },
  {
    "text": "Variational Autoencoder",
    "source": "ELEC/COMP 576: - Slide 55",
    "source_detail": "ELEC576-Lec06.pdf, Page 55",
    "lecture": "ELEC/COMP 576:",
    "lecture_number": "576",
    "page": 55,
    "content_type": "text",
    "doc_id": "slide_576_55",
    "doc_type": "slide",
    "is_definition": true,
    "contains_equation": true,
    "importance": "high",
    "tags": [
      "generative models"
    ]
  },
  {
    "text": "Variational Autoencoder \u2022 We assume prior p(z) is standard Normal (N(0,I)) \u2022 q(z|x) is also assumed to be Gaussian with diagonal covariance and its parameters generated by the encoder g(x) \u2022 We use neural network f(z) to map z to x and model p(x|z)",
    "source": "ELEC/COMP 576: - Slide 56",
    "source_detail": "ELEC576-Lec06.pdf, Page 56",
    "lecture": "ELEC/COMP 576:",
    "lecture_number": "576",
    "page": 56,
    "content_type": "text",
    "doc_id": "slide_576_56",
    "doc_type": "slide",
    "is_definition": false,
    "contains_equation": true,
    "importance": "high",
    "tags": [
      "generative models",
      "neural networks"
    ]
  },
  {
    "text": "Variational Autoencoder KL-Divergence b/w prior and approximate Data consistency term posterior This also has a closed-form expression assuming q(z|x) is Gaussian and p(z) is standard normal",
    "source": "ELEC/COMP 576: - Slide 57",
    "source_detail": "ELEC576-Lec06.pdf, Page 57",
    "lecture": "ELEC/COMP 576:",
    "lecture_number": "576",
    "page": 57,
    "content_type": "text",
    "doc_id": "slide_576_57",
    "doc_type": "slide",
    "is_definition": false,
    "contains_equation": true,
    "importance": "high",
    "tags": [
      "generative models"
    ]
  },
  {
    "text": "Variational Autoencoder \u2022 Encoder g(x) generates the parameters of approximate posterior. So, how do we backpropagate? \u2022 During training, generate a random sample (\u03f5) from standard normal N(0,I). Scale and shift to generate latent vector z: \u2022 This is the reparametrization trick and is differentiable \u2022 Use the z as input to the decoder to predict x",
    "source": "ELEC/COMP 576: - Slide 58",
    "source_detail": "ELEC576-Lec06.pdf, Page 58",
    "lecture": "ELEC/COMP 576:",
    "lecture_number": "576",
    "page": 58,
    "content_type": "text",
    "doc_id": "slide_576_58",
    "doc_type": "slide",
    "is_definition": false,
    "contains_equation": true,
    "importance": "high",
    "tags": [
      "backpropagation",
      "generative models"
    ]
  },
  {
    "text": "Variational Autoencoder",
    "source": "ELEC/COMP 576: - Slide 59",
    "source_detail": "ELEC576-Lec06.pdf, Page 59",
    "lecture": "ELEC/COMP 576:",
    "lecture_number": "576",
    "page": 59,
    "content_type": "text",
    "doc_id": "slide_576_59",
    "doc_type": "slide",
    "is_definition": true,
    "contains_equation": true,
    "importance": "high",
    "tags": [
      "generative models"
    ]
  },
  {
    "text": "What do you think are the drawbacks of VAE?",
    "source": "ELEC/COMP 576: - Slide 60",
    "source_detail": "ELEC576-Lec06.pdf, Page 60",
    "lecture": "ELEC/COMP 576:",
    "lecture_number": "576",
    "page": 60,
    "content_type": "text",
    "doc_id": "slide_576_60",
    "doc_type": "slide",
    "is_definition": false,
    "contains_equation": false,
    "importance": "medium",
    "tags": [
      "generative models"
    ]
  },
  {
    "text": "Generative Adversarial Networks (GAN) \u2022 VAEs are generative and learn explicit distribution \u2013 with strong assumptions \u2022 Also, VAEs lead to blurry generated samples GANs overcome this challenge \u2013 no explicit distribution predicted",
    "source": "ELEC/COMP 576: - Slide 61",
    "source_detail": "ELEC576-Lec06.pdf, Page 61",
    "lecture": "ELEC/COMP 576:",
    "lecture_number": "576",
    "page": 61,
    "content_type": "text",
    "doc_id": "slide_576_61",
    "doc_type": "slide",
    "is_definition": true,
    "contains_equation": false,
    "importance": "high",
    "tags": [
      "generative models"
    ]
  },
  {
    "text": "Generative Adversarial Networks (GAN)",
    "source": "ELEC/COMP 576: - Slide 62",
    "source_detail": "ELEC576-Lec06.pdf, Page 62",
    "lecture": "ELEC/COMP 576:",
    "lecture_number": "576",
    "page": 62,
    "content_type": "text",
    "doc_id": "slide_576_62",
    "doc_type": "slide",
    "is_definition": true,
    "contains_equation": false,
    "importance": "high",
    "tags": [
      "generative models"
    ]
  },
  {
    "text": "Zero-Sum Game Objective",
    "source": "ELEC/COMP 576: - Slide 63",
    "source_detail": "ELEC576-Lec06.pdf, Page 63",
    "lecture": "ELEC/COMP 576:",
    "lecture_number": "576",
    "page": 63,
    "content_type": "text",
    "doc_id": "slide_576_63",
    "doc_type": "slide",
    "is_definition": false,
    "contains_equation": false,
    "importance": "high",
    "tags": [
      "Objective",
      "Game Theory",
      "Zero-Sum Game"
    ]
  },
  {
    "text": "Zero-Sum Game Objective",
    "source": "ELEC/COMP 576: - Slide 64",
    "source_detail": "ELEC576-Lec06.pdf, Page 64",
    "lecture": "ELEC/COMP 576:",
    "lecture_number": "576",
    "page": 64,
    "content_type": "text",
    "doc_id": "slide_576_64",
    "doc_type": "slide",
    "is_definition": true,
    "contains_equation": false,
    "importance": "high",
    "tags": [
      "Objective",
      "Game Theory",
      "Zero-Sum Game"
    ]
  },
  {
    "text": "GAN Training Cycle Discriminator training \u2022 The discriminator is shown a batch of real images from the dataset and trained to classify them as \"real\" (outputting 1). \u2022 It's also shown a batch of fake images produced by the generator and trained to classify them as \"fake\" (outputting 0). \u2022 The discriminator's weights are updated to improve its ability to distinguish real from fake.",
    "source": "ELEC/COMP 576: - Slide 65",
    "source_detail": "ELEC576-Lec06.pdf, Page 65",
    "lecture": "ELEC/COMP 576:",
    "lecture_number": "576",
    "page": 65,
    "content_type": "figure",
    "doc_id": "slide_576_65",
    "doc_type": "slide",
    "is_definition": false,
    "contains_equation": false,
    "importance": "high",
    "tags": [
      "generative models"
    ]
  },
  {
    "text": "GAN Training Cycle Generator training \u2022 The generator produces a batch of fake images. \u2022 These fake images are fed into the discriminator. \u2022 The generator receives feedback on how well its fakes fooled the discriminator. \u2022 Its weights are then updated to generate even more realistic data, aiming to trick the discriminator.",
    "source": "ELEC/COMP 576: - Slide 66",
    "source_detail": "ELEC576-Lec06.pdf, Page 66",
    "lecture": "ELEC/COMP 576:",
    "lecture_number": "576",
    "page": 66,
    "content_type": "figure",
    "doc_id": "slide_576_66",
    "doc_type": "slide",
    "is_definition": true,
    "contains_equation": false,
    "importance": "high",
    "tags": [
      "generative models"
    ]
  },
  {
    "text": "Visualization of Model Samples",
    "source": "ELEC/COMP 576: - Slide 67",
    "source_detail": "ELEC576-Lec06.pdf, Page 67",
    "lecture": "ELEC/COMP 576:",
    "lecture_number": "576",
    "page": 67,
    "content_type": "text",
    "doc_id": "slide_576_67",
    "doc_type": "slide",
    "is_definition": false,
    "contains_equation": false,
    "importance": "medium",
    "tags": [
      "Visualization",
      "Model",
      "Samples"
    ]
  },
  {
    "text": "Can you precisely control what sample you generate from a GAN? For example: While generating faces, generate ones for a certain identity?",
    "source": "ELEC/COMP 576: - Slide 68",
    "source_detail": "ELEC576-Lec06.pdf, Page 68",
    "lecture": "ELEC/COMP 576:",
    "lecture_number": "576",
    "page": 68,
    "content_type": "text",
    "doc_id": "slide_576_68",
    "doc_type": "slide",
    "is_definition": false,
    "contains_equation": false,
    "importance": "high",
    "tags": [
      "generative models"
    ]
  },
  {
    "text": "Can you precisely control what sample you generate from a GAN? No. Input is random noise",
    "source": "ELEC/COMP 576: - Slide 69",
    "source_detail": "ELEC576-Lec06.pdf, Page 69",
    "lecture": "ELEC/COMP 576:",
    "lecture_number": "576",
    "page": 69,
    "content_type": "text",
    "doc_id": "slide_576_69",
    "doc_type": "slide",
    "is_definition": false,
    "contains_equation": false,
    "importance": "high",
    "tags": [
      "generative models"
    ]
  },
  {
    "text": "Pix2Pix Conditional GAN Image-Image translation using conditional GAN",
    "source": "ELEC/COMP 576: - Slide 70",
    "source_detail": "ELEC576-Lec06.pdf, Page 70",
    "lecture": "ELEC/COMP 576:",
    "lecture_number": "576",
    "page": 70,
    "content_type": "figure",
    "doc_id": "slide_576_70",
    "doc_type": "slide",
    "is_definition": false,
    "contains_equation": false,
    "importance": "high",
    "tags": [
      "generative models"
    ]
  },
  {
    "text": "Pix2Pix Conditional GAN Choice of generator",
    "source": "ELEC/COMP 576: - Slide 71",
    "source_detail": "ELEC576-Lec06.pdf, Page 71",
    "lecture": "ELEC/COMP 576:",
    "lecture_number": "576",
    "page": 71,
    "content_type": "text",
    "doc_id": "slide_576_71",
    "doc_type": "slide",
    "is_definition": false,
    "contains_equation": false,
    "importance": "high",
    "tags": [
      "generative models"
    ]
  },
  {
    "text": "Pix2Pix Conditional GAN What happens if we don\u2019t use the L1 loss?",
    "source": "ELEC/COMP 576: - Slide 72",
    "source_detail": "ELEC576-Lec06.pdf, Page 72",
    "lecture": "ELEC/COMP 576:",
    "lecture_number": "576",
    "page": 72,
    "content_type": "text",
    "doc_id": "slide_576_72",
    "doc_type": "slide",
    "is_definition": false,
    "contains_equation": true,
    "importance": "high",
    "tags": [
      "regularization",
      "generative models",
      "loss functions"
    ]
  },
  {
    "text": "Pix2Pix Conditional GAN What happens if we don\u2019t use the L1 loss?",
    "source": "ELEC/COMP 576: - Slide 73",
    "source_detail": "ELEC576-Lec06.pdf, Page 73",
    "lecture": "ELEC/COMP 576:",
    "lecture_number": "576",
    "page": 73,
    "content_type": "text",
    "doc_id": "slide_576_73",
    "doc_type": "slide",
    "is_definition": false,
    "contains_equation": true,
    "importance": "high",
    "tags": [
      "regularization",
      "generative models",
      "loss functions"
    ]
  },
  {
    "text": "Understand & Visualizing Convnets",
    "source": "ELEC/COMP 576: - Slide 2",
    "source_detail": "ELEC576-Lec07-1.pdf, Page 2",
    "lecture": "ELEC/COMP 576:",
    "lecture_number": "576",
    "page": 2,
    "content_type": "text",
    "doc_id": "slide_576_2",
    "doc_type": "slide",
    "is_definition": false,
    "contains_equation": false,
    "importance": "high",
    "tags": [
      "cnn"
    ]
  },
  {
    "text": "Deconvolutional Net [Zeiler and Fergus]",
    "source": "ELEC/COMP 576: - Slide 3",
    "source_detail": "ELEC576-Lec07-1.pdf, Page 3",
    "lecture": "ELEC/COMP 576:",
    "lecture_number": "576",
    "page": 3,
    "content_type": "text",
    "doc_id": "slide_576_3",
    "doc_type": "slide",
    "is_definition": true,
    "contains_equation": false,
    "importance": "high",
    "tags": [
      "cnn"
    ]
  },
  {
    "text": "Feature Visualization [Zeiler and Fergus]",
    "source": "ELEC/COMP 576: - Slide 4",
    "source_detail": "ELEC576-Lec07-1.pdf, Page 4",
    "lecture": "ELEC/COMP 576:",
    "lecture_number": "576",
    "page": 4,
    "content_type": "text",
    "doc_id": "slide_576_4",
    "doc_type": "slide",
    "is_definition": false,
    "contains_equation": false,
    "importance": "high",
    "tags": [
      "Fergus",
      "Zeiler",
      "Feature Visualization"
    ]
  },
  {
    "text": "Feature Visualization [Zeiler and Fergus]",
    "source": "ELEC/COMP 576: - Slide 5",
    "source_detail": "ELEC576-Lec07-1.pdf, Page 5",
    "lecture": "ELEC/COMP 576:",
    "lecture_number": "576",
    "page": 5,
    "content_type": "text",
    "doc_id": "slide_576_5",
    "doc_type": "slide",
    "is_definition": false,
    "contains_equation": false,
    "importance": "high",
    "tags": [
      "Fergus",
      "Zeiler",
      "Feature Visualization"
    ]
  },
  {
    "text": "Feature Visualization [Zeiler and Fergus]",
    "source": "ELEC/COMP 576: - Slide 6",
    "source_detail": "ELEC576-Lec07-1.pdf, Page 6",
    "lecture": "ELEC/COMP 576:",
    "lecture_number": "576",
    "page": 6,
    "content_type": "text",
    "doc_id": "slide_576_6",
    "doc_type": "slide",
    "is_definition": false,
    "contains_equation": false,
    "importance": "high",
    "tags": [
      "Fergus",
      "Zeiler",
      "Feature Visualization"
    ]
  },
  {
    "text": "Feature Visualization [Zeiler and Fergus]",
    "source": "ELEC/COMP 576: - Slide 7",
    "source_detail": "ELEC576-Lec07-1.pdf, Page 7",
    "lecture": "ELEC/COMP 576:",
    "lecture_number": "576",
    "page": 7,
    "content_type": "text",
    "doc_id": "slide_576_7",
    "doc_type": "slide",
    "is_definition": false,
    "contains_equation": false,
    "importance": "high",
    "tags": [
      "Fergus",
      "Zeiler",
      "Feature Visualization"
    ]
  },
  {
    "text": "Feature Visualization [Zeiler and Fergus]",
    "source": "ELEC/COMP 576: - Slide 8",
    "source_detail": "ELEC576-Lec07-1.pdf, Page 8",
    "lecture": "ELEC/COMP 576:",
    "lecture_number": "576",
    "page": 8,
    "content_type": "text",
    "doc_id": "slide_576_8",
    "doc_type": "slide",
    "is_definition": false,
    "contains_equation": false,
    "importance": "high",
    "tags": [
      "Fergus",
      "Zeiler",
      "Feature Visualization"
    ]
  },
  {
    "text": "Activity Maximization (aka Saliency Maps) [Simonyan et al.]",
    "source": "ELEC/COMP 576: - Slide 9",
    "source_detail": "ELEC576-Lec07-1.pdf, Page 9",
    "lecture": "ELEC/COMP 576:",
    "lecture_number": "576",
    "page": 9,
    "content_type": "text",
    "doc_id": "slide_576_9",
    "doc_type": "slide",
    "is_definition": false,
    "contains_equation": false,
    "importance": "high",
    "tags": [
      "Simonyan",
      "Activity Maximization",
      "Saliency Maps"
    ]
  },
  {
    "text": "Deep Dream Visualization",
    "source": "ELEC/COMP 576: - Slide 10",
    "source_detail": "ELEC576-Lec07-1.pdf, Page 10",
    "lecture": "ELEC/COMP 576:",
    "lecture_number": "576",
    "page": 10,
    "content_type": "text",
    "doc_id": "slide_576_10",
    "doc_type": "slide",
    "is_definition": false,
    "contains_equation": false,
    "importance": "medium",
    "tags": [
      "Visualization",
      "Image Processing",
      "Neural Networks",
      "Artificial Intelligence",
      "Deep Dream"
    ]
  },
  {
    "text": "Deep Dream Visualization To produce human viewable images, need to \u2022 Activity maximization (gradient ascent) \u2022 L2 regularization \u2022 Gaussian blur \u2022 Clipping \u2022 Multiple scales (octaves) \u2022 Code: https://github.com/google/deepdream/blob/ \u2022 master/dream.ipynb",
    "source": "ELEC/COMP 576: - Slide 11",
    "source_detail": "ELEC576-Lec07-1.pdf, Page 11",
    "lecture": "ELEC/COMP 576:",
    "lecture_number": "576",
    "page": 11,
    "content_type": "figure",
    "doc_id": "slide_576_11",
    "doc_type": "slide",
    "is_definition": false,
    "contains_equation": true,
    "importance": "high",
    "tags": [
      "regularization"
    ]
  },
  {
    "text": "Example Image [Inceptionism Gallery]",
    "source": "ELEC/COMP 576: - Slide 12",
    "source_detail": "ELEC576-Lec07-1.pdf, Page 12",
    "lecture": "ELEC/COMP 576:",
    "lecture_number": "576",
    "page": 12,
    "content_type": "figure",
    "doc_id": "slide_576_12",
    "doc_type": "slide",
    "is_definition": false,
    "contains_equation": false,
    "importance": "low",
    "tags": [
      "Image",
      "Inceptionism",
      "Gallery"
    ]
  },
  {
    "text": "Dumbbell Deep Dream AlexNet VGGNet GoogleNet",
    "source": "ELEC/COMP 576: - Slide 13",
    "source_detail": "ELEC576-Lec07-1.pdf, Page 13",
    "lecture": "ELEC/COMP 576:",
    "lecture_number": "576",
    "page": 13,
    "content_type": "text",
    "doc_id": "slide_576_13",
    "doc_type": "slide",
    "is_definition": false,
    "contains_equation": false,
    "importance": "high",
    "tags": [
      "GoogleNet",
      "Dumbbell",
      "VGGNet",
      "Deep Dream",
      "AlexNet"
    ]
  },
  {
    "text": "Deep Dream Video Class: goldfish, Carassius auratus",
    "source": "ELEC/COMP 576: - Slide 14",
    "source_detail": "ELEC576-Lec07-1.pdf, Page 14",
    "lecture": "ELEC/COMP 576:",
    "lecture_number": "576",
    "page": 14,
    "content_type": "text",
    "doc_id": "slide_576_14",
    "doc_type": "slide",
    "is_definition": false,
    "contains_equation": false,
    "importance": "low",
    "tags": [
      "Video Class",
      "Carassius auratus",
      "goldfish",
      "Deep Dream"
    ]
  },
  {
    "text": "Infinite Zoom-In on Deep Dream https://www.youtube.com/watch?v=SCE-QeDfXtA",
    "source": "ELEC/COMP 576: - Slide 15",
    "source_detail": "ELEC576-Lec07-1.pdf, Page 15",
    "lecture": "ELEC/COMP 576:",
    "lecture_number": "576",
    "page": 15,
    "content_type": "text",
    "doc_id": "slide_576_15",
    "doc_type": "slide",
    "is_definition": false,
    "contains_equation": false,
    "importance": "medium",
    "tags": [
      "YouTube",
      "AI Art",
      "Visual Effects",
      "Deep Dream",
      "Infinite Zoom-In"
    ]
  },
  {
    "text": "Texture Synthesis [Leon Gatys, Alexander Ecker, Matthias Bethge]",
    "source": "ELEC/COMP 576: - Slide 16",
    "source_detail": "ELEC576-Lec07-1.pdf, Page 16",
    "lecture": "ELEC/COMP 576:",
    "lecture_number": "576",
    "page": 16,
    "content_type": "text",
    "doc_id": "slide_576_16",
    "doc_type": "slide",
    "is_definition": false,
    "contains_equation": true,
    "importance": "high",
    "tags": [
      "Alexander Ecker",
      "Matthias Bethge",
      "Texture Synthesis",
      "Leon Gatys"
    ]
  },
  {
    "text": "Generated Textures [Leon Gatys, Alexander Ecker, Matthias Bethge]",
    "source": "ELEC/COMP 576: - Slide 17",
    "source_detail": "ELEC576-Lec07-1.pdf, Page 17",
    "lecture": "ELEC/COMP 576:",
    "lecture_number": "576",
    "page": 17,
    "content_type": "text",
    "doc_id": "slide_576_17",
    "doc_type": "slide",
    "is_definition": false,
    "contains_equation": true,
    "importance": "high",
    "tags": [
      "Alexander Ecker",
      "Matthias Bethge",
      "Leon Gatys",
      "Generated Textures"
    ]
  },
  {
    "text": "DeepStyle Examples [Leon Gatys, Alexander Ecker, Matthias Bethge]",
    "source": "ELEC/COMP 576: - Slide 18",
    "source_detail": "ELEC576-Lec07-1.pdf, Page 18",
    "lecture": "ELEC/COMP 576:",
    "lecture_number": "576",
    "page": 18,
    "content_type": "text",
    "doc_id": "slide_576_18",
    "doc_type": "slide",
    "is_definition": false,
    "contains_equation": true,
    "importance": "high",
    "tags": [
      "Alexander Ecker",
      "Matthias Bethge",
      "DeepStyle",
      "examples",
      "Leon Gatys"
    ]
  },
  {
    "text": "DeepStyle: Combining Style + Content from Distinct Images [Leon Gatys, Alexander Ecker, Matthias Bethge]",
    "source": "ELEC/COMP 576: - Slide 19",
    "source_detail": "ELEC576-Lec07-1.pdf, Page 19",
    "lecture": "ELEC/COMP 576:",
    "lecture_number": "576",
    "page": 19,
    "content_type": "figure",
    "doc_id": "slide_576_19",
    "doc_type": "slide",
    "is_definition": false,
    "contains_equation": true,
    "importance": "high",
    "tags": [
      "Style Transfer",
      "Matthias Bethge",
      "DeepStyle",
      "Image Processing",
      "Leon Gatys"
    ]
  },
  {
    "text": "Introduction to Recurrent Neural Networks",
    "source": "ELEC/COMP 576: - Slide 20",
    "source_detail": "ELEC576-Lec07-1.pdf, Page 20",
    "lecture": "ELEC/COMP 576:",
    "lecture_number": "576",
    "page": 20,
    "content_type": "text",
    "doc_id": "slide_576_20",
    "doc_type": "slide",
    "is_definition": true,
    "contains_equation": false,
    "importance": "high",
    "tags": [
      "rnn",
      "neural networks"
    ]
  },
  {
    "text": "What Are Recurrent Neural Networks? Recurrent Neural Networks (RNNs) are networks \u2022 that have feedback Output is feed back to the input \u2022 Sequence processing \u2022 Ideal for time-series data or sequential data \u2022",
    "source": "ELEC/COMP 576: - Slide 21",
    "source_detail": "ELEC576-Lec07-1.pdf, Page 21",
    "lecture": "ELEC/COMP 576:",
    "lecture_number": "576",
    "page": 21,
    "content_type": "text",
    "doc_id": "slide_576_21",
    "doc_type": "slide",
    "is_definition": true,
    "contains_equation": false,
    "importance": "high",
    "tags": [
      "rnn",
      "neural networks"
    ]
  },
  {
    "text": "Important RNN Architectures Hopfield Network \u2022 Jordan and Elman Networks \u2022 Echo State Networks \u2022 Long Short Term Memory (LSTM) \u2022 Bi-Directional RNN \u2022 Gated Recurrent Unit (GRU) \u2022 Neural Turing Machine \u2022",
    "source": "ELEC/COMP 576: - Slide 23",
    "source_detail": "ELEC576-Lec07-1.pdf, Page 23",
    "lecture": "ELEC/COMP 576:",
    "lecture_number": "576",
    "page": 23,
    "content_type": "text",
    "doc_id": "slide_576_23",
    "doc_type": "slide",
    "is_definition": false,
    "contains_equation": false,
    "importance": "high",
    "tags": [
      "rnn",
      "neural networks"
    ]
  },
  {
    "text": "Hopfield Network [Wikipedia]",
    "source": "ELEC/COMP 576: - Slide 24",
    "source_detail": "ELEC576-Lec07-1.pdf, Page 24",
    "lecture": "ELEC/COMP 576:",
    "lecture_number": "576",
    "page": 24,
    "content_type": "text",
    "doc_id": "slide_576_24",
    "doc_type": "slide",
    "is_definition": true,
    "contains_equation": true,
    "importance": "high",
    "tags": [
      "associative memory",
      "pattern recognition",
      "Hopfield Network",
      "neural networks",
      "energy function"
    ]
  },
  {
    "text": "Elman Networks [John McCullock]",
    "source": "ELEC/COMP 576: - Slide 25",
    "source_detail": "ELEC576-Lec07-1.pdf, Page 25",
    "lecture": "ELEC/COMP 576:",
    "lecture_number": "576",
    "page": 25,
    "content_type": "text",
    "doc_id": "slide_576_25",
    "doc_type": "slide",
    "is_definition": false,
    "contains_equation": false,
    "importance": "high",
    "tags": [
      "John McCullock",
      "Elman Networks",
      "neural networks"
    ]
  },
  {
    "text": "Echo State Networks [Herbert Jaeger]",
    "source": "ELEC/COMP 576: - Slide 26",
    "source_detail": "ELEC576-Lec07-1.pdf, Page 26",
    "lecture": "ELEC/COMP 576:",
    "lecture_number": "576",
    "page": 26,
    "content_type": "text",
    "doc_id": "slide_576_26",
    "doc_type": "slide",
    "is_definition": false,
    "contains_equation": true,
    "importance": "high",
    "tags": [
      "Herbert Jaeger",
      "Echo State Networks",
      "dynamical systems",
      "machine learning",
      "neural networks"
    ]
  },
  {
    "text": "RNN Formulation [Richard Socher]",
    "source": "ELEC/COMP 576: - Slide 28",
    "source_detail": "ELEC576-Lec07-1.pdf, Page 28",
    "lecture": "ELEC/COMP 576:",
    "lecture_number": "576",
    "page": 28,
    "content_type": "text",
    "doc_id": "slide_576_28",
    "doc_type": "slide",
    "is_definition": false,
    "contains_equation": true,
    "importance": "high",
    "tags": [
      "rnn",
      "neural networks"
    ]
  },
  {
    "text": "RNN Diagram Unrolled into FF NN [Richard Socher]",
    "source": "ELEC/COMP 576: - Slide 29",
    "source_detail": "ELEC576-Lec07-1.pdf, Page 29",
    "lecture": "ELEC/COMP 576:",
    "lecture_number": "576",
    "page": 29,
    "content_type": "figure",
    "doc_id": "slide_576_29",
    "doc_type": "slide",
    "is_definition": false,
    "contains_equation": true,
    "importance": "high",
    "tags": [
      "rnn",
      "neural networks"
    ]
  },
  {
    "text": "RNN Example [Andrej Karpathy]",
    "source": "ELEC/COMP 576: - Slide 30",
    "source_detail": "ELEC576-Lec07-1.pdf, Page 30",
    "lecture": "ELEC/COMP 576:",
    "lecture_number": "576",
    "page": 30,
    "content_type": "text",
    "doc_id": "slide_576_30",
    "doc_type": "slide",
    "is_definition": false,
    "contains_equation": true,
    "importance": "high",
    "tags": [
      "rnn",
      "neural networks"
    ]
  },
  {
    "text": "Different Inference Tasks \u2014> Different RNN Architectures [Kevin Murphy]",
    "source": "ELEC/COMP 576: - Slide 31",
    "source_detail": "ELEC576-Lec07-1.pdf, Page 31",
    "lecture": "ELEC/COMP 576:",
    "lecture_number": "576",
    "page": 31,
    "content_type": "text",
    "doc_id": "slide_576_31",
    "doc_type": "slide",
    "is_definition": false,
    "contains_equation": false,
    "importance": "high",
    "tags": [
      "rnn",
      "neural networks"
    ]
  },
  {
    "text": "Different Structures for Filtering/Prediction Tasks [Andrej Karpathy] Object Image Action Machine Object Recognition Captioning Recognition Translation Tracking",
    "source": "ELEC/COMP 576: - Slide 32",
    "source_detail": "ELEC576-Lec07-1.pdf, Page 32",
    "lecture": "ELEC/COMP 576:",
    "lecture_number": "576",
    "page": 32,
    "content_type": "figure",
    "doc_id": "slide_576_32",
    "doc_type": "slide",
    "is_definition": false,
    "contains_equation": false,
    "importance": "high",
    "tags": [
      "Filtering",
      "Image Captioning",
      "Action Tracking",
      "Prediction Tasks",
      "Object Recognition"
    ]
  },
  {
    "text": "Universal Expressive Power Results [John Bullinaria]",
    "source": "ELEC/COMP 576: - Slide 33",
    "source_detail": "ELEC576-Lec07-1.pdf, Page 33",
    "lecture": "ELEC/COMP 576:",
    "lecture_number": "576",
    "page": 33,
    "content_type": "text",
    "doc_id": "slide_576_33",
    "doc_type": "slide",
    "is_definition": false,
    "contains_equation": true,
    "importance": "high",
    "tags": [
      "Results",
      "Universal Expressive Power",
      "John Bullinaria"
    ]
  },
  {
    "text": "Training an RNN Use back propagation through time (BPTT) \u2022 [Denny Britz]",
    "source": "ELEC/COMP 576: - Slide 35",
    "source_detail": "ELEC576-Lec07-1.pdf, Page 35",
    "lecture": "ELEC/COMP 576:",
    "lecture_number": "576",
    "page": 35,
    "content_type": "text",
    "doc_id": "slide_576_35",
    "doc_type": "slide",
    "is_definition": false,
    "contains_equation": true,
    "importance": "high",
    "tags": [
      "rnn",
      "neural networks"
    ]
  },
  {
    "text": "Back Propagation through Time [Denny Britz]",
    "source": "ELEC/COMP 576: - Slide 36",
    "source_detail": "ELEC576-Lec07-1.pdf, Page 36",
    "lecture": "ELEC/COMP 576:",
    "lecture_number": "576",
    "page": 36,
    "content_type": "text",
    "doc_id": "slide_576_36",
    "doc_type": "slide",
    "is_definition": false,
    "contains_equation": true,
    "importance": "high",
    "tags": [
      "neural networks"
    ]
  },
  {
    "text": "RNN Training Issues Exploding/Vanishing gradients \u2022 Exploding/Vanishing activations \u2022",
    "source": "ELEC/COMP 576: - Slide 37",
    "source_detail": "ELEC576-Lec07-1.pdf, Page 37",
    "lecture": "ELEC/COMP 576:",
    "lecture_number": "576",
    "page": 37,
    "content_type": "text",
    "doc_id": "slide_576_37",
    "doc_type": "slide",
    "is_definition": true,
    "contains_equation": false,
    "importance": "high",
    "tags": [
      "rnn",
      "neural networks"
    ]
  },
  {
    "text": "Exploding Gradients Solution: Gradient Clipping [Richard Socher] http://www.jmlr.org/proceedings/papers/v28/pascanu13.pdf",
    "source": "ELEC/COMP 576: - Slide 38",
    "source_detail": "ELEC576-Lec07-1.pdf, Page 38",
    "lecture": "ELEC/COMP 576:",
    "lecture_number": "576",
    "page": 38,
    "content_type": "text",
    "doc_id": "slide_576_38",
    "doc_type": "slide",
    "is_definition": false,
    "contains_equation": true,
    "importance": "high",
    "tags": [
      "Gradient Clipping",
      "Richard Socher",
      "Machine Learning",
      "Neural Networks",
      "Exploding Gradients"
    ]
  },
  {
    "text": "Vanishing Gradients/ Activations [Hochreiter, Schmidhuber]",
    "source": "ELEC/COMP 576: - Slide 39",
    "source_detail": "ELEC576-Lec07-1.pdf, Page 39",
    "lecture": "ELEC/COMP 576:",
    "lecture_number": "576",
    "page": 39,
    "content_type": "text",
    "doc_id": "slide_576_39",
    "doc_type": "slide",
    "is_definition": false,
    "contains_equation": false,
    "importance": "high",
    "tags": [
      "neural networks"
    ]
  },
  {
    "text": "Why Training is Unstable Variance of activations/gradients grows multiplicatively [Xu, Huang, Li]",
    "source": "ELEC/COMP 576: - Slide 40",
    "source_detail": "ELEC576-Lec07-1.pdf, Page 40",
    "lecture": "ELEC/COMP 576:",
    "lecture_number": "576",
    "page": 40,
    "content_type": "text",
    "doc_id": "slide_576_40",
    "doc_type": "slide",
    "is_definition": false,
    "contains_equation": true,
    "importance": "high",
    "tags": [
      "neural networks"
    ]
  },
  {
    "text": "Interesting Question Are there modifications to an RNN such that it can \u2022 combat these activations/gradient problems?",
    "source": "ELEC/COMP 576: - Slide 41",
    "source_detail": "ELEC576-Lec07-1.pdf, Page 41",
    "lecture": "ELEC/COMP 576:",
    "lecture_number": "576",
    "page": 41,
    "content_type": "text",
    "doc_id": "slide_576_41",
    "doc_type": "slide",
    "is_definition": false,
    "contains_equation": false,
    "importance": "high",
    "tags": [
      "rnn",
      "neural networks"
    ]
  },
  {
    "text": "RNNs with Longer Term Memory",
    "source": "ELEC/COMP 576: - Slide 42",
    "source_detail": "ELEC576-Lec07-1.pdf, Page 42",
    "lecture": "ELEC/COMP 576:",
    "lecture_number": "576",
    "page": 42,
    "content_type": "text",
    "doc_id": "slide_576_42",
    "doc_type": "slide",
    "is_definition": false,
    "contains_equation": false,
    "importance": "high",
    "tags": [
      "rnn",
      "neural networks"
    ]
  },
  {
    "text": "Motivation The need to remember certain events for arbitrarily \u2022 long periods of time (Non-Markovian) The need to forget certain events \u2022",
    "source": "ELEC/COMP 576: - Slide 43",
    "source_detail": "ELEC576-Lec07-1.pdf, Page 43",
    "lecture": "ELEC/COMP 576:",
    "lecture_number": "576",
    "page": 43,
    "content_type": "text",
    "doc_id": "slide_576_43",
    "doc_type": "slide",
    "is_definition": false,
    "contains_equation": false,
    "importance": "high",
    "tags": [
      "Non-Markovian",
      "Memory",
      "Motivation",
      "Forgetting"
    ]
  },
  {
    "text": "Long Short Term Memory 3 gates \u2022 Input \u2022 Forget \u2022 Output \u2022 [Zygmunt Z.]",
    "source": "ELEC/COMP 576: - Slide 44",
    "source_detail": "ELEC576-Lec07-1.pdf, Page 44",
    "lecture": "ELEC/COMP 576:",
    "lecture_number": "576",
    "page": 44,
    "content_type": "text",
    "doc_id": "slide_576_44",
    "doc_type": "slide",
    "is_definition": true,
    "contains_equation": false,
    "importance": "high",
    "tags": [
      "Forget",
      "Output",
      "Input",
      "Long Short Term Memory",
      "gates"
    ]
  },
  {
    "text": "LSTM Formulation [Alex Graves, Navdeep Jaitly]",
    "source": "ELEC/COMP 576: - Slide 45",
    "source_detail": "ELEC576-Lec07-1.pdf, Page 45",
    "lecture": "ELEC/COMP 576:",
    "lecture_number": "576",
    "page": 45,
    "content_type": "text",
    "doc_id": "slide_576_45",
    "doc_type": "slide",
    "is_definition": false,
    "contains_equation": true,
    "importance": "high",
    "tags": [
      "rnn"
    ]
  },
  {
    "text": "Preserving Gradients [Hochreiter, Schmidhuber]",
    "source": "ELEC/COMP 576: - Slide 46",
    "source_detail": "ELEC576-Lec07-1.pdf, Page 46",
    "lecture": "ELEC/COMP 576:",
    "lecture_number": "576",
    "page": 46,
    "content_type": "text",
    "doc_id": "slide_576_46",
    "doc_type": "slide",
    "is_definition": false,
    "contains_equation": true,
    "importance": "high",
    "tags": [
      "Hochreiter",
      "backpropagation",
      "Preserving Gradients",
      "neural networks",
      "Schmidhuber"
    ]
  },
  {
    "text": "Gated Recurrent Unit 2 gates \u2022 Reset \u2022 Combine new \u2022 input with previous memory Update \u2022 How long the \u2022 [Zygmunt Z.] previous memory should stay",
    "source": "ELEC/COMP 576: - Slide 47",
    "source_detail": "ELEC576-Lec07-1.pdf, Page 47",
    "lecture": "ELEC/COMP 576:",
    "lecture_number": "576",
    "page": 47,
    "content_type": "text",
    "doc_id": "slide_576_47",
    "doc_type": "slide",
    "is_definition": false,
    "contains_equation": false,
    "importance": "high",
    "tags": [
      "rnn"
    ]
  },
  {
    "text": "GRU Formulation [Danny Britz]",
    "source": "ELEC/COMP 576: - Slide 48",
    "source_detail": "ELEC576-Lec07-1.pdf, Page 48",
    "lecture": "ELEC/COMP 576:",
    "lecture_number": "576",
    "page": 48,
    "content_type": "text",
    "doc_id": "slide_576_48",
    "doc_type": "slide",
    "is_definition": false,
    "contains_equation": true,
    "importance": "high",
    "tags": [
      "rnn",
      "neural networks"
    ]
  },
  {
    "text": "LSTM & GRU Benefits Remember for longer temporal durations \u2022 RNN has issues for remembering longer \u2022 durations Able to have feedback flow at different strengths \u2022 depending on inputs",
    "source": "ELEC/COMP 576: - Slide 49",
    "source_detail": "ELEC576-Lec07-1.pdf, Page 49",
    "lecture": "ELEC/COMP 576:",
    "lecture_number": "576",
    "page": 49,
    "content_type": "text",
    "doc_id": "slide_576_49",
    "doc_type": "slide",
    "is_definition": false,
    "contains_equation": false,
    "importance": "high",
    "tags": [
      "rnn",
      "neural networks"
    ]
  },
  {
    "text": "Differences between LSTM & GRU GRU has two gates, while LSTM has three gates \u2022 GRU does not have internal memory \u2022 GRU does not use a second nonlinearity for \u2022 computing the output",
    "source": "ELEC/COMP 576: - Slide 50",
    "source_detail": "ELEC576-Lec07-1.pdf, Page 50",
    "lecture": "ELEC/COMP 576:",
    "lecture_number": "576",
    "page": 50,
    "content_type": "text",
    "doc_id": "slide_576_50",
    "doc_type": "slide",
    "is_definition": true,
    "contains_equation": false,
    "importance": "medium",
    "tags": [
      "rnn"
    ]
  },
  {
    "text": "Visual Difference of LSTM & GRU LSTM GRU [Chris Olah]",
    "source": "ELEC/COMP 576: - Slide 51",
    "source_detail": "ELEC576-Lec07-1.pdf, Page 51",
    "lecture": "ELEC/COMP 576:",
    "lecture_number": "576",
    "page": 51,
    "content_type": "text",
    "doc_id": "slide_576_51",
    "doc_type": "slide",
    "is_definition": false,
    "contains_equation": false,
    "importance": "medium",
    "tags": [
      "rnn"
    ]
  },
  {
    "text": "LSTM vs GRU Results [Chung, Gulcehre, Cho, Bengio]",
    "source": "ELEC/COMP 576: - Slide 52",
    "source_detail": "ELEC576-Lec07-1.pdf, Page 52",
    "lecture": "ELEC/COMP 576:",
    "lecture_number": "576",
    "page": 52,
    "content_type": "text",
    "doc_id": "slide_576_52",
    "doc_type": "slide",
    "is_definition": false,
    "contains_equation": true,
    "importance": "high",
    "tags": [
      "rnn"
    ]
  },
  {
    "text": "Other Methods for Stabilizing RNN Training",
    "source": "ELEC/COMP 576: - Slide 53",
    "source_detail": "ELEC576-Lec07-1.pdf, Page 53",
    "lecture": "ELEC/COMP 576:",
    "lecture_number": "576",
    "page": 53,
    "content_type": "text",
    "doc_id": "slide_576_53",
    "doc_type": "slide",
    "is_definition": false,
    "contains_equation": false,
    "importance": "medium",
    "tags": [
      "rnn",
      "neural networks"
    ]
  },
  {
    "text": "Why Training is Unstable Variance of activations/gradients grows multiplicatively [Xu, Huang, Li]",
    "source": "ELEC/COMP 576: - Slide 54",
    "source_detail": "ELEC576-Lec07-1.pdf, Page 54",
    "lecture": "ELEC/COMP 576:",
    "lecture_number": "576",
    "page": 54,
    "content_type": "text",
    "doc_id": "slide_576_54",
    "doc_type": "slide",
    "is_definition": false,
    "contains_equation": true,
    "importance": "high",
    "tags": [
      "neural networks"
    ]
  },
  {
    "text": "Stabilizing Activations & Gradients We want [Xu, Huang, Li]",
    "source": "ELEC/COMP 576: - Slide 55",
    "source_detail": "ELEC576-Lec07-1.pdf, Page 55",
    "lecture": "ELEC/COMP 576:",
    "lecture_number": "576",
    "page": 55,
    "content_type": "text",
    "doc_id": "slide_576_55",
    "doc_type": "slide",
    "is_definition": false,
    "contains_equation": false,
    "importance": "high",
    "tags": [
      "neural networks"
    ]
  },
  {
    "text": "Taylor Expansions of Different Activation Functions [Xu, Huang, Li]",
    "source": "ELEC/COMP 576: - Slide 56",
    "source_detail": "ELEC576-Lec07-1.pdf, Page 56",
    "lecture": "ELEC/COMP 576:",
    "lecture_number": "576",
    "page": 56,
    "content_type": "text",
    "doc_id": "slide_576_56",
    "doc_type": "slide",
    "is_definition": false,
    "contains_equation": true,
    "importance": "high",
    "tags": [
      "neural networks"
    ]
  },
  {
    "text": "Layer Normalization Similar to batch normalization \u2022 Apply it to RNNs to stabilize the hidden state \u2022 dynamics [Ba, Kiros, Hinton]",
    "source": "ELEC/COMP 576: - Slide 57",
    "source_detail": "ELEC576-Lec07-1.pdf, Page 57",
    "lecture": "ELEC/COMP 576:",
    "lecture_number": "576",
    "page": 57,
    "content_type": "text",
    "doc_id": "slide_576_57",
    "doc_type": "slide",
    "is_definition": false,
    "contains_equation": false,
    "importance": "high",
    "tags": [
      "regularization",
      "rnn",
      "neural networks"
    ]
  },
  {
    "text": "Layer Normalization Results [Ba, Kiros, Hinton]",
    "source": "ELEC/COMP 576: - Slide 58",
    "source_detail": "ELEC576-Lec07-1.pdf, Page 58",
    "lecture": "ELEC/COMP 576:",
    "lecture_number": "576",
    "page": 58,
    "content_type": "text",
    "doc_id": "slide_576_58",
    "doc_type": "slide",
    "is_definition": false,
    "contains_equation": true,
    "importance": "high",
    "tags": [
      "Results",
      "Hinton",
      "Kiros",
      "Layer Normalization",
      "Ba"
    ]
  },
  {
    "text": "Bidirectional RNNs The output at time t does not depend on previous \u2022 time steps but also the future Two RNNs stacked on top of each other \u2022 [Danny Britz]",
    "source": "ELEC/COMP 576: - Slide 60",
    "source_detail": "ELEC576-Lec07-1.pdf, Page 60",
    "lecture": "ELEC/COMP 576:",
    "lecture_number": "576",
    "page": 60,
    "content_type": "text",
    "doc_id": "slide_576_60",
    "doc_type": "slide",
    "is_definition": false,
    "contains_equation": false,
    "importance": "medium",
    "tags": [
      "rnn",
      "neural networks"
    ]
  },
  {
    "text": "Deep RNNs Stack them on top of each other \u2022 The output of the previous RNN is the input to the \u2022 next one [Danny Britz]",
    "source": "ELEC/COMP 576: - Slide 61",
    "source_detail": "ELEC576-Lec07-1.pdf, Page 61",
    "lecture": "ELEC/COMP 576:",
    "lecture_number": "576",
    "page": 61,
    "content_type": "text",
    "doc_id": "slide_576_61",
    "doc_type": "slide",
    "is_definition": false,
    "contains_equation": false,
    "importance": "medium",
    "tags": [
      "rnn",
      "neural networks"
    ]
  },
  {
    "text": "The Power of RNNs: Understanding and Visualizing",
    "source": "ELEC/COMP 576: - Slide 62",
    "source_detail": "ELEC576-Lec07-1.pdf, Page 62",
    "lecture": "ELEC/COMP 576:",
    "lecture_number": "576",
    "page": 62,
    "content_type": "text",
    "doc_id": "slide_576_62",
    "doc_type": "slide",
    "is_definition": false,
    "contains_equation": false,
    "importance": "high",
    "tags": [
      "rnn",
      "neural networks"
    ]
  },
  {
    "text": "The Effectiveness of an RNN [Andrej Karpathy]",
    "source": "ELEC/COMP 576: - Slide 63",
    "source_detail": "ELEC576-Lec07-1.pdf, Page 63",
    "lecture": "ELEC/COMP 576:",
    "lecture_number": "576",
    "page": 63,
    "content_type": "text",
    "doc_id": "slide_576_63",
    "doc_type": "slide",
    "is_definition": false,
    "contains_equation": true,
    "importance": "high",
    "tags": [
      "rnn",
      "neural networks"
    ]
  },
  {
    "text": "The Effectiveness of an RNN [Andrej Karpathy]",
    "source": "ELEC/COMP 576: - Slide 64",
    "source_detail": "ELEC576-Lec07-1.pdf, Page 64",
    "lecture": "ELEC/COMP 576:",
    "lecture_number": "576",
    "page": 64,
    "content_type": "text",
    "doc_id": "slide_576_64",
    "doc_type": "slide",
    "is_definition": false,
    "contains_equation": true,
    "importance": "high",
    "tags": [
      "rnn",
      "neural networks"
    ]
  },
  {
    "text": "The Effectiveness of an RNN [Andrej Karpathy]",
    "source": "ELEC/COMP 576: - Slide 65",
    "source_detail": "ELEC576-Lec07-1.pdf, Page 65",
    "lecture": "ELEC/COMP 576:",
    "lecture_number": "576",
    "page": 65,
    "content_type": "text",
    "doc_id": "slide_576_65",
    "doc_type": "slide",
    "is_definition": false,
    "contains_equation": true,
    "importance": "high",
    "tags": [
      "rnn",
      "neural networks"
    ]
  },
  {
    "text": "The Effectiveness of an RNN Trained on War & Peace Iteration: 100 Iteration: 300 Iteration: 2000 [Andrej Karpathy]",
    "source": "ELEC/COMP 576: - Slide 66",
    "source_detail": "ELEC576-Lec07-1.pdf, Page 66",
    "lecture": "ELEC/COMP 576:",
    "lecture_number": "576",
    "page": 66,
    "content_type": "text",
    "doc_id": "slide_576_66",
    "doc_type": "slide",
    "is_definition": false,
    "contains_equation": false,
    "importance": "medium",
    "tags": [
      "rnn",
      "neural networks"
    ]
  },
  {
    "text": "Visualize the Neurons of an RNN [Andrej Karpathy]",
    "source": "ELEC/COMP 576: - Slide 67",
    "source_detail": "ELEC576-Lec07-1.pdf, Page 67",
    "lecture": "ELEC/COMP 576:",
    "lecture_number": "576",
    "page": 67,
    "content_type": "text",
    "doc_id": "slide_576_67",
    "doc_type": "slide",
    "is_definition": false,
    "contains_equation": false,
    "importance": "high",
    "tags": [
      "rnn",
      "neural networks"
    ]
  },
  {
    "text": "Visualize the Neurons of an RNN [Andrej Karpathy]",
    "source": "ELEC/COMP 576: - Slide 68",
    "source_detail": "ELEC576-Lec07-1.pdf, Page 68",
    "lecture": "ELEC/COMP 576:",
    "lecture_number": "576",
    "page": 68,
    "content_type": "text",
    "doc_id": "slide_576_68",
    "doc_type": "slide",
    "is_definition": false,
    "contains_equation": false,
    "importance": "high",
    "tags": [
      "rnn",
      "neural networks"
    ]
  },
  {
    "text": "RNN Applications Speech Recognition \u2022 Natural Language Processing \u2022 Action Recognition \u2022 Machine Translation \u2022 Many more to come \u2022",
    "source": "ELEC/COMP 576: - Slide 70",
    "source_detail": "ELEC576-Lec07-1.pdf, Page 70",
    "lecture": "ELEC/COMP 576:",
    "lecture_number": "576",
    "page": 70,
    "content_type": "text",
    "doc_id": "slide_576_70",
    "doc_type": "slide",
    "is_definition": false,
    "contains_equation": false,
    "importance": "high",
    "tags": [
      "rnn",
      "neural networks"
    ]
  },
  {
    "text": "Speech Recognition Deep Bidirectional LSTM \u2022 [Alex Graves, Navdeep Jaitly, Abdel-rahman Mohamed]",
    "source": "ELEC/COMP 576: - Slide 71",
    "source_detail": "ELEC576-Lec07-1.pdf, Page 71",
    "lecture": "ELEC/COMP 576:",
    "lecture_number": "576",
    "page": 71,
    "content_type": "text",
    "doc_id": "slide_576_71",
    "doc_type": "slide",
    "is_definition": false,
    "contains_equation": true,
    "importance": "high",
    "tags": [
      "rnn"
    ]
  },
  {
    "text": "Conversational Speech Recognition Achieving human \u2022 parity [Xiong et al.]",
    "source": "ELEC/COMP 576: - Slide 72",
    "source_detail": "ELEC576-Lec07-1.pdf, Page 72",
    "lecture": "ELEC/COMP 576:",
    "lecture_number": "576",
    "page": 72,
    "content_type": "text",
    "doc_id": "slide_576_72",
    "doc_type": "slide",
    "is_definition": false,
    "contains_equation": false,
    "importance": "high",
    "tags": [
      "cnn"
    ]
  },
  {
    "text": "Natural Language Processing [Soumith Chantala]",
    "source": "ELEC/COMP 576: - Slide 73",
    "source_detail": "ELEC576-Lec07-1.pdf, Page 73",
    "lecture": "ELEC/COMP 576:",
    "lecture_number": "576",
    "page": 73,
    "content_type": "text",
    "doc_id": "slide_576_73",
    "doc_type": "slide",
    "is_definition": false,
    "contains_equation": false,
    "importance": "high",
    "tags": [
      "Soumith Chantala",
      "Natural Language Processing"
    ]
  },
  {
    "text": "Contextual LSTM for NLP Tasks [Ghost et al.]",
    "source": "ELEC/COMP 576: - Slide 74",
    "source_detail": "ELEC576-Lec07-1.pdf, Page 74",
    "lecture": "ELEC/COMP 576:",
    "lecture_number": "576",
    "page": 74,
    "content_type": "text",
    "doc_id": "slide_576_74",
    "doc_type": "slide",
    "is_definition": false,
    "contains_equation": true,
    "importance": "high",
    "tags": [
      "rnn"
    ]
  },
  {
    "text": "Action Recognition Long-term Recurrent Convnet \u2022 [Donahue et al.]",
    "source": "ELEC/COMP 576: - Slide 75",
    "source_detail": "ELEC576-Lec07-1.pdf, Page 75",
    "lecture": "ELEC/COMP 576:",
    "lecture_number": "576",
    "page": 75,
    "content_type": "text",
    "doc_id": "slide_576_75",
    "doc_type": "slide",
    "is_definition": false,
    "contains_equation": false,
    "importance": "high",
    "tags": [
      "cnn",
      "rnn"
    ]
  },
  {
    "text": "Google\u2019s Neural Machine Translation System [Yonghui Wu et al.]",
    "source": "ELEC/COMP 576: - Slide 76",
    "source_detail": "ELEC576-Lec07-1.pdf, Page 76",
    "lecture": "ELEC/COMP 576:",
    "lecture_number": "576",
    "page": 76,
    "content_type": "text",
    "doc_id": "slide_576_76",
    "doc_type": "slide",
    "is_definition": false,
    "contains_equation": false,
    "importance": "high",
    "tags": [
      "Machine Learning",
      "Yonghui Wu",
      "Natural Language Processing",
      "Google",
      "Neural Machine Translation"
    ]
  },
  {
    "text": "Image Captioning [Vinyals, Toshev, Bengio, Erhan]",
    "source": "ELEC/COMP 576: - Slide 77",
    "source_detail": "ELEC576-Lec07-1.pdf, Page 77",
    "lecture": "ELEC/COMP 576:",
    "lecture_number": "576",
    "page": 77,
    "content_type": "figure",
    "doc_id": "slide_576_77",
    "doc_type": "slide",
    "is_definition": false,
    "contains_equation": false,
    "importance": "high",
    "tags": [
      "Erhan",
      "Image Captioning",
      "Bengio",
      "Vinyals",
      "Toshev"
    ]
  },
  {
    "text": "Image Captioning [Vinyals, Toshev, Bengio, Erhan]",
    "source": "ELEC/COMP 576: - Slide 78",
    "source_detail": "ELEC576-Lec07-1.pdf, Page 78",
    "lecture": "ELEC/COMP 576:",
    "lecture_number": "576",
    "page": 78,
    "content_type": "figure",
    "doc_id": "slide_576_78",
    "doc_type": "slide",
    "is_definition": false,
    "contains_equation": false,
    "importance": "high",
    "tags": [
      "Erhan",
      "Image Captioning",
      "Bengio",
      "Vinyals",
      "Toshev"
    ]
  },
  {
    "text": "Object Tracking [Ning, Zhang, Huang, He, Wang]",
    "source": "ELEC/COMP 576: - Slide 79",
    "source_detail": "ELEC576-Lec07-1.pdf, Page 79",
    "lecture": "ELEC/COMP 576:",
    "lecture_number": "576",
    "page": 79,
    "content_type": "text",
    "doc_id": "slide_576_79",
    "doc_type": "slide",
    "is_definition": false,
    "contains_equation": false,
    "importance": "high",
    "tags": [
      "Zhang",
      "Ning",
      "Huang",
      "Wang",
      "He",
      "Object Tracking"
    ]
  },
  {
    "text": "Neural Turing Machines [Chris Olah]",
    "source": "ELEC/COMP 576: - Slide 80",
    "source_detail": "ELEC576-Lec07-1.pdf, Page 80",
    "lecture": "ELEC/COMP 576:",
    "lecture_number": "576",
    "page": 80,
    "content_type": "text",
    "doc_id": "slide_576_80",
    "doc_type": "slide",
    "is_definition": true,
    "contains_equation": true,
    "importance": "high",
    "tags": [
      "artificial intelligence",
      "Chris Olah",
      "machine learning",
      "neural networks",
      "Neural Turing Machines"
    ]
  },
  {
    "text": "WaveNet [van den Oord et al.]",
    "source": "ELEC/COMP 576: - Slide 81",
    "source_detail": "ELEC576-Lec07-1.pdf, Page 81",
    "lecture": "ELEC/COMP 576:",
    "lecture_number": "576",
    "page": 81,
    "content_type": "text",
    "doc_id": "slide_576_81",
    "doc_type": "slide",
    "is_definition": false,
    "contains_equation": false,
    "importance": "high",
    "tags": [
      "audio generation",
      "WaveNet",
      "van den Oord",
      "neural networks",
      "deep learning"
    ]
  },
  {
    "text": "DoomBot Doom Competition \u2022 Facebook won 1st place (F1) \u2022 https://www.youtube.com/watch? \u2022 v=94EPSjQH38Y",
    "source": "ELEC/COMP 576: - Slide 82",
    "source_detail": "ELEC576-Lec07-1.pdf, Page 82",
    "lecture": "ELEC/COMP 576:",
    "lecture_number": "576",
    "page": 82,
    "content_type": "text",
    "doc_id": "slide_576_82",
    "doc_type": "slide",
    "is_definition": false,
    "contains_equation": false,
    "importance": "low",
    "tags": [
      "YouTube",
      "DoomBot",
      "1st place",
      "Doom Competition",
      "Facebook"
    ]
  },
  {
    "text": "ODE2RNN:Parameter Estimation for Systems of Ordinary Differential Equations ODE-based RNN Recurrent Update !83",
    "source": "ELEC/COMP 576: - Slide 83",
    "source_detail": "ELEC576-Lec07-1.pdf, Page 83",
    "lecture": "ELEC/COMP 576:",
    "lecture_number": "576",
    "page": 83,
    "content_type": "text",
    "doc_id": "slide_576_83",
    "doc_type": "slide",
    "is_definition": false,
    "contains_equation": true,
    "importance": "high",
    "tags": [
      "rnn",
      "neural networks"
    ]
  },
  {
    "text": "Introduction to Transformers",
    "source": "ELEC/COMP 576: - Slide 2",
    "source_detail": "ELEC576-Lec07.pdf, Page 2",
    "lecture": "ELEC/COMP 576:",
    "lecture_number": "576",
    "page": 2,
    "content_type": "text",
    "doc_id": "slide_576_2",
    "doc_type": "slide",
    "is_definition": false,
    "contains_equation": false,
    "importance": "high",
    "tags": [
      "attention"
    ]
  },
  {
    "text": "What are some of the drawbacks CNNs?",
    "source": "ELEC/COMP 576: - Slide 3",
    "source_detail": "ELEC576-Lec07.pdf, Page 3",
    "lecture": "ELEC/COMP 576:",
    "lecture_number": "576",
    "page": 3,
    "content_type": "text",
    "doc_id": "slide_576_3",
    "doc_type": "slide",
    "is_definition": false,
    "contains_equation": false,
    "importance": "medium",
    "tags": [
      "cnn",
      "neural networks"
    ]
  },
  {
    "text": "What are some of the drawbacks CNNs? \u2022 Local connectivity: global context is aggregated slowly as we go deeper. Great for small dataset \u2022 Not easy to deal with sequential data",
    "source": "ELEC/COMP 576: - Slide 4",
    "source_detail": "ELEC576-Lec07.pdf, Page 4",
    "lecture": "ELEC/COMP 576:",
    "lecture_number": "576",
    "page": 4,
    "content_type": "text",
    "doc_id": "slide_576_4",
    "doc_type": "slide",
    "is_definition": false,
    "contains_equation": false,
    "importance": "medium",
    "tags": [
      "cnn",
      "neural networks"
    ]
  },
  {
    "text": "How do we get rid of these drawbacks?",
    "source": "ELEC/COMP 576: - Slide 5",
    "source_detail": "ELEC576-Lec07.pdf, Page 5",
    "lecture": "ELEC/COMP 576:",
    "lecture_number": "576",
    "page": 5,
    "content_type": "text",
    "doc_id": "slide_576_5",
    "doc_type": "slide",
    "is_definition": false,
    "contains_equation": false,
    "importance": "low",
    "tags": [
      "solutions",
      "drawbacks",
      "improvement"
    ]
  },
  {
    "text": "How do we get rid of these drawbacks? Make kernels big Have MLP on the entire image --- like having massive kernels Deal with samples sequentially \u2026.",
    "source": "ELEC/COMP 576: - Slide 6",
    "source_detail": "ELEC576-Lec07.pdf, Page 6",
    "lecture": "ELEC/COMP 576:",
    "lecture_number": "576",
    "page": 6,
    "content_type": "figure",
    "doc_id": "slide_576_6",
    "doc_type": "slide",
    "is_definition": false,
    "contains_equation": false,
    "importance": "medium",
    "tags": [
      "kernels",
      "MLP",
      "image processing",
      "samples",
      "drawbacks"
    ]
  },
  {
    "text": "How do we get rid of these drawbacks? Make kernels big Have MLP on the entire image --- like having massive kernels Deal with samples sequentially \u2026.",
    "source": "ELEC/COMP 576: - Slide 7",
    "source_detail": "ELEC576-Lec07.pdf, Page 7",
    "lecture": "ELEC/COMP 576:",
    "lecture_number": "576",
    "page": 7,
    "content_type": "figure",
    "doc_id": "slide_576_7",
    "doc_type": "slide",
    "is_definition": false,
    "contains_equation": false,
    "importance": "medium",
    "tags": [
      "kernels",
      "MLP",
      "image processing",
      "samples",
      "drawbacks"
    ]
  },
  {
    "text": "How do we get rid of these drawbacks? A single MLP layer on 1MP image will use 1012 parameters! Make kerneTlso huog em uch memory, Have MLP on the entire image --- like having huge kernels parameters and compute Deal with samples sequentially \u2026.",
    "source": "ELEC/COMP 576: - Slide 8",
    "source_detail": "ELEC576-Lec07.pdf, Page 8",
    "lecture": "ELEC/COMP 576:",
    "lecture_number": "576",
    "page": 8,
    "content_type": "figure",
    "doc_id": "slide_576_8",
    "doc_type": "slide",
    "is_definition": false,
    "contains_equation": true,
    "importance": "high",
    "tags": [
      "sequential sampling",
      "image processing",
      "parameters",
      "MLP layer",
      "memory usage"
    ]
  },
  {
    "text": "Attention Mechanism \u2022 New type of operation \u2022 Automatically determine importance of each component of a sequence relative to other components in the same sequence \u2013 still global ops but selective",
    "source": "ELEC/COMP 576: - Slide 9",
    "source_detail": "ELEC576-Lec07.pdf, Page 9",
    "lecture": "ELEC/COMP 576:",
    "lecture_number": "576",
    "page": 9,
    "content_type": "text",
    "doc_id": "slide_576_9",
    "doc_type": "slide",
    "is_definition": true,
    "contains_equation": false,
    "importance": "high",
    "tags": [
      "attention"
    ]
  },
  {
    "text": "Attention \u2013 A brief History 2014 \u2013 Attention first applied to machine translation problem in NLP \u2022 2015 \u2013 Attention was extended to vision task for captioning and \u2022 image grounding 2016 \u2013 Self-attention is explored in machine-translation problems \u2022 2017\u2013 \u201c Attention is All You Need\u201d introduces transformers \u2022 2018 \u2013 BERT and GPT-1 are developed for NLP \u2022 2020 \u2013 Vision Transformer was developed for CV \u2022 \u2026 \u2022",
    "source": "ELEC/COMP 576: - Slide 10",
    "source_detail": "ELEC576-Lec07.pdf, Page 10",
    "lecture": "ELEC/COMP 576:",
    "lecture_number": "576",
    "page": 10,
    "content_type": "figure",
    "doc_id": "slide_576_10",
    "doc_type": "slide",
    "is_definition": false,
    "contains_equation": false,
    "importance": "high",
    "tags": [
      "attention"
    ]
  },
  {
    "text": "Attention Mechanism Think of attention as some operations between Q and X with learnable parameters Wk, Wv Slide Credit: Justin Johnson",
    "source": "ELEC/COMP 576: - Slide 11",
    "source_detail": "ELEC576-Lec07.pdf, Page 11",
    "lecture": "ELEC/COMP 576:",
    "lecture_number": "576",
    "page": 11,
    "content_type": "text",
    "doc_id": "slide_576_11",
    "doc_type": "slide",
    "is_definition": true,
    "contains_equation": true,
    "importance": "high",
    "tags": [
      "attention"
    ]
  },
  {
    "text": "Attention Mechanism Query, Key and Value were terms borrowed from information retrieval You enter a query that maps against keys and retrieves value",
    "source": "ELEC/COMP 576: - Slide 12",
    "source_detail": "ELEC576-Lec07.pdf, Page 12",
    "lecture": "ELEC/COMP 576:",
    "lecture_number": "576",
    "page": 12,
    "content_type": "text",
    "doc_id": "slide_576_12",
    "doc_type": "slide",
    "is_definition": true,
    "contains_equation": false,
    "importance": "high",
    "tags": [
      "attention"
    ]
  },
  {
    "text": "Attention Mechanism Scaled Dot Product",
    "source": "ELEC/COMP 576: - Slide 14",
    "source_detail": "ELEC576-Lec07.pdf, Page 14",
    "lecture": "ELEC/COMP 576:",
    "lecture_number": "576",
    "page": 14,
    "content_type": "text",
    "doc_id": "slide_576_14",
    "doc_type": "slide",
    "is_definition": true,
    "contains_equation": true,
    "importance": "high",
    "tags": [
      "attention"
    ]
  },
  {
    "text": "Self-Attention Layer Building block of transformers",
    "source": "ELEC/COMP 576: - Slide 18",
    "source_detail": "ELEC576-Lec07.pdf, Page 18",
    "lecture": "ELEC/COMP 576:",
    "lecture_number": "576",
    "page": 18,
    "content_type": "text",
    "doc_id": "slide_576_18",
    "doc_type": "slide",
    "is_definition": true,
    "contains_equation": false,
    "importance": "high",
    "tags": [
      "attention"
    ]
  },
  {
    "text": "Self-Attention Layer Building block of transformers",
    "source": "ELEC/COMP 576: - Slide 19",
    "source_detail": "ELEC576-Lec07.pdf, Page 19",
    "lecture": "ELEC/COMP 576:",
    "lecture_number": "576",
    "page": 19,
    "content_type": "text",
    "doc_id": "slide_576_19",
    "doc_type": "slide",
    "is_definition": true,
    "contains_equation": false,
    "importance": "high",
    "tags": [
      "attention"
    ]
  },
  {
    "text": "Self-Attention Layer Building block of transformers",
    "source": "ELEC/COMP 576: - Slide 20",
    "source_detail": "ELEC576-Lec07.pdf, Page 20",
    "lecture": "ELEC/COMP 576:",
    "lecture_number": "576",
    "page": 20,
    "content_type": "text",
    "doc_id": "slide_576_20",
    "doc_type": "slide",
    "is_definition": true,
    "contains_equation": false,
    "importance": "high",
    "tags": [
      "attention"
    ]
  },
  {
    "text": "Self-Attention Layer Building block of transformers",
    "source": "ELEC/COMP 576: - Slide 21",
    "source_detail": "ELEC576-Lec07.pdf, Page 21",
    "lecture": "ELEC/COMP 576:",
    "lecture_number": "576",
    "page": 21,
    "content_type": "text",
    "doc_id": "slide_576_21",
    "doc_type": "slide",
    "is_definition": true,
    "contains_equation": false,
    "importance": "high",
    "tags": [
      "attention"
    ]
  },
  {
    "text": "Self-Attention Layer Building block of transformers",
    "source": "ELEC/COMP 576: - Slide 22",
    "source_detail": "ELEC576-Lec07.pdf, Page 22",
    "lecture": "ELEC/COMP 576:",
    "lecture_number": "576",
    "page": 22,
    "content_type": "text",
    "doc_id": "slide_576_22",
    "doc_type": "slide",
    "is_definition": true,
    "contains_equation": false,
    "importance": "high",
    "tags": [
      "attention"
    ]
  },
  {
    "text": "Self-Attention Layer Building block of transformers",
    "source": "ELEC/COMP 576: - Slide 23",
    "source_detail": "ELEC576-Lec07.pdf, Page 23",
    "lecture": "ELEC/COMP 576:",
    "lecture_number": "576",
    "page": 23,
    "content_type": "text",
    "doc_id": "slide_576_23",
    "doc_type": "slide",
    "is_definition": true,
    "contains_equation": false,
    "importance": "high",
    "tags": [
      "attention"
    ]
  },
  {
    "text": "Self-Attention Layer Building block of transformers",
    "source": "ELEC/COMP 576: - Slide 24",
    "source_detail": "ELEC576-Lec07.pdf, Page 24",
    "lecture": "ELEC/COMP 576:",
    "lecture_number": "576",
    "page": 24,
    "content_type": "text",
    "doc_id": "slide_576_24",
    "doc_type": "slide",
    "is_definition": true,
    "contains_equation": false,
    "importance": "high",
    "tags": [
      "attention"
    ]
  },
  {
    "text": "Self-Attention Layer Building block of transformers We have a problem",
    "source": "ELEC/COMP 576: - Slide 25",
    "source_detail": "ELEC576-Lec07.pdf, Page 25",
    "lecture": "ELEC/COMP 576:",
    "lecture_number": "576",
    "page": 25,
    "content_type": "text",
    "doc_id": "slide_576_25",
    "doc_type": "slide",
    "is_definition": false,
    "contains_equation": false,
    "importance": "high",
    "tags": [
      "attention"
    ]
  },
  {
    "text": "Self-Attention Layer Building block of transformers We have a problem: What happens if you shuffle the input?",
    "source": "ELEC/COMP 576: - Slide 26",
    "source_detail": "ELEC576-Lec07.pdf, Page 26",
    "lecture": "ELEC/COMP 576:",
    "lecture_number": "576",
    "page": 26,
    "content_type": "text",
    "doc_id": "slide_576_26",
    "doc_type": "slide",
    "is_definition": true,
    "contains_equation": false,
    "importance": "high",
    "tags": [
      "attention"
    ]
  },
  {
    "text": "Self-Attention Layer Building block of transformers",
    "source": "ELEC/COMP 576: - Slide 27",
    "source_detail": "ELEC576-Lec07.pdf, Page 27",
    "lecture": "ELEC/COMP 576:",
    "lecture_number": "576",
    "page": 27,
    "content_type": "text",
    "doc_id": "slide_576_27",
    "doc_type": "slide",
    "is_definition": true,
    "contains_equation": false,
    "importance": "high",
    "tags": [
      "attention"
    ]
  },
  {
    "text": "Why is this a problem? Think of scenarios",
    "source": "ELEC/COMP 576: - Slide 36",
    "source_detail": "ELEC576-Lec07.pdf, Page 36",
    "lecture": "ELEC/COMP 576:",
    "lecture_number": "576",
    "page": 36,
    "content_type": "text",
    "doc_id": "slide_576_36",
    "doc_type": "slide",
    "is_definition": false,
    "contains_equation": false,
    "importance": "low",
    "tags": [
      "scenarios",
      "critical thinking",
      "problem identification"
    ]
  },
  {
    "text": "Positional Encoding Should be unique for each position \u2013 not cyclic \u2022 Bounded \u2022 For example: \u2022 pos: index of the input i: ith component of the positional encoding vector d : embedding dimension model Different calculation for even and odd \u2018i\u2019",
    "source": "ELEC/COMP 576: - Slide 38",
    "source_detail": "ELEC576-Lec07.pdf, Page 38",
    "lecture": "ELEC/COMP 576:",
    "lecture_number": "576",
    "page": 38,
    "content_type": "text",
    "doc_id": "slide_576_38",
    "doc_type": "slide",
    "is_definition": true,
    "contains_equation": true,
    "importance": "high",
    "tags": [
      "Embedding Dimension",
      "Positional Encoding",
      "Even and Odd Indexing",
      "Unique Positioning"
    ]
  },
  {
    "text": "Input sequence of vectors",
    "source": "ELEC/COMP 576: - Slide 39",
    "source_detail": "ELEC576-Lec07.pdf, Page 39",
    "lecture": "ELEC/COMP 576:",
    "lecture_number": "576",
    "page": 39,
    "content_type": "text",
    "doc_id": "slide_576_39",
    "doc_type": "slide",
    "is_definition": false,
    "contains_equation": false,
    "importance": "medium",
    "tags": [
      "input sequence",
      "vectors",
      "data processing"
    ]
  },
  {
    "text": "Each head deals with vectors of size Dx/3",
    "source": "ELEC/COMP 576: - Slide 40",
    "source_detail": "ELEC576-Lec07.pdf, Page 40",
    "lecture": "ELEC/COMP 576:",
    "lecture_number": "576",
    "page": 40,
    "content_type": "text",
    "doc_id": "slide_576_40",
    "doc_type": "slide",
    "is_definition": false,
    "contains_equation": true,
    "importance": "high",
    "tags": [
      "head",
      "vectors",
      "size",
      "Dx/3"
    ]
  },
  {
    "text": "Attention is All You Need Vaswani et al Neurips 2017 Introduces transformer \u2013 but builds on self-attention Only attention units. No conv or Recurrent layers at all. Hence \u201cattention is all you need\u201d",
    "source": "ELEC/COMP 576: - Slide 47",
    "source_detail": "ELEC576-Lec07.pdf, Page 47",
    "lecture": "ELEC/COMP 576:",
    "lecture_number": "576",
    "page": 47,
    "content_type": "text",
    "doc_id": "slide_576_47",
    "doc_type": "slide",
    "is_definition": true,
    "contains_equation": false,
    "importance": "high",
    "tags": [
      "cnn",
      "attention",
      "rnn"
    ]
  },
  {
    "text": "Attention is All You Need Vaswani et al Neurips 2017 Introduces transformer \u2013 but builds on self-attention Fun fact:",
    "source": "ELEC/COMP 576: - Slide 48",
    "source_detail": "ELEC576-Lec07.pdf, Page 48",
    "lecture": "ELEC/COMP 576:",
    "lecture_number": "576",
    "page": 48,
    "content_type": "text",
    "doc_id": "slide_576_48",
    "doc_type": "slide",
    "is_definition": true,
    "contains_equation": false,
    "importance": "high",
    "tags": [
      "attention"
    ]
  },
  {
    "text": "Transformer Input sequence of vectors",
    "source": "ELEC/COMP 576: - Slide 49",
    "source_detail": "ELEC576-Lec07.pdf, Page 49",
    "lecture": "ELEC/COMP 576:",
    "lecture_number": "576",
    "page": 49,
    "content_type": "text",
    "doc_id": "slide_576_49",
    "doc_type": "slide",
    "is_definition": false,
    "contains_equation": false,
    "importance": "high",
    "tags": [
      "attention"
    ]
  },
  {
    "text": "Transformer Remember me?",
    "source": "ELEC/COMP 576: - Slide 51",
    "source_detail": "ELEC576-Lec07.pdf, Page 51",
    "lecture": "ELEC/COMP 576:",
    "lecture_number": "576",
    "page": 51,
    "content_type": "text",
    "doc_id": "slide_576_51",
    "doc_type": "slide",
    "is_definition": false,
    "contains_equation": false,
    "importance": "high",
    "tags": [
      "attention"
    ]
  },
  {
    "text": "Transformer Layer Norm:",
    "source": "ELEC/COMP 576: - Slide 52",
    "source_detail": "ELEC576-Lec07.pdf, Page 52",
    "lecture": "ELEC/COMP 576:",
    "lecture_number": "576",
    "page": 52,
    "content_type": "text",
    "doc_id": "slide_576_52",
    "doc_type": "slide",
    "is_definition": false,
    "contains_equation": false,
    "importance": "medium",
    "tags": [
      "attention"
    ]
  },
  {
    "text": "Transformer Layer Norm:",
    "source": "ELEC/COMP 576: - Slide 53",
    "source_detail": "ELEC576-Lec07.pdf, Page 53",
    "lecture": "ELEC/COMP 576:",
    "lecture_number": "576",
    "page": 53,
    "content_type": "text",
    "doc_id": "slide_576_53",
    "doc_type": "slide",
    "is_definition": false,
    "contains_equation": false,
    "importance": "medium",
    "tags": [
      "attention"
    ]
  },
  {
    "text": "Transformer Layer Norm:",
    "source": "ELEC/COMP 576: - Slide 54",
    "source_detail": "ELEC576-Lec07.pdf, Page 54",
    "lecture": "ELEC/COMP 576:",
    "lecture_number": "576",
    "page": 54,
    "content_type": "text",
    "doc_id": "slide_576_54",
    "doc_type": "slide",
    "is_definition": false,
    "contains_equation": false,
    "importance": "medium",
    "tags": [
      "attention"
    ]
  },
  {
    "text": "Transformer Layer Norm:",
    "source": "ELEC/COMP 576: - Slide 55",
    "source_detail": "ELEC576-Lec07.pdf, Page 55",
    "lecture": "ELEC/COMP 576:",
    "lecture_number": "576",
    "page": 55,
    "content_type": "text",
    "doc_id": "slide_576_55",
    "doc_type": "slide",
    "is_definition": false,
    "contains_equation": false,
    "importance": "medium",
    "tags": [
      "attention"
    ]
  },
  {
    "text": "BERT Devlin et al 2018",
    "source": "ELEC/COMP 576: - Slide 59",
    "source_detail": "ELEC576-Lec07.pdf, Page 59",
    "lecture": "ELEC/COMP 576:",
    "lecture_number": "576",
    "page": 59,
    "content_type": "text",
    "doc_id": "slide_576_59",
    "doc_type": "slide",
    "is_definition": false,
    "contains_equation": false,
    "importance": "high",
    "tags": [
      "2018",
      "transformer models",
      "BERT",
      "natural language processing",
      "Devlin"
    ]
  },
  {
    "text": "BERT Devlin et al 2018",
    "source": "ELEC/COMP 576: - Slide 60",
    "source_detail": "ELEC576-Lec07.pdf, Page 60",
    "lecture": "ELEC/COMP 576:",
    "lecture_number": "576",
    "page": 60,
    "content_type": "text",
    "doc_id": "slide_576_60",
    "doc_type": "slide",
    "is_definition": false,
    "contains_equation": false,
    "importance": "high",
    "tags": [
      "2018",
      "transformer models",
      "BERT",
      "natural language processing",
      "Devlin"
    ]
  },
  {
    "text": "Pre-training Transformers Raffel et al, \u201cExploring the Limits of Transfer Learning with a Unified Text-to-Text Transformer\u201d, 2019 Brown et al, \u201cLanguage Models are Few-Shot Learners\u201d, 2020",
    "source": "ELEC/COMP 576: - Slide 61",
    "source_detail": "ELEC576-Lec07.pdf, Page 61",
    "lecture": "ELEC/COMP 576:",
    "lecture_number": "576",
    "page": 61,
    "content_type": "text",
    "doc_id": "slide_576_61",
    "doc_type": "slide",
    "is_definition": false,
    "contains_equation": false,
    "importance": "high",
    "tags": [
      "attention",
      "transfer learning"
    ]
  },
  {
    "text": "Transformers for vision",
    "source": "ELEC/COMP 576: - Slide 62",
    "source_detail": "ELEC576-Lec07.pdf, Page 62",
    "lecture": "ELEC/COMP 576:",
    "lecture_number": "576",
    "page": 62,
    "content_type": "text",
    "doc_id": "slide_576_62",
    "doc_type": "slide",
    "is_definition": false,
    "contains_equation": false,
    "importance": "high",
    "tags": [
      "attention"
    ]
  },
  {
    "text": "Transformers for vision \u2022 How do we build transformers for vision tasks? \u2022 What will our sequences be?",
    "source": "ELEC/COMP 576: - Slide 63",
    "source_detail": "ELEC576-Lec07.pdf, Page 63",
    "lecture": "ELEC/COMP 576:",
    "lecture_number": "576",
    "page": 63,
    "content_type": "text",
    "doc_id": "slide_576_63",
    "doc_type": "slide",
    "is_definition": false,
    "contains_equation": false,
    "importance": "high",
    "tags": [
      "attention"
    ]
  },
  {
    "text": "Transformers for vision \u2022 What will our sequences be? \u2022 What if each pixel is an element of the sequence?",
    "source": "ELEC/COMP 576: - Slide 64",
    "source_detail": "ELEC576-Lec07.pdf, Page 64",
    "lecture": "ELEC/COMP 576:",
    "lecture_number": "576",
    "page": 64,
    "content_type": "text",
    "doc_id": "slide_576_64",
    "doc_type": "slide",
    "is_definition": false,
    "contains_equation": false,
    "importance": "medium",
    "tags": [
      "attention"
    ]
  },
  {
    "text": "Transformers for vision \u2022 Pixels as sequence: ImageNet 224x224 images \u2192 ~50K length sequence! \u2022 Even worse for High-res images and video \u2022 Computation is quadratic in the input sequence length! \u2022 Memory consumption is huge!",
    "source": "ELEC/COMP 576: - Slide 65",
    "source_detail": "ELEC576-Lec07.pdf, Page 65",
    "lecture": "ELEC/COMP 576:",
    "lecture_number": "576",
    "page": 65,
    "content_type": "figure",
    "doc_id": "slide_576_65",
    "doc_type": "slide",
    "is_definition": false,
    "contains_equation": true,
    "importance": "high",
    "tags": [
      "attention"
    ]
  },
  {
    "text": "Transformers for vision",
    "source": "ELEC/COMP 576: - Slide 66",
    "source_detail": "ELEC576-Lec07.pdf, Page 66",
    "lecture": "ELEC/COMP 576:",
    "lecture_number": "576",
    "page": 66,
    "content_type": "text",
    "doc_id": "slide_576_66",
    "doc_type": "slide",
    "is_definition": false,
    "contains_equation": false,
    "importance": "high",
    "tags": [
      "attention"
    ]
  },
  {
    "text": "Transformers for vision \u2022 Pixels as sequence: ImageNet 224x224 images \u2192 ~50K length sequence! \u2022 Even worse for High-res images and video \u2022 Computation is quadratic in the input sequence length! \u2022 Memory consumption is huge! \u2022 So how do we deal with this issue?",
    "source": "ELEC/COMP 576: - Slide 67",
    "source_detail": "ELEC576-Lec07.pdf, Page 67",
    "lecture": "ELEC/COMP 576:",
    "lecture_number": "576",
    "page": 67,
    "content_type": "figure",
    "doc_id": "slide_576_67",
    "doc_type": "slide",
    "is_definition": false,
    "contains_equation": true,
    "importance": "high",
    "tags": [
      "attention"
    ]
  },
  {
    "text": "Transformers for vision \u2022 Pixels as sequence: ImageNet 224x224 images \u2192 ~50K length sequence! \u2022 Even worse for High-res images and video \u2022 Computation is quadratic in the input sequence length! \u2022 Memory consumption is huge! \u2022 So how do we deal with this issue? Use patches!",
    "source": "ELEC/COMP 576: - Slide 68",
    "source_detail": "ELEC576-Lec07.pdf, Page 68",
    "lecture": "ELEC/COMP 576:",
    "lecture_number": "576",
    "page": 68,
    "content_type": "figure",
    "doc_id": "slide_576_68",
    "doc_type": "slide",
    "is_definition": false,
    "contains_equation": true,
    "importance": "high",
    "tags": [
      "attention"
    ]
  },
  {
    "text": "Vision Transformer (ViT)",
    "source": "ELEC/COMP 576: - Slide 69",
    "source_detail": "ELEC576-Lec07.pdf, Page 69",
    "lecture": "ELEC/COMP 576:",
    "lecture_number": "576",
    "page": 69,
    "content_type": "text",
    "doc_id": "slide_576_69",
    "doc_type": "slide",
    "is_definition": true,
    "contains_equation": false,
    "importance": "high",
    "tags": [
      "attention"
    ]
  },
  {
    "text": "Vision Transformer (ViT)",
    "source": "ELEC/COMP 576: - Slide 70",
    "source_detail": "ELEC576-Lec07.pdf, Page 70",
    "lecture": "ELEC/COMP 576:",
    "lecture_number": "576",
    "page": 70,
    "content_type": "text",
    "doc_id": "slide_576_70",
    "doc_type": "slide",
    "is_definition": true,
    "contains_equation": false,
    "importance": "high",
    "tags": [
      "attention"
    ]
  },
  {
    "text": "Vision Transformer (ViT)",
    "source": "ELEC/COMP 576: - Slide 71",
    "source_detail": "ELEC576-Lec07.pdf, Page 71",
    "lecture": "ELEC/COMP 576:",
    "lecture_number": "576",
    "page": 71,
    "content_type": "text",
    "doc_id": "slide_576_71",
    "doc_type": "slide",
    "is_definition": true,
    "contains_equation": false,
    "importance": "high",
    "tags": [
      "attention"
    ]
  },
  {
    "text": "Vision Transformer (ViT)",
    "source": "ELEC/COMP 576: - Slide 72",
    "source_detail": "ELEC576-Lec07.pdf, Page 72",
    "lecture": "ELEC/COMP 576:",
    "lecture_number": "576",
    "page": 72,
    "content_type": "text",
    "doc_id": "slide_576_72",
    "doc_type": "slide",
    "is_definition": true,
    "contains_equation": false,
    "importance": "high",
    "tags": [
      "attention"
    ]
  },
  {
    "text": "Vision Transformer (ViT)",
    "source": "ELEC/COMP 576: - Slide 73",
    "source_detail": "ELEC576-Lec07.pdf, Page 73",
    "lecture": "ELEC/COMP 576:",
    "lecture_number": "576",
    "page": 73,
    "content_type": "text",
    "doc_id": "slide_576_73",
    "doc_type": "slide",
    "is_definition": true,
    "contains_equation": false,
    "importance": "high",
    "tags": [
      "attention"
    ]
  },
  {
    "text": "Vision Transformer (ViT)",
    "source": "ELEC/COMP 576: - Slide 74",
    "source_detail": "ELEC576-Lec07.pdf, Page 74",
    "lecture": "ELEC/COMP 576:",
    "lecture_number": "576",
    "page": 74,
    "content_type": "text",
    "doc_id": "slide_576_74",
    "doc_type": "slide",
    "is_definition": true,
    "contains_equation": false,
    "importance": "high",
    "tags": [
      "attention"
    ]
  },
  {
    "text": "Vision Transformer (ViT)",
    "source": "ELEC/COMP 576: - Slide 75",
    "source_detail": "ELEC576-Lec07.pdf, Page 75",
    "lecture": "ELEC/COMP 576:",
    "lecture_number": "576",
    "page": 75,
    "content_type": "text",
    "doc_id": "slide_576_75",
    "doc_type": "slide",
    "is_definition": true,
    "contains_equation": false,
    "importance": "high",
    "tags": [
      "attention"
    ]
  },
  {
    "text": "Vision Transformer (ViT) No conv layers!",
    "source": "ELEC/COMP 576: - Slide 76",
    "source_detail": "ELEC576-Lec07.pdf, Page 76",
    "lecture": "ELEC/COMP 576:",
    "lecture_number": "576",
    "page": 76,
    "content_type": "text",
    "doc_id": "slide_576_76",
    "doc_type": "slide",
    "is_definition": false,
    "contains_equation": false,
    "importance": "high",
    "tags": [
      "cnn",
      "attention"
    ]
  },
  {
    "text": "Vision Transformer (ViT)",
    "source": "ELEC/COMP 576: - Slide 77",
    "source_detail": "ELEC576-Lec07.pdf, Page 77",
    "lecture": "ELEC/COMP 576:",
    "lecture_number": "576",
    "page": 77,
    "content_type": "text",
    "doc_id": "slide_576_77",
    "doc_type": "slide",
    "is_definition": true,
    "contains_equation": false,
    "importance": "high",
    "tags": [
      "attention"
    ]
  },
  {
    "text": "Vision Transformer (ViT)",
    "source": "ELEC/COMP 576: - Slide 78",
    "source_detail": "ELEC576-Lec07.pdf, Page 78",
    "lecture": "ELEC/COMP 576:",
    "lecture_number": "576",
    "page": 78,
    "content_type": "text",
    "doc_id": "slide_576_78",
    "doc_type": "slide",
    "is_definition": true,
    "contains_equation": false,
    "importance": "high",
    "tags": [
      "attention"
    ]
  },
  {
    "text": "So performing classification using ViT is straightforward \u2013 use the [CLS] \u2022 embedding How do we perform dense prediction? E.g. Segmentation map/Depth \u2022 map, etc",
    "source": "ELEC/COMP 576: - Slide 79",
    "source_detail": "ELEC576-Lec07.pdf, Page 79",
    "lecture": "ELEC/COMP 576:",
    "lecture_number": "576",
    "page": 79,
    "content_type": "text",
    "doc_id": "slide_576_79",
    "doc_type": "slide",
    "is_definition": false,
    "contains_equation": true,
    "importance": "high",
    "tags": [
      "dense prediction",
      "depth map",
      "classification",
      "ViT",
      "segmentation map"
    ]
  },
  {
    "text": "Dense Prediction Transformer Ranftl et al 2021 Supervised Training",
    "source": "ELEC/COMP 576: - Slide 80",
    "source_detail": "ELEC576-Lec07.pdf, Page 80",
    "lecture": "ELEC/COMP 576:",
    "lecture_number": "576",
    "page": 80,
    "content_type": "text",
    "doc_id": "slide_576_80",
    "doc_type": "slide",
    "is_definition": false,
    "contains_equation": true,
    "importance": "high",
    "tags": [
      "attention"
    ]
  },
  {
    "text": "Dense Prediction Transformer ViT",
    "source": "ELEC/COMP 576: - Slide 81",
    "source_detail": "ELEC576-Lec07.pdf, Page 81",
    "lecture": "ELEC/COMP 576:",
    "lecture_number": "576",
    "page": 81,
    "content_type": "text",
    "doc_id": "slide_576_81",
    "doc_type": "slide",
    "is_definition": false,
    "contains_equation": false,
    "importance": "high",
    "tags": [
      "attention"
    ]
  },
  {
    "text": "Dense Prediction Transformer",
    "source": "ELEC/COMP 576: - Slide 82",
    "source_detail": "ELEC576-Lec07.pdf, Page 82",
    "lecture": "ELEC/COMP 576:",
    "lecture_number": "576",
    "page": 82,
    "content_type": "text",
    "doc_id": "slide_576_82",
    "doc_type": "slide",
    "is_definition": false,
    "contains_equation": false,
    "importance": "high",
    "tags": [
      "attention"
    ]
  },
  {
    "text": "Dense Prediction Transformer But you can do more than depth estimation with this architecture",
    "source": "ELEC/COMP 576: - Slide 83",
    "source_detail": "ELEC576-Lec07.pdf, Page 83",
    "lecture": "ELEC/COMP 576:",
    "lecture_number": "576",
    "page": 83,
    "content_type": "text",
    "doc_id": "slide_576_83",
    "doc_type": "slide",
    "is_definition": false,
    "contains_equation": false,
    "importance": "medium",
    "tags": [
      "attention"
    ]
  },
  {
    "text": "Masked Autoencoders He at al 2021 Unsupervised Training",
    "source": "ELEC/COMP 576: - Slide 84",
    "source_detail": "ELEC576-Lec07.pdf, Page 84",
    "lecture": "ELEC/COMP 576:",
    "lecture_number": "576",
    "page": 84,
    "content_type": "text",
    "doc_id": "slide_576_84",
    "doc_type": "slide",
    "is_definition": false,
    "contains_equation": true,
    "importance": "high",
    "tags": [
      "generative models"
    ]
  },
  {
    "text": "Masked Autoencoders He at al 2021 Series of transformer blocks (process the mask tokens too) ViT (don\u2019t process the mask tokens)",
    "source": "ELEC/COMP 576: - Slide 85",
    "source_detail": "ELEC576-Lec07.pdf, Page 85",
    "lecture": "ELEC/COMP 576:",
    "lecture_number": "576",
    "page": 85,
    "content_type": "text",
    "doc_id": "slide_576_85",
    "doc_type": "slide",
    "is_definition": false,
    "contains_equation": false,
    "importance": "medium",
    "tags": [
      "attention",
      "generative models"
    ]
  },
  {
    "text": "Masked Autoencoders Acc. On Imagnet-1k With strong regularization and \u201cgood recipe\u201d for training Pre-training done on ImageNet-1k",
    "source": "ELEC/COMP 576: - Slide 86",
    "source_detail": "ELEC576-Lec07.pdf, Page 86",
    "lecture": "ELEC/COMP 576:",
    "lecture_number": "576",
    "page": 86,
    "content_type": "figure",
    "doc_id": "slide_576_86",
    "doc_type": "slide",
    "is_definition": false,
    "contains_equation": false,
    "importance": "high",
    "tags": [
      "regularization",
      "generative models"
    ]
  },
  {
    "text": "CLIP Radford et al 2021 Training with language supervision",
    "source": "ELEC/COMP 576: - Slide 87",
    "source_detail": "ELEC576-Lec07.pdf, Page 87",
    "lecture": "ELEC/COMP 576:",
    "lecture_number": "576",
    "page": 87,
    "content_type": "text",
    "doc_id": "slide_576_87",
    "doc_type": "slide",
    "is_definition": false,
    "contains_equation": false,
    "importance": "high",
    "tags": [
      "CLIP",
      "language supervision",
      "Training",
      "2021",
      "Radford et al"
    ]
  },
  {
    "text": "CLIP \u2022 Trained on a proprietary 400M image-caption paired dataset \u2022 Image encoder is ViT \u2022 Training done with contrastive loss \u2022 Can do decent zero-shot classification, cross-modal retrieval (retrieve image from text or vice versa)",
    "source": "ELEC/COMP 576: - Slide 88",
    "source_detail": "ELEC576-Lec07.pdf, Page 88",
    "lecture": "ELEC/COMP 576:",
    "lecture_number": "576",
    "page": 88,
    "content_type": "figure",
    "doc_id": "slide_576_88",
    "doc_type": "slide",
    "is_definition": false,
    "contains_equation": false,
    "importance": "high",
    "tags": [
      "loss functions"
    ]
  },
  {
    "text": "CLIP Zero shot classification \u2022",
    "source": "ELEC/COMP 576: - Slide 89",
    "source_detail": "ELEC576-Lec07.pdf, Page 89",
    "lecture": "ELEC/COMP 576:",
    "lecture_number": "576",
    "page": 89,
    "content_type": "text",
    "doc_id": "slide_576_89",
    "doc_type": "slide",
    "is_definition": false,
    "contains_equation": false,
    "importance": "high",
    "tags": [
      "CLIP",
      "zero shot classification"
    ]
  },
  {
    "text": "Why Training is Unstable Variance of activations/gradients grows multiplicatively [Xu, Huang, Li]",
    "source": "ELEC/COMP 576: - Slide 3",
    "source_detail": "ELEC576-Lec08.pdf, Page 3",
    "lecture": "ELEC/COMP 576:",
    "lecture_number": "576",
    "page": 3,
    "content_type": "text",
    "doc_id": "slide_576_3",
    "doc_type": "slide",
    "is_definition": false,
    "contains_equation": true,
    "importance": "high",
    "tags": [
      "neural networks"
    ]
  },
  {
    "text": "Interesting Question Are there modifications to an RNN such that it can \u2022 combat these gradient problems?",
    "source": "ELEC/COMP 576: - Slide 4",
    "source_detail": "ELEC576-Lec08.pdf, Page 4",
    "lecture": "ELEC/COMP 576:",
    "lecture_number": "576",
    "page": 4,
    "content_type": "text",
    "doc_id": "slide_576_4",
    "doc_type": "slide",
    "is_definition": false,
    "contains_equation": false,
    "importance": "high",
    "tags": [
      "rnn",
      "neural networks"
    ]
  },
  {
    "text": "RNNs with Longer Term Memory",
    "source": "ELEC/COMP 576: - Slide 5",
    "source_detail": "ELEC576-Lec08.pdf, Page 5",
    "lecture": "ELEC/COMP 576:",
    "lecture_number": "576",
    "page": 5,
    "content_type": "text",
    "doc_id": "slide_576_5",
    "doc_type": "slide",
    "is_definition": false,
    "contains_equation": false,
    "importance": "high",
    "tags": [
      "rnn",
      "neural networks"
    ]
  },
  {
    "text": "Motivation The need to remember certain events for arbitrarily \u2022 long periods of time (Non-Markovian) The need to forget certain events \u2022",
    "source": "ELEC/COMP 576: - Slide 6",
    "source_detail": "ELEC576-Lec08.pdf, Page 6",
    "lecture": "ELEC/COMP 576:",
    "lecture_number": "576",
    "page": 6,
    "content_type": "text",
    "doc_id": "slide_576_6",
    "doc_type": "slide",
    "is_definition": false,
    "contains_equation": false,
    "importance": "high",
    "tags": [
      "Non-Markovian",
      "Memory",
      "Motivation",
      "Forgetting"
    ]
  },
  {
    "text": "Long Short Term Memory 3 gates \u2022 Input \u2022 Forget \u2022 Output \u2022 [Zygmunt Z.]",
    "source": "ELEC/COMP 576: - Slide 7",
    "source_detail": "ELEC576-Lec08.pdf, Page 7",
    "lecture": "ELEC/COMP 576:",
    "lecture_number": "576",
    "page": 7,
    "content_type": "text",
    "doc_id": "slide_576_7",
    "doc_type": "slide",
    "is_definition": true,
    "contains_equation": false,
    "importance": "high",
    "tags": [
      "Forget",
      "Output",
      "Input",
      "Long Short Term Memory",
      "gates"
    ]
  },
  {
    "text": "LSTM Formulation [Alex Graves, Navdeep Jaitly]",
    "source": "ELEC/COMP 576: - Slide 8",
    "source_detail": "ELEC576-Lec08.pdf, Page 8",
    "lecture": "ELEC/COMP 576:",
    "lecture_number": "576",
    "page": 8,
    "content_type": "text",
    "doc_id": "slide_576_8",
    "doc_type": "slide",
    "is_definition": false,
    "contains_equation": true,
    "importance": "high",
    "tags": [
      "rnn"
    ]
  },
  {
    "text": "Preserving Gradients [Hochreiter, Schmidhuber]",
    "source": "ELEC/COMP 576: - Slide 9",
    "source_detail": "ELEC576-Lec08.pdf, Page 9",
    "lecture": "ELEC/COMP 576:",
    "lecture_number": "576",
    "page": 9,
    "content_type": "text",
    "doc_id": "slide_576_9",
    "doc_type": "slide",
    "is_definition": false,
    "contains_equation": true,
    "importance": "high",
    "tags": [
      "Hochreiter",
      "backpropagation",
      "Preserving Gradients",
      "neural networks",
      "Schmidhuber"
    ]
  },
  {
    "text": "Gated Recurrent Unit 2 gates \u2022 Reset \u2022 Combine new \u2022 input with previous memory Update \u2022 How long the \u2022 [Zygmunt Z.] previous memory should stay",
    "source": "ELEC/COMP 576: - Slide 10",
    "source_detail": "ELEC576-Lec08.pdf, Page 10",
    "lecture": "ELEC/COMP 576:",
    "lecture_number": "576",
    "page": 10,
    "content_type": "text",
    "doc_id": "slide_576_10",
    "doc_type": "slide",
    "is_definition": false,
    "contains_equation": false,
    "importance": "high",
    "tags": [
      "rnn"
    ]
  },
  {
    "text": "GRU Formulation [Danny Britz]",
    "source": "ELEC/COMP 576: - Slide 11",
    "source_detail": "ELEC576-Lec08.pdf, Page 11",
    "lecture": "ELEC/COMP 576:",
    "lecture_number": "576",
    "page": 11,
    "content_type": "text",
    "doc_id": "slide_576_11",
    "doc_type": "slide",
    "is_definition": false,
    "contains_equation": true,
    "importance": "high",
    "tags": [
      "rnn",
      "neural networks"
    ]
  },
  {
    "text": "LSTM & GRU Benefits Remember for longer temporal durations \u2022 RNN has issues for remembering longer \u2022 durations Able to have feedback flow at different strengths \u2022 depending on inputs",
    "source": "ELEC/COMP 576: - Slide 12",
    "source_detail": "ELEC576-Lec08.pdf, Page 12",
    "lecture": "ELEC/COMP 576:",
    "lecture_number": "576",
    "page": 12,
    "content_type": "text",
    "doc_id": "slide_576_12",
    "doc_type": "slide",
    "is_definition": false,
    "contains_equation": false,
    "importance": "high",
    "tags": [
      "rnn",
      "neural networks"
    ]
  },
  {
    "text": "Differences between LSTM & GRU GRU has two gates, while LSTM has three gates \u2022 GRU does not have internal memory \u2022 GRU does not use a second nonlinearity for \u2022 computing the output",
    "source": "ELEC/COMP 576: - Slide 13",
    "source_detail": "ELEC576-Lec08.pdf, Page 13",
    "lecture": "ELEC/COMP 576:",
    "lecture_number": "576",
    "page": 13,
    "content_type": "text",
    "doc_id": "slide_576_13",
    "doc_type": "slide",
    "is_definition": true,
    "contains_equation": false,
    "importance": "high",
    "tags": [
      "rnn"
    ]
  },
  {
    "text": "Visual Difference of LSTM & GRU LSTM GRU [Chris Olah]",
    "source": "ELEC/COMP 576: - Slide 14",
    "source_detail": "ELEC576-Lec08.pdf, Page 14",
    "lecture": "ELEC/COMP 576:",
    "lecture_number": "576",
    "page": 14,
    "content_type": "text",
    "doc_id": "slide_576_14",
    "doc_type": "slide",
    "is_definition": false,
    "contains_equation": false,
    "importance": "medium",
    "tags": [
      "rnn"
    ]
  },
  {
    "text": "LSTM vs GRU Results [Chung, Gulcehre, Cho, Bengio]",
    "source": "ELEC/COMP 576: - Slide 15",
    "source_detail": "ELEC576-Lec08.pdf, Page 15",
    "lecture": "ELEC/COMP 576:",
    "lecture_number": "576",
    "page": 15,
    "content_type": "text",
    "doc_id": "slide_576_15",
    "doc_type": "slide",
    "is_definition": false,
    "contains_equation": false,
    "importance": "high",
    "tags": [
      "rnn"
    ]
  },
  {
    "text": "Other Methods for Stabilizing RNN Training",
    "source": "ELEC/COMP 576: - Slide 16",
    "source_detail": "ELEC576-Lec08.pdf, Page 16",
    "lecture": "ELEC/COMP 576:",
    "lecture_number": "576",
    "page": 16,
    "content_type": "text",
    "doc_id": "slide_576_16",
    "doc_type": "slide",
    "is_definition": false,
    "contains_equation": false,
    "importance": "medium",
    "tags": [
      "rnn",
      "neural networks"
    ]
  },
  {
    "text": "Why Training is Unstable Variance of activations/gradients grows multiplicatively [Xu, Huang, Li]",
    "source": "ELEC/COMP 576: - Slide 17",
    "source_detail": "ELEC576-Lec08.pdf, Page 17",
    "lecture": "ELEC/COMP 576:",
    "lecture_number": "576",
    "page": 17,
    "content_type": "text",
    "doc_id": "slide_576_17",
    "doc_type": "slide",
    "is_definition": false,
    "contains_equation": true,
    "importance": "high",
    "tags": [
      "neural networks"
    ]
  },
  {
    "text": "Stabilizing Activations & Gradients We want [Xu, Huang, Li]",
    "source": "ELEC/COMP 576: - Slide 18",
    "source_detail": "ELEC576-Lec08.pdf, Page 18",
    "lecture": "ELEC/COMP 576:",
    "lecture_number": "576",
    "page": 18,
    "content_type": "text",
    "doc_id": "slide_576_18",
    "doc_type": "slide",
    "is_definition": false,
    "contains_equation": false,
    "importance": "high",
    "tags": [
      "neural networks"
    ]
  },
  {
    "text": "Taylor Expansions of Different Activation Functions [Xu, Huang, Li]",
    "source": "ELEC/COMP 576: - Slide 19",
    "source_detail": "ELEC576-Lec08.pdf, Page 19",
    "lecture": "ELEC/COMP 576:",
    "lecture_number": "576",
    "page": 19,
    "content_type": "text",
    "doc_id": "slide_576_19",
    "doc_type": "slide",
    "is_definition": false,
    "contains_equation": true,
    "importance": "high",
    "tags": [
      "neural networks"
    ]
  },
  {
    "text": "Layer Normalization Similar to batch normalization \u2022 Apply it to RNNs to stabilize the hidden state \u2022 dynamics [Ba, Kiros, Hinton]",
    "source": "ELEC/COMP 576: - Slide 20",
    "source_detail": "ELEC576-Lec08.pdf, Page 20",
    "lecture": "ELEC/COMP 576:",
    "lecture_number": "576",
    "page": 20,
    "content_type": "text",
    "doc_id": "slide_576_20",
    "doc_type": "slide",
    "is_definition": false,
    "contains_equation": false,
    "importance": "high",
    "tags": [
      "regularization",
      "rnn",
      "neural networks"
    ]
  },
  {
    "text": "Layer Normalization Results [Ba, Kiros, Hinton]",
    "source": "ELEC/COMP 576: - Slide 21",
    "source_detail": "ELEC576-Lec08.pdf, Page 21",
    "lecture": "ELEC/COMP 576:",
    "lecture_number": "576",
    "page": 21,
    "content_type": "text",
    "doc_id": "slide_576_21",
    "doc_type": "slide",
    "is_definition": false,
    "contains_equation": true,
    "importance": "high",
    "tags": [
      "Results",
      "Hinton",
      "Kiros",
      "Layer Normalization",
      "Ba"
    ]
  },
  {
    "text": "Streamlining Normalization [Liao, Kawaguchi, Poggio]",
    "source": "ELEC/COMP 576: - Slide 22",
    "source_detail": "ELEC576-Lec08.pdf, Page 22",
    "lecture": "ELEC/COMP 576:",
    "lecture_number": "576",
    "page": 22,
    "content_type": "text",
    "doc_id": "slide_576_22",
    "doc_type": "slide",
    "is_definition": false,
    "contains_equation": true,
    "importance": "high",
    "tags": [
      "Streamlining",
      "Liao",
      "Kawaguchi",
      "Poggio",
      "Normalization"
    ]
  },
  {
    "text": "Streamlining Normalization [Liao, Kawaguchi, Poggio]",
    "source": "ELEC/COMP 576: - Slide 23",
    "source_detail": "ELEC576-Lec08.pdf, Page 23",
    "lecture": "ELEC/COMP 576:",
    "lecture_number": "576",
    "page": 23,
    "content_type": "text",
    "doc_id": "slide_576_23",
    "doc_type": "slide",
    "is_definition": false,
    "contains_equation": true,
    "importance": "high",
    "tags": [
      "Streamlining",
      "Liao",
      "Kawaguchi",
      "Poggio",
      "Normalization"
    ]
  },
  {
    "text": "Streamlining Normalization for RNNs [Liao, Kawaguchi, Poggio]",
    "source": "ELEC/COMP 576: - Slide 24",
    "source_detail": "ELEC576-Lec08.pdf, Page 24",
    "lecture": "ELEC/COMP 576:",
    "lecture_number": "576",
    "page": 24,
    "content_type": "text",
    "doc_id": "slide_576_24",
    "doc_type": "slide",
    "is_definition": false,
    "contains_equation": true,
    "importance": "high",
    "tags": [
      "rnn",
      "neural networks"
    ]
  },
  {
    "text": "Streamlining Normalization Results [Liao, Kawaguchi, Poggio]",
    "source": "ELEC/COMP 576: - Slide 25",
    "source_detail": "ELEC576-Lec08.pdf, Page 25",
    "lecture": "ELEC/COMP 576:",
    "lecture_number": "576",
    "page": 25,
    "content_type": "text",
    "doc_id": "slide_576_25",
    "doc_type": "slide",
    "is_definition": false,
    "contains_equation": true,
    "importance": "high",
    "tags": [
      "Streamlining",
      "Liao",
      "Results",
      "Kawaguchi",
      "Normalization"
    ]
  },
  {
    "text": "Streamlining Normalization RNN Results [Liao, Kawaguchi, Poggio]",
    "source": "ELEC/COMP 576: - Slide 26",
    "source_detail": "ELEC576-Lec08.pdf, Page 26",
    "lecture": "ELEC/COMP 576:",
    "lecture_number": "576",
    "page": 26,
    "content_type": "text",
    "doc_id": "slide_576_26",
    "doc_type": "slide",
    "is_definition": false,
    "contains_equation": true,
    "importance": "high",
    "tags": [
      "rnn",
      "neural networks"
    ]
  },
  {
    "text": "Normalization Techniques [Liao, Kawaguchi, Poggio]",
    "source": "ELEC/COMP 576: - Slide 27",
    "source_detail": "ELEC576-Lec08.pdf, Page 27",
    "lecture": "ELEC/COMP 576:",
    "lecture_number": "576",
    "page": 27,
    "content_type": "text",
    "doc_id": "slide_576_27",
    "doc_type": "slide",
    "is_definition": false,
    "contains_equation": true,
    "importance": "high",
    "tags": [
      "Liao",
      "Kawaguchi",
      "Poggio",
      "Normalization Techniques"
    ]
  },
  {
    "text": "RNN Applications Speech Recognition \u2022 Natural Language Processing \u2022 Action Recognition \u2022 Machine Translation \u2022 Many more to come \u2022",
    "source": "ELEC/COMP 576: - Slide 29",
    "source_detail": "ELEC576-Lec08.pdf, Page 29",
    "lecture": "ELEC/COMP 576:",
    "lecture_number": "576",
    "page": 29,
    "content_type": "text",
    "doc_id": "slide_576_29",
    "doc_type": "slide",
    "is_definition": false,
    "contains_equation": false,
    "importance": "high",
    "tags": [
      "rnn",
      "neural networks"
    ]
  },
  {
    "text": "Bidirectional RNNs The output at time t does not depend on previous \u2022 time steps but also the future Two RNNs stacked on top of each other \u2022 [Danny Britz]",
    "source": "ELEC/COMP 576: - Slide 30",
    "source_detail": "ELEC576-Lec08.pdf, Page 30",
    "lecture": "ELEC/COMP 576:",
    "lecture_number": "576",
    "page": 30,
    "content_type": "text",
    "doc_id": "slide_576_30",
    "doc_type": "slide",
    "is_definition": false,
    "contains_equation": false,
    "importance": "medium",
    "tags": [
      "rnn",
      "neural networks"
    ]
  },
  {
    "text": "Deep RNNs Stack them on top of each other \u2022 The output of the previous RNN is the input to the \u2022 next one [Danny Britz]",
    "source": "ELEC/COMP 576: - Slide 31",
    "source_detail": "ELEC576-Lec08.pdf, Page 31",
    "lecture": "ELEC/COMP 576:",
    "lecture_number": "576",
    "page": 31,
    "content_type": "text",
    "doc_id": "slide_576_31",
    "doc_type": "slide",
    "is_definition": false,
    "contains_equation": false,
    "importance": "medium",
    "tags": [
      "rnn",
      "neural networks"
    ]
  },
  {
    "text": "Speech Recognition \u2022 Infer phonemes from the past and the future \u2022 Bidirectional Stacked LSTM [Alex Graves, Navdeep Jaitly, Abdel-rahman Mohamed]",
    "source": "ELEC/COMP 576: - Slide 32",
    "source_detail": "ELEC576-Lec08.pdf, Page 32",
    "lecture": "ELEC/COMP 576:",
    "lecture_number": "576",
    "page": 32,
    "content_type": "text",
    "doc_id": "slide_576_32",
    "doc_type": "slide",
    "is_definition": false,
    "contains_equation": false,
    "importance": "high",
    "tags": [
      "rnn"
    ]
  },
  {
    "text": "Conversational Speech Recognition Achieving human \u2022 parity Combining RNN \u2022 and CNN [Xiong et al.]",
    "source": "ELEC/COMP 576: - Slide 33",
    "source_detail": "ELEC576-Lec08.pdf, Page 33",
    "lecture": "ELEC/COMP 576:",
    "lecture_number": "576",
    "page": 33,
    "content_type": "text",
    "doc_id": "slide_576_33",
    "doc_type": "slide",
    "is_definition": false,
    "contains_equation": true,
    "importance": "high",
    "tags": [
      "cnn",
      "rnn",
      "neural networks"
    ]
  },
  {
    "text": "Natural Language Processing \u2022 Infer character distribution from past characters in the sequence \u2022 Remember for longer durations [Soumith Chantala]",
    "source": "ELEC/COMP 576: - Slide 34",
    "source_detail": "ELEC576-Lec08.pdf, Page 34",
    "lecture": "ELEC/COMP 576:",
    "lecture_number": "576",
    "page": 34,
    "content_type": "text",
    "doc_id": "slide_576_34",
    "doc_type": "slide",
    "is_definition": false,
    "contains_equation": false,
    "importance": "high",
    "tags": [
      "character distribution",
      "sequence prediction",
      "memory retention",
      "Natural Language Processing"
    ]
  },
  {
    "text": "Contextual LSTM for NLP Tasks \u2022 Using a word embedding with LSTM layers to learn sentiments \u2022 Incorporating a thought unit [Ghost et al.]",
    "source": "ELEC/COMP 576: - Slide 35",
    "source_detail": "ELEC576-Lec08.pdf, Page 35",
    "lecture": "ELEC/COMP 576:",
    "lecture_number": "576",
    "page": 35,
    "content_type": "text",
    "doc_id": "slide_576_35",
    "doc_type": "slide",
    "is_definition": false,
    "contains_equation": false,
    "importance": "high",
    "tags": [
      "rnn"
    ]
  },
  {
    "text": "Action Recognition \u2022 Using LSTMs and CNN for videos \u2022 CNN creates a feature vector that is feed into LSTM [Donahue et al.]",
    "source": "ELEC/COMP 576: - Slide 36",
    "source_detail": "ELEC576-Lec08.pdf, Page 36",
    "lecture": "ELEC/COMP 576:",
    "lecture_number": "576",
    "page": 36,
    "content_type": "text",
    "doc_id": "slide_576_36",
    "doc_type": "slide",
    "is_definition": false,
    "contains_equation": false,
    "importance": "high",
    "tags": [
      "cnn",
      "rnn",
      "neural networks"
    ]
  },
  {
    "text": "Google\u2019s Neural Machine Translation System \u2022 Encoder and Decoder LSTMs \u2022 Attention model [Yonghui Wu et al.]",
    "source": "ELEC/COMP 576: - Slide 37",
    "source_detail": "ELEC576-Lec08.pdf, Page 37",
    "lecture": "ELEC/COMP 576:",
    "lecture_number": "576",
    "page": 37,
    "content_type": "text",
    "doc_id": "slide_576_37",
    "doc_type": "slide",
    "is_definition": false,
    "contains_equation": false,
    "importance": "high",
    "tags": [
      "attention",
      "rnn"
    ]
  },
  {
    "text": "Image Captioning Pt 1 \u2022 Combination of CNN and LSTM to caption images \u2022 Using a pretrained CNN for visual features [Vinyals, Toshev, Bengio, Erhan]",
    "source": "ELEC/COMP 576: - Slide 38",
    "source_detail": "ELEC576-Lec08.pdf, Page 38",
    "lecture": "ELEC/COMP 576:",
    "lecture_number": "576",
    "page": 38,
    "content_type": "figure",
    "doc_id": "slide_576_38",
    "doc_type": "slide",
    "is_definition": false,
    "contains_equation": false,
    "importance": "high",
    "tags": [
      "cnn",
      "rnn",
      "transfer learning",
      "neural networks"
    ]
  },
  {
    "text": "Image Captioning Pt 2 [Vinyals, Toshev, Bengio, Erhan]",
    "source": "ELEC/COMP 576: - Slide 39",
    "source_detail": "ELEC576-Lec08.pdf, Page 39",
    "lecture": "ELEC/COMP 576:",
    "lecture_number": "576",
    "page": 39,
    "content_type": "figure",
    "doc_id": "slide_576_39",
    "doc_type": "slide",
    "is_definition": false,
    "contains_equation": true,
    "importance": "high",
    "tags": [
      "Erhan",
      "Image Captioning",
      "Bengio",
      "Vinyals",
      "Toshev"
    ]
  },
  {
    "text": "Object Tracking \u2022 Using an object detector with an LSTM to track objects \u2022 Model the dynamics of video [Ning, Zhang, Huang, He, Wang]",
    "source": "ELEC/COMP 576: - Slide 40",
    "source_detail": "ELEC576-Lec08.pdf, Page 40",
    "lecture": "ELEC/COMP 576:",
    "lecture_number": "576",
    "page": 40,
    "content_type": "text",
    "doc_id": "slide_576_40",
    "doc_type": "slide",
    "is_definition": false,
    "contains_equation": false,
    "importance": "high",
    "tags": [
      "rnn"
    ]
  },
  {
    "text": "Neural Turing Machines \u2022 LSTM with external memory \u2022 Analogous to a Turing Machine [Chris Olah]",
    "source": "ELEC/COMP 576: - Slide 41",
    "source_detail": "ELEC576-Lec08.pdf, Page 41",
    "lecture": "ELEC/COMP 576:",
    "lecture_number": "576",
    "page": 41,
    "content_type": "text",
    "doc_id": "slide_576_41",
    "doc_type": "slide",
    "is_definition": true,
    "contains_equation": false,
    "importance": "high",
    "tags": [
      "rnn"
    ]
  },
  {
    "text": "WaveNet \u2022 Using stack of diluted layers \u2022 To generate next sample, it models conditional probability given previous samples [van den Oord et al.]",
    "source": "ELEC/COMP 576: - Slide 42",
    "source_detail": "ELEC576-Lec08.pdf, Page 42",
    "lecture": "ELEC/COMP 576:",
    "lecture_number": "576",
    "page": 42,
    "content_type": "text",
    "doc_id": "slide_576_42",
    "doc_type": "slide",
    "is_definition": false,
    "contains_equation": true,
    "importance": "high",
    "tags": [
      "sample generation",
      "diluted layers",
      "conditional probability",
      "WaveNet"
    ]
  },
  {
    "text": "DoomBot Doom Competition \u2022 Facebook won 1st place (F1) \u2022 https://www.youtube.com/watch? \u2022 v=94EPSjQH38Y",
    "source": "ELEC/COMP 576: - Slide 43",
    "source_detail": "ELEC576-Lec08.pdf, Page 43",
    "lecture": "ELEC/COMP 576:",
    "lecture_number": "576",
    "page": 43,
    "content_type": "text",
    "doc_id": "slide_576_43",
    "doc_type": "slide",
    "is_definition": false,
    "contains_equation": false,
    "importance": "low",
    "tags": [
      "DoomBot",
      "1st place",
      "Doom Competition",
      "F1",
      "Facebook"
    ]
  },
  {
    "text": "Character-level RNN Language Models",
    "source": "ELEC/COMP 576: - Slide 2",
    "source_detail": "ELEC576-Lec10.pdf, Page 2",
    "lecture": "ELEC/COMP 576:",
    "lecture_number": "576",
    "page": 2,
    "content_type": "text",
    "doc_id": "slide_576_2",
    "doc_type": "slide",
    "is_definition": false,
    "contains_equation": false,
    "importance": "high",
    "tags": [
      "rnn",
      "neural networks"
    ]
  },
  {
    "text": "Goal Model the probability distribution of the next \u2022 character in a sequence Given the previous characters \u2022 [Susanto, Chieu, Lu]",
    "source": "ELEC/COMP 576: - Slide 3",
    "source_detail": "ELEC576-Lec10.pdf, Page 3",
    "lecture": "ELEC/COMP 576:",
    "lecture_number": "576",
    "page": 3,
    "content_type": "text",
    "doc_id": "slide_576_3",
    "doc_type": "slide",
    "is_definition": false,
    "contains_equation": true,
    "importance": "high",
    "tags": [
      "modeling",
      "probability distribution",
      "character sequence",
      "previous characters"
    ]
  },
  {
    "text": "N-grams Group the characters into n characters \u2022 n=1 unigram \u2022 n=2 bigram \u2022 Useful for protein sequencing, computational \u2022 linguistics, etc.",
    "source": "ELEC/COMP 576: - Slide 4",
    "source_detail": "ELEC576-Lec10.pdf, Page 4",
    "lecture": "ELEC/COMP 576:",
    "lecture_number": "576",
    "page": 4,
    "content_type": "text",
    "doc_id": "slide_576_4",
    "doc_type": "slide",
    "is_definition": true,
    "contains_equation": false,
    "importance": "high",
    "tags": [
      "bigram",
      "protein sequencing",
      "N-grams",
      "computational linguistics",
      "unigram"
    ]
  },
  {
    "text": "Comparing Against N- Grams [Karpathy, Johnson, Li]",
    "source": "ELEC/COMP 576: - Slide 5",
    "source_detail": "ELEC576-Lec10.pdf, Page 5",
    "lecture": "ELEC/COMP 576:",
    "lecture_number": "576",
    "page": 5,
    "content_type": "text",
    "doc_id": "slide_576_5",
    "doc_type": "slide",
    "is_definition": false,
    "contains_equation": true,
    "importance": "high",
    "tags": [
      "Johnson",
      "Li",
      "Karpathy",
      "Comparative Analysis",
      "N-Grams"
    ]
  },
  {
    "text": "Remembering for Longer Durations [Karpathy, Johnson, Li]",
    "source": "ELEC/COMP 576: - Slide 6",
    "source_detail": "ELEC576-Lec10.pdf, Page 6",
    "lecture": "ELEC/COMP 576:",
    "lecture_number": "576",
    "page": 6,
    "content_type": "text",
    "doc_id": "slide_576_6",
    "doc_type": "slide",
    "is_definition": false,
    "contains_equation": false,
    "importance": "high",
    "tags": [
      "memory retention",
      "educational techniques",
      "cognitive psychology",
      "long-term memory"
    ]
  },
  {
    "text": "Character-Aware Neural Language Models [Kim, Jernite, Sontag, Rush]",
    "source": "ELEC/COMP 576: - Slide 7",
    "source_detail": "ELEC576-Lec10.pdf, Page 7",
    "lecture": "ELEC/COMP 576:",
    "lecture_number": "576",
    "page": 7,
    "content_type": "text",
    "doc_id": "slide_576_7",
    "doc_type": "slide",
    "is_definition": false,
    "contains_equation": true,
    "importance": "high",
    "tags": [
      "Deep Learning",
      "Neural Language Models",
      "Character-Aware",
      "Natural Language Processing"
    ]
  },
  {
    "text": "The Effectiveness of an RNN [Andrej Karpathy]",
    "source": "ELEC/COMP 576: - Slide 8",
    "source_detail": "ELEC576-Lec10.pdf, Page 8",
    "lecture": "ELEC/COMP 576:",
    "lecture_number": "576",
    "page": 8,
    "content_type": "text",
    "doc_id": "slide_576_8",
    "doc_type": "slide",
    "is_definition": false,
    "contains_equation": true,
    "importance": "high",
    "tags": [
      "rnn",
      "neural networks"
    ]
  },
  {
    "text": "The Effectiveness of an RNN [Andrej Karpathy]",
    "source": "ELEC/COMP 576: - Slide 9",
    "source_detail": "ELEC576-Lec10.pdf, Page 9",
    "lecture": "ELEC/COMP 576:",
    "lecture_number": "576",
    "page": 9,
    "content_type": "text",
    "doc_id": "slide_576_9",
    "doc_type": "slide",
    "is_definition": false,
    "contains_equation": true,
    "importance": "high",
    "tags": [
      "rnn",
      "neural networks"
    ]
  },
  {
    "text": "The Effectiveness of an RNN [Andrej Karpathy]",
    "source": "ELEC/COMP 576: - Slide 10",
    "source_detail": "ELEC576-Lec10.pdf, Page 10",
    "lecture": "ELEC/COMP 576:",
    "lecture_number": "576",
    "page": 10,
    "content_type": "text",
    "doc_id": "slide_576_10",
    "doc_type": "slide",
    "is_definition": false,
    "contains_equation": true,
    "importance": "high",
    "tags": [
      "rnn",
      "neural networks"
    ]
  },
  {
    "text": "The Effectiveness of an RNN Trained on War & Peace Iteration: 100 Iteration: 300 Iteration: 2000 [Andrej Karpathy]",
    "source": "ELEC/COMP 576: - Slide 11",
    "source_detail": "ELEC576-Lec10.pdf, Page 11",
    "lecture": "ELEC/COMP 576:",
    "lecture_number": "576",
    "page": 11,
    "content_type": "text",
    "doc_id": "slide_576_11",
    "doc_type": "slide",
    "is_definition": false,
    "contains_equation": true,
    "importance": "high",
    "tags": [
      "rnn",
      "neural networks"
    ]
  },
  {
    "text": "Visualize the Neurons of an RNN [Andrej Karpathy]",
    "source": "ELEC/COMP 576: - Slide 12",
    "source_detail": "ELEC576-Lec10.pdf, Page 12",
    "lecture": "ELEC/COMP 576:",
    "lecture_number": "576",
    "page": 12,
    "content_type": "text",
    "doc_id": "slide_576_12",
    "doc_type": "slide",
    "is_definition": false,
    "contains_equation": false,
    "importance": "medium",
    "tags": [
      "rnn",
      "neural networks"
    ]
  },
  {
    "text": "Visualize the Neurons of an RNN [Andrej Karpathy]",
    "source": "ELEC/COMP 576: - Slide 13",
    "source_detail": "ELEC576-Lec10.pdf, Page 13",
    "lecture": "ELEC/COMP 576:",
    "lecture_number": "576",
    "page": 13,
    "content_type": "text",
    "doc_id": "slide_576_13",
    "doc_type": "slide",
    "is_definition": false,
    "contains_equation": false,
    "importance": "high",
    "tags": [
      "rnn",
      "neural networks"
    ]
  },
  {
    "text": "Word-level RNN Language Models",
    "source": "ELEC/COMP 576: - Slide 14",
    "source_detail": "ELEC576-Lec10.pdf, Page 14",
    "lecture": "ELEC/COMP 576:",
    "lecture_number": "576",
    "page": 14,
    "content_type": "text",
    "doc_id": "slide_576_14",
    "doc_type": "slide",
    "is_definition": false,
    "contains_equation": false,
    "importance": "high",
    "tags": [
      "rnn",
      "neural networks"
    ]
  },
  {
    "text": "Goals Model the probability distribution of the next word \u2022 in a sequence Given the previous words \u2022 [Nicholas Leonard]",
    "source": "ELEC/COMP 576: - Slide 15",
    "source_detail": "ELEC576-Lec10.pdf, Page 15",
    "lecture": "ELEC/COMP 576:",
    "lecture_number": "576",
    "page": 15,
    "content_type": "text",
    "doc_id": "slide_576_15",
    "doc_type": "slide",
    "is_definition": false,
    "contains_equation": false,
    "importance": "high",
    "tags": [
      "sequence",
      "previous words",
      "next word",
      "probability distribution"
    ]
  },
  {
    "text": "Global Vectors for Word Representation (GloVe) Provide semantic information/context for words \u2022 Unsupervised method for learning word \u2022 representations [Richard Socher]",
    "source": "ELEC/COMP 576: - Slide 16",
    "source_detail": "ELEC576-Lec10.pdf, Page 16",
    "lecture": "ELEC/COMP 576:",
    "lecture_number": "576",
    "page": 16,
    "content_type": "text",
    "doc_id": "slide_576_16",
    "doc_type": "slide",
    "is_definition": true,
    "contains_equation": false,
    "importance": "high",
    "tags": [
      "GloVe",
      "semantic information",
      "unsupervised learning",
      "word representation"
    ]
  },
  {
    "text": "Glove Visualization [Richard Socher]",
    "source": "ELEC/COMP 576: - Slide 17",
    "source_detail": "ELEC576-Lec10.pdf, Page 17",
    "lecture": "ELEC/COMP 576:",
    "lecture_number": "576",
    "page": 17,
    "content_type": "text",
    "doc_id": "slide_576_17",
    "doc_type": "slide",
    "is_definition": false,
    "contains_equation": false,
    "importance": "high",
    "tags": [
      "Glove Visualization",
      "Natural Language Processing",
      "Richard Socher",
      "Word Embeddings"
    ]
  },
  {
    "text": "Word2Vec Learn word embeddings \u2022 Shallow, two-layer neural network \u2022 Trained to reconstruct linguistic context between \u2022 words Produces a vector space for the words \u2022",
    "source": "ELEC/COMP 576: - Slide 18",
    "source_detail": "ELEC576-Lec10.pdf, Page 18",
    "lecture": "ELEC/COMP 576:",
    "lecture_number": "576",
    "page": 18,
    "content_type": "text",
    "doc_id": "slide_576_18",
    "doc_type": "slide",
    "is_definition": true,
    "contains_equation": false,
    "importance": "high",
    "tags": [
      "neural networks"
    ]
  },
  {
    "text": "Word2Vec Visualization [Tensorflow]",
    "source": "ELEC/COMP 576: - Slide 19",
    "source_detail": "ELEC576-Lec10.pdf, Page 19",
    "lecture": "ELEC/COMP 576:",
    "lecture_number": "576",
    "page": 19,
    "content_type": "text",
    "doc_id": "slide_576_19",
    "doc_type": "slide",
    "is_definition": false,
    "contains_equation": true,
    "importance": "high",
    "tags": [
      "Visualization",
      "Word2Vec",
      "Tensorflow"
    ]
  },
  {
    "text": "Question Time What is the main difference between word2vec and \u2022 GloVe?",
    "source": "ELEC/COMP 576: - Slide 20",
    "source_detail": "ELEC576-Lec10.pdf, Page 20",
    "lecture": "ELEC/COMP 576:",
    "lecture_number": "576",
    "page": 20,
    "content_type": "text",
    "doc_id": "slide_576_20",
    "doc_type": "slide",
    "is_definition": false,
    "contains_equation": false,
    "importance": "high",
    "tags": [
      "embedding models",
      "GloVe",
      "word2vec",
      "difference"
    ]
  },
  {
    "text": "Word2vec with RNNs [Mikolov, Yih, Zweig]",
    "source": "ELEC/COMP 576: - Slide 21",
    "source_detail": "ELEC576-Lec10.pdf, Page 21",
    "lecture": "ELEC/COMP 576:",
    "lecture_number": "576",
    "page": 21,
    "content_type": "text",
    "doc_id": "slide_576_21",
    "doc_type": "slide",
    "is_definition": false,
    "contains_equation": true,
    "importance": "high",
    "tags": [
      "rnn",
      "neural networks"
    ]
  },
  {
    "text": "Word RNN trained on Shakespeare [Sung Kim]",
    "source": "ELEC/COMP 576: - Slide 22",
    "source_detail": "ELEC576-Lec10.pdf, Page 22",
    "lecture": "ELEC/COMP 576:",
    "lecture_number": "576",
    "page": 22,
    "content_type": "text",
    "doc_id": "slide_576_22",
    "doc_type": "slide",
    "is_definition": false,
    "contains_equation": false,
    "importance": "medium",
    "tags": [
      "rnn",
      "neural networks"
    ]
  },
  {
    "text": "Gated Word RNN [Miyamoto, Cho]",
    "source": "ELEC/COMP 576: - Slide 23",
    "source_detail": "ELEC576-Lec10.pdf, Page 23",
    "lecture": "ELEC/COMP 576:",
    "lecture_number": "576",
    "page": 23,
    "content_type": "text",
    "doc_id": "slide_576_23",
    "doc_type": "slide",
    "is_definition": false,
    "contains_equation": true,
    "importance": "high",
    "tags": [
      "rnn",
      "neural networks"
    ]
  },
  {
    "text": "Gated Word RNN Results [Miyamoto, Cho]",
    "source": "ELEC/COMP 576: - Slide 24",
    "source_detail": "ELEC576-Lec10.pdf, Page 24",
    "lecture": "ELEC/COMP 576:",
    "lecture_number": "576",
    "page": 24,
    "content_type": "text",
    "doc_id": "slide_576_24",
    "doc_type": "slide",
    "is_definition": false,
    "contains_equation": true,
    "importance": "high",
    "tags": [
      "rnn",
      "neural networks"
    ]
  },
  {
    "text": "Combining Character & Word Level [Bojanowski, Joulin, Mikolov]",
    "source": "ELEC/COMP 576: - Slide 25",
    "source_detail": "ELEC576-Lec10.pdf, Page 25",
    "lecture": "ELEC/COMP 576:",
    "lecture_number": "576",
    "page": 25,
    "content_type": "text",
    "doc_id": "slide_576_25",
    "doc_type": "slide",
    "is_definition": false,
    "contains_equation": true,
    "importance": "high",
    "tags": [
      "Character Level",
      "Mikolov",
      "Bojanowski",
      "Word Level",
      "Joulin"
    ]
  },
  {
    "text": "Question Time In which situation(s) can you see character-level \u2022 RNN more suitable than a word-level RNN?",
    "source": "ELEC/COMP 576: - Slide 26",
    "source_detail": "ELEC576-Lec10.pdf, Page 26",
    "lecture": "ELEC/COMP 576:",
    "lecture_number": "576",
    "page": 26,
    "content_type": "text",
    "doc_id": "slide_576_26",
    "doc_type": "slide",
    "is_definition": false,
    "contains_equation": false,
    "importance": "medium",
    "tags": [
      "rnn",
      "neural networks"
    ]
  },
  {
    "text": "Character vs Word Level Models",
    "source": "ELEC/COMP 576: - Slide 27",
    "source_detail": "ELEC576-Lec10.pdf, Page 27",
    "lecture": "ELEC/COMP 576:",
    "lecture_number": "576",
    "page": 27,
    "content_type": "text",
    "doc_id": "slide_576_27",
    "doc_type": "slide",
    "is_definition": false,
    "contains_equation": false,
    "importance": "high",
    "tags": [
      "Character Level Models",
      "Text Representation",
      "Word Level Models",
      "Natural Language Processing"
    ]
  },
  {
    "text": "Character vs Word-Level Models [Kim, Jernite, Sontag, Rush]",
    "source": "ELEC/COMP 576: - Slide 28",
    "source_detail": "ELEC576-Lec10.pdf, Page 28",
    "lecture": "ELEC/COMP 576:",
    "lecture_number": "576",
    "page": 28,
    "content_type": "text",
    "doc_id": "slide_576_28",
    "doc_type": "slide",
    "is_definition": false,
    "contains_equation": false,
    "importance": "high",
    "tags": [
      "Text Representation",
      "Word-Level Models",
      "Natural Language Processing",
      "Character-Level Models"
    ]
  },
  {
    "text": "Word Representations of Character & Word Models [Kim, Jernite, Sontag, Rush]",
    "source": "ELEC/COMP 576: - Slide 29",
    "source_detail": "ELEC576-Lec10.pdf, Page 29",
    "lecture": "ELEC/COMP 576:",
    "lecture_number": "576",
    "page": 29,
    "content_type": "text",
    "doc_id": "slide_576_29",
    "doc_type": "slide",
    "is_definition": false,
    "contains_equation": true,
    "importance": "high",
    "tags": [
      "Machine Learning",
      "Word Representations",
      "Word Models",
      "Natural Language Processing",
      "Character Models"
    ]
  },
  {
    "text": "Word-level RNN Language Models",
    "source": "ELEC/COMP 576: - Slide 30",
    "source_detail": "ELEC576-Lec10.pdf, Page 30",
    "lecture": "ELEC/COMP 576:",
    "lecture_number": "576",
    "page": 30,
    "content_type": "text",
    "doc_id": "slide_576_30",
    "doc_type": "slide",
    "is_definition": false,
    "contains_equation": false,
    "importance": "high",
    "tags": [
      "rnn",
      "neural networks"
    ]
  },
  {
    "text": "Motivation \u2022 Model the probability distribution of the next word in a sequence, given the previous words \u2022 Words are the minimal unit to provide meaning \u2022 Another step to a hierarchical model [Nicholas Leonard]",
    "source": "ELEC/COMP 576: - Slide 31",
    "source_detail": "ELEC576-Lec10.pdf, Page 31",
    "lecture": "ELEC/COMP 576:",
    "lecture_number": "576",
    "page": 31,
    "content_type": "text",
    "doc_id": "slide_576_31",
    "doc_type": "slide",
    "is_definition": false,
    "contains_equation": false,
    "importance": "high",
    "tags": [
      "word sequence",
      "meaning of words",
      "hierarchical model",
      "probability distribution"
    ]
  },
  {
    "text": "Global Vectors for Word Representation (GloVe) Provide semantic information/context for words \u2022 Unsupervised method for learning word \u2022 representations [Richard Socher]",
    "source": "ELEC/COMP 576: - Slide 32",
    "source_detail": "ELEC576-Lec10.pdf, Page 32",
    "lecture": "ELEC/COMP 576:",
    "lecture_number": "576",
    "page": 32,
    "content_type": "text",
    "doc_id": "slide_576_32",
    "doc_type": "slide",
    "is_definition": true,
    "contains_equation": false,
    "importance": "high",
    "tags": [
      "GloVe",
      "semantic information",
      "unsupervised learning",
      "word representation"
    ]
  },
  {
    "text": "Glove Visualization [Richard Socher]",
    "source": "ELEC/COMP 576: - Slide 33",
    "source_detail": "ELEC576-Lec10.pdf, Page 33",
    "lecture": "ELEC/COMP 576:",
    "lecture_number": "576",
    "page": 33,
    "content_type": "text",
    "doc_id": "slide_576_33",
    "doc_type": "slide",
    "is_definition": false,
    "contains_equation": false,
    "importance": "high",
    "tags": [
      "Glove Visualization",
      "Natural Language Processing",
      "Richard Socher",
      "Word Embeddings"
    ]
  },
  {
    "text": "Word2Vec Learn word embeddings \u2022 Shallow, two-layer neural network \u2022 Training makes observed word-context pairs \u2022 have similar embeddings, while scattering unobserved pairs. Intuitively, words that appear in similar contexts should have similar embeddings Produces a vector space for the words \u2022 [Goldberg, Levy Arxiv 2014]",
    "source": "ELEC/COMP 576: - Slide 34",
    "source_detail": "ELEC576-Lec10.pdf, Page 34",
    "lecture": "ELEC/COMP 576:",
    "lecture_number": "576",
    "page": 34,
    "content_type": "text",
    "doc_id": "slide_576_34",
    "doc_type": "slide",
    "is_definition": true,
    "contains_equation": false,
    "importance": "high",
    "tags": [
      "neural networks"
    ]
  },
  {
    "text": "Word2Vec Visualization [Tensorflow]",
    "source": "ELEC/COMP 576: - Slide 35",
    "source_detail": "ELEC576-Lec10.pdf, Page 35",
    "lecture": "ELEC/COMP 576:",
    "lecture_number": "576",
    "page": 35,
    "content_type": "text",
    "doc_id": "slide_576_35",
    "doc_type": "slide",
    "is_definition": false,
    "contains_equation": true,
    "importance": "high",
    "tags": [
      "Visualization",
      "Word2Vec",
      "Tensorflow"
    ]
  },
  {
    "text": "Understanding Word2Vec Probability that word context pair taken from document [Goldberg, Levy Arxiv 2014]",
    "source": "ELEC/COMP 576: - Slide 36",
    "source_detail": "ELEC576-Lec10.pdf, Page 36",
    "lecture": "ELEC/COMP 576:",
    "lecture_number": "576",
    "page": 36,
    "content_type": "text",
    "doc_id": "slide_576_36",
    "doc_type": "slide",
    "is_definition": false,
    "contains_equation": true,
    "importance": "high",
    "tags": [
      "Goldberg",
      "Levy",
      "Word2Vec",
      "word context pair",
      "Probability"
    ]
  },
  {
    "text": "Understanding Word2Vec Maximize likelihood real context pairs come from document [Goldberg, Levy Arxiv 2014]",
    "source": "ELEC/COMP 576: - Slide 37",
    "source_detail": "ELEC576-Lec10.pdf, Page 37",
    "lecture": "ELEC/COMP 576:",
    "lecture_number": "576",
    "page": 37,
    "content_type": "text",
    "doc_id": "slide_576_37",
    "doc_type": "slide",
    "is_definition": false,
    "contains_equation": true,
    "importance": "high",
    "tags": [
      "Goldberg",
      "Levy",
      "Word2Vec",
      "context pairs",
      "likelihood"
    ]
  },
  {
    "text": "Word2Vec as Word-Context Association Matrix Decomposition Solution is optimal parameters obey relation: 1. Construct word context Pointwise Mutual Information association matrix 2. Low rank decomposition = [Goldberg, Levy Arxiv 2014]",
    "source": "ELEC/COMP 576: - Slide 38",
    "source_detail": "ELEC576-Lec10.pdf, Page 38",
    "lecture": "ELEC/COMP 576:",
    "lecture_number": "576",
    "page": 38,
    "content_type": "text",
    "doc_id": "slide_576_38",
    "doc_type": "slide",
    "is_definition": true,
    "contains_equation": true,
    "importance": "high",
    "tags": [
      "low rank decomposition",
      "Goldberg",
      "Levy",
      "Word2Vec",
      "Pointwise Mutual Information"
    ]
  },
  {
    "text": "Question Time Given the theoretical understanding of word2vec, \u2022 what kinds of things will word2vec not capture well? Can you think of ways to make it better? \u2022",
    "source": "ELEC/COMP 576: - Slide 39",
    "source_detail": "ELEC576-Lec10.pdf, Page 39",
    "lecture": "ELEC/COMP 576:",
    "lecture_number": "576",
    "page": 39,
    "content_type": "text",
    "doc_id": "slide_576_39",
    "doc_type": "slide",
    "is_definition": false,
    "contains_equation": false,
    "importance": "medium",
    "tags": [
      "limitations",
      "improvements",
      "theoretical understanding",
      "word2vec"
    ]
  },
  {
    "text": "Word2vec with RNNs [Mikolov, Yih, Zweig]",
    "source": "ELEC/COMP 576: - Slide 40",
    "source_detail": "ELEC576-Lec10.pdf, Page 40",
    "lecture": "ELEC/COMP 576:",
    "lecture_number": "576",
    "page": 40,
    "content_type": "text",
    "doc_id": "slide_576_40",
    "doc_type": "slide",
    "is_definition": false,
    "contains_equation": true,
    "importance": "high",
    "tags": [
      "rnn",
      "neural networks"
    ]
  },
  {
    "text": "Word RNN trained on Shakespeare [Sung Kim]",
    "source": "ELEC/COMP 576: - Slide 41",
    "source_detail": "ELEC576-Lec10.pdf, Page 41",
    "lecture": "ELEC/COMP 576:",
    "lecture_number": "576",
    "page": 41,
    "content_type": "text",
    "doc_id": "slide_576_41",
    "doc_type": "slide",
    "is_definition": false,
    "contains_equation": false,
    "importance": "medium",
    "tags": [
      "rnn",
      "neural networks"
    ]
  },
  {
    "text": "Gated Word RNN [Miyamoto, Cho]",
    "source": "ELEC/COMP 576: - Slide 42",
    "source_detail": "ELEC576-Lec10.pdf, Page 42",
    "lecture": "ELEC/COMP 576:",
    "lecture_number": "576",
    "page": 42,
    "content_type": "text",
    "doc_id": "slide_576_42",
    "doc_type": "slide",
    "is_definition": false,
    "contains_equation": true,
    "importance": "high",
    "tags": [
      "rnn",
      "neural networks"
    ]
  },
  {
    "text": "Gated Word RNN Results [Miyamoto, Cho]",
    "source": "ELEC/COMP 576: - Slide 43",
    "source_detail": "ELEC576-Lec10.pdf, Page 43",
    "lecture": "ELEC/COMP 576:",
    "lecture_number": "576",
    "page": 43,
    "content_type": "text",
    "doc_id": "slide_576_43",
    "doc_type": "slide",
    "is_definition": false,
    "contains_equation": true,
    "importance": "high",
    "tags": [
      "rnn",
      "neural networks"
    ]
  },
  {
    "text": "Combining Character & Word Level [Bojanowski, Joulin, Mikolov]",
    "source": "ELEC/COMP 576: - Slide 44",
    "source_detail": "ELEC576-Lec10.pdf, Page 44",
    "lecture": "ELEC/COMP 576:",
    "lecture_number": "576",
    "page": 44,
    "content_type": "text",
    "doc_id": "slide_576_44",
    "doc_type": "slide",
    "is_definition": false,
    "contains_equation": true,
    "importance": "high",
    "tags": [
      "Character Level",
      "Mikolov",
      "Bojanowski",
      "Word Level",
      "Joulin"
    ]
  },
  {
    "text": "Question Time In which situation(s) can you see character-level \u2022 RNN more suitable than a word-level RNN?",
    "source": "ELEC/COMP 576: - Slide 45",
    "source_detail": "ELEC576-Lec10.pdf, Page 45",
    "lecture": "ELEC/COMP 576:",
    "lecture_number": "576",
    "page": 45,
    "content_type": "text",
    "doc_id": "slide_576_45",
    "doc_type": "slide",
    "is_definition": false,
    "contains_equation": false,
    "importance": "medium",
    "tags": [
      "rnn",
      "neural networks"
    ]
  },
  {
    "text": "Generating Movie Scripts LSTM named Benjamin \u2022 Learned to predict which letters would follow, then \u2022 the words and phrases Trained on corpus of past 1980 and 1990 sci-fi movie \u2022 scripts \"I'll give them top marks if they promise never to do this \u2022 again.\" https://www.youtube.com/watch?v=LY7x2Ihqjmc \u2022",
    "source": "ELEC/COMP 576: - Slide 46",
    "source_detail": "ELEC576-Lec10.pdf, Page 46",
    "lecture": "ELEC/COMP 576:",
    "lecture_number": "576",
    "page": 46,
    "content_type": "text",
    "doc_id": "slide_576_46",
    "doc_type": "slide",
    "is_definition": false,
    "contains_equation": false,
    "importance": "medium",
    "tags": [
      "rnn"
    ]
  },
  {
    "text": "Character vs Word Level Models",
    "source": "ELEC/COMP 576: - Slide 47",
    "source_detail": "ELEC576-Lec10.pdf, Page 47",
    "lecture": "ELEC/COMP 576:",
    "lecture_number": "576",
    "page": 47,
    "content_type": "text",
    "doc_id": "slide_576_47",
    "doc_type": "slide",
    "is_definition": false,
    "contains_equation": false,
    "importance": "medium",
    "tags": [
      "Character Level Models",
      "Text Representation",
      "Word Level Models",
      "Natural Language Processing"
    ]
  },
  {
    "text": "Character vs Word-Level Models [Kim, Jernite, Sontag, Rush]",
    "source": "ELEC/COMP 576: - Slide 48",
    "source_detail": "ELEC576-Lec10.pdf, Page 48",
    "lecture": "ELEC/COMP 576:",
    "lecture_number": "576",
    "page": 48,
    "content_type": "text",
    "doc_id": "slide_576_48",
    "doc_type": "slide",
    "is_definition": false,
    "contains_equation": false,
    "importance": "high",
    "tags": [
      "Text Representation",
      "Word-Level Models",
      "Natural Language Processing",
      "Character-Level Models"
    ]
  },
  {
    "text": "Word Representations of Character & Word Models [Kim, Jernite, Sontag, Rush]",
    "source": "ELEC/COMP 576: - Slide 49",
    "source_detail": "ELEC576-Lec10.pdf, Page 49",
    "lecture": "ELEC/COMP 576:",
    "lecture_number": "576",
    "page": 49,
    "content_type": "text",
    "doc_id": "slide_576_49",
    "doc_type": "slide",
    "is_definition": false,
    "contains_equation": true,
    "importance": "high",
    "tags": [
      "Word Representations",
      "Character Models",
      "Word Models",
      "Natural Language Processing"
    ]
  },
  {
    "text": "Tweet2Vec [Dhingra, Zhou, Fitzpatrick, Muehl, Cohen]",
    "source": "ELEC/COMP 576: - Slide 51",
    "source_detail": "ELEC576-Lec10.pdf, Page 51",
    "lecture": "ELEC/COMP 576:",
    "lecture_number": "576",
    "page": 51,
    "content_type": "text",
    "doc_id": "slide_576_51",
    "doc_type": "slide",
    "is_definition": false,
    "contains_equation": false,
    "importance": "high",
    "tags": [
      "Zhou",
      "Fitzpatrick",
      "Muehl",
      "Tweet2Vec",
      "Dhingra"
    ]
  },
  {
    "text": "Tweet2Vec Encoder [Dhingra, Zhou, Fitzpatrick, Muehl, Cohen]",
    "source": "ELEC/COMP 576: - Slide 52",
    "source_detail": "ELEC576-Lec10.pdf, Page 52",
    "lecture": "ELEC/COMP 576:",
    "lecture_number": "576",
    "page": 52,
    "content_type": "text",
    "doc_id": "slide_576_52",
    "doc_type": "slide",
    "is_definition": false,
    "contains_equation": false,
    "importance": "high",
    "tags": [
      "Zhou",
      "Fitzpatrick",
      "Encoder",
      "Tweet2Vec",
      "Dhingra"
    ]
  },
  {
    "text": "Tweet2Vec Results [Dhingra, Zhou, Fitzpatrick, Muehl, Cohen]",
    "source": "ELEC/COMP 576: - Slide 53",
    "source_detail": "ELEC576-Lec10.pdf, Page 53",
    "lecture": "ELEC/COMP 576:",
    "lecture_number": "576",
    "page": 53,
    "content_type": "text",
    "doc_id": "slide_576_53",
    "doc_type": "slide",
    "is_definition": false,
    "contains_equation": false,
    "importance": "high",
    "tags": [
      "Zhou",
      "Fitzpatrick",
      "Results",
      "Tweet2Vec",
      "Dhingra"
    ]
  },
  {
    "text": "Gene2Vec Word2Vec performs poorly on long nucleotide \u2022 sequences Short sequences are very common like AAAGTT \u2022 [David Cox]",
    "source": "ELEC/COMP 576: - Slide 54",
    "source_detail": "ELEC576-Lec10.pdf, Page 54",
    "lecture": "ELEC/COMP 576:",
    "lecture_number": "576",
    "page": 54,
    "content_type": "text",
    "doc_id": "slide_576_54",
    "doc_type": "slide",
    "is_definition": false,
    "contains_equation": false,
    "importance": "medium",
    "tags": [
      "Word2Vec",
      "Gene2Vec",
      "nucleotide sequences",
      "David Cox",
      "short sequences"
    ]
  },
  {
    "text": "Gene2Vec Visual Hydrophobic Amino Acids [David Cox]",
    "source": "ELEC/COMP 576: - Slide 55",
    "source_detail": "ELEC576-Lec10.pdf, Page 55",
    "lecture": "ELEC/COMP 576:",
    "lecture_number": "576",
    "page": 55,
    "content_type": "text",
    "doc_id": "slide_576_55",
    "doc_type": "slide",
    "is_definition": false,
    "contains_equation": false,
    "importance": "high",
    "tags": [
      "Gene2Vec",
      "Visual",
      "Hydrophobic",
      "David Cox",
      "Amino Acids"
    ]
  },
  {
    "text": "Doc2Vec Similar to Word2Vec but to a larger scale \u2022 Sentences & Paragraphs \u2022 [RaRe Technologies]",
    "source": "ELEC/COMP 576: - Slide 56",
    "source_detail": "ELEC576-Lec10.pdf, Page 56",
    "lecture": "ELEC/COMP 576:",
    "lecture_number": "576",
    "page": 56,
    "content_type": "figure",
    "doc_id": "slide_576_56",
    "doc_type": "slide",
    "is_definition": false,
    "contains_equation": false,
    "importance": "medium",
    "tags": [
      "Doc2Vec",
      "Word2Vec",
      "RaRe Technologies",
      "Paragraphs",
      "Sentences"
    ]
  },
  {
    "text": "Applications of Document Models Discovery of litigation e.g. CS Disco \u2022 Sentiment Classification e.g. movie reviews \u2022",
    "source": "ELEC/COMP 576: - Slide 57",
    "source_detail": "ELEC576-Lec10.pdf, Page 57",
    "lecture": "ELEC/COMP 576:",
    "lecture_number": "576",
    "page": 57,
    "content_type": "text",
    "doc_id": "slide_576_57",
    "doc_type": "slide",
    "is_definition": false,
    "contains_equation": false,
    "importance": "medium",
    "tags": [
      "Sentiment Classification",
      "Litigation Discovery",
      "Document Models",
      "Movie Reviews"
    ]
  },
  {
    "text": "Goal Model the probability distribution of the next \u2022 character in a sequence Given the previous characters \u2022 [Susanto, Chieu, Lu]",
    "source": "ELEC/COMP 576: - Slide 59",
    "source_detail": "ELEC576-Lec10.pdf, Page 59",
    "lecture": "ELEC/COMP 576:",
    "lecture_number": "576",
    "page": 59,
    "content_type": "text",
    "doc_id": "slide_576_59",
    "doc_type": "slide",
    "is_definition": false,
    "contains_equation": true,
    "importance": "high",
    "tags": [
      "modeling",
      "probability distribution",
      "character sequence",
      "previous characters"
    ]
  },
  {
    "text": "N-grams Group the characters into n characters \u2022 n=1 unigram \u2022 n=2 bigram \u2022 Useful for protein sequencing, computational \u2022 linguistics, etc.",
    "source": "ELEC/COMP 576: - Slide 60",
    "source_detail": "ELEC576-Lec10.pdf, Page 60",
    "lecture": "ELEC/COMP 576:",
    "lecture_number": "576",
    "page": 60,
    "content_type": "text",
    "doc_id": "slide_576_60",
    "doc_type": "slide",
    "is_definition": true,
    "contains_equation": false,
    "importance": "medium",
    "tags": [
      "bigram",
      "protein sequencing",
      "N-grams",
      "computational linguistics",
      "unigram"
    ]
  },
  {
    "text": "Comparing Against N- Grams [Karpathy, Johnson, Li]",
    "source": "ELEC/COMP 576: - Slide 61",
    "source_detail": "ELEC576-Lec10.pdf, Page 61",
    "lecture": "ELEC/COMP 576:",
    "lecture_number": "576",
    "page": 61,
    "content_type": "text",
    "doc_id": "slide_576_61",
    "doc_type": "slide",
    "is_definition": false,
    "contains_equation": true,
    "importance": "high",
    "tags": [
      "Johnson",
      "Li",
      "Karpathy",
      "Comparative Analysis",
      "N-Grams"
    ]
  },
  {
    "text": "Remembering for Longer Durations [Karpathy, Johnson, Li]",
    "source": "ELEC/COMP 576: - Slide 62",
    "source_detail": "ELEC576-Lec10.pdf, Page 62",
    "lecture": "ELEC/COMP 576:",
    "lecture_number": "576",
    "page": 62,
    "content_type": "text",
    "doc_id": "slide_576_62",
    "doc_type": "slide",
    "is_definition": false,
    "contains_equation": false,
    "importance": "high",
    "tags": [
      "memory retention",
      "educational techniques",
      "cognitive psychology",
      "long-term memory"
    ]
  },
  {
    "text": "Character-Aware Neural Language Models [Kim, Jernite, Sontag, Rush]",
    "source": "ELEC/COMP 576: - Slide 63",
    "source_detail": "ELEC576-Lec10.pdf, Page 63",
    "lecture": "ELEC/COMP 576:",
    "lecture_number": "576",
    "page": 63,
    "content_type": "text",
    "doc_id": "slide_576_63",
    "doc_type": "slide",
    "is_definition": false,
    "contains_equation": true,
    "importance": "high",
    "tags": [
      "Deep Learning",
      "Neural Language Models",
      "Character-Aware",
      "Natural Language Processing"
    ]
  },
  {
    "text": "The Effectiveness of an RNN [Andrej Karpathy]",
    "source": "ELEC/COMP 576: - Slide 64",
    "source_detail": "ELEC576-Lec10.pdf, Page 64",
    "lecture": "ELEC/COMP 576:",
    "lecture_number": "576",
    "page": 64,
    "content_type": "text",
    "doc_id": "slide_576_64",
    "doc_type": "slide",
    "is_definition": false,
    "contains_equation": true,
    "importance": "high",
    "tags": [
      "rnn",
      "neural networks"
    ]
  },
  {
    "text": "The Effectiveness of an RNN [Andrej Karpathy]",
    "source": "ELEC/COMP 576: - Slide 65",
    "source_detail": "ELEC576-Lec10.pdf, Page 65",
    "lecture": "ELEC/COMP 576:",
    "lecture_number": "576",
    "page": 65,
    "content_type": "text",
    "doc_id": "slide_576_65",
    "doc_type": "slide",
    "is_definition": false,
    "contains_equation": true,
    "importance": "high",
    "tags": [
      "rnn",
      "neural networks"
    ]
  },
  {
    "text": "The Effectiveness of an RNN [Andrej Karpathy]",
    "source": "ELEC/COMP 576: - Slide 66",
    "source_detail": "ELEC576-Lec10.pdf, Page 66",
    "lecture": "ELEC/COMP 576:",
    "lecture_number": "576",
    "page": 66,
    "content_type": "text",
    "doc_id": "slide_576_66",
    "doc_type": "slide",
    "is_definition": false,
    "contains_equation": true,
    "importance": "high",
    "tags": [
      "rnn",
      "neural networks"
    ]
  },
  {
    "text": "The Effectiveness of an RNN Trained on War & Peace Iteration: 100 Iteration: 300 Iteration: 2000 [Andrej Karpathy]",
    "source": "ELEC/COMP 576: - Slide 67",
    "source_detail": "ELEC576-Lec10.pdf, Page 67",
    "lecture": "ELEC/COMP 576:",
    "lecture_number": "576",
    "page": 67,
    "content_type": "text",
    "doc_id": "slide_576_67",
    "doc_type": "slide",
    "is_definition": false,
    "contains_equation": true,
    "importance": "high",
    "tags": [
      "rnn",
      "neural networks"
    ]
  },
  {
    "text": "Visualize the Neurons of an RNN [Andrej Karpathy]",
    "source": "ELEC/COMP 576: - Slide 68",
    "source_detail": "ELEC576-Lec10.pdf, Page 68",
    "lecture": "ELEC/COMP 576:",
    "lecture_number": "576",
    "page": 68,
    "content_type": "text",
    "doc_id": "slide_576_68",
    "doc_type": "slide",
    "is_definition": false,
    "contains_equation": false,
    "importance": "high",
    "tags": [
      "rnn",
      "neural networks"
    ]
  },
  {
    "text": "Visualize the Neurons of an RNN [Andrej Karpathy]",
    "source": "ELEC/COMP 576: - Slide 69",
    "source_detail": "ELEC576-Lec10.pdf, Page 69",
    "lecture": "ELEC/COMP 576:",
    "lecture_number": "576",
    "page": 69,
    "content_type": "text",
    "doc_id": "slide_576_69",
    "doc_type": "slide",
    "is_definition": false,
    "contains_equation": false,
    "importance": "high",
    "tags": [
      "rnn",
      "neural networks"
    ]
  },
  {
    "text": "Word-level RNN Language Models",
    "source": "ELEC/COMP 576: - Slide 70",
    "source_detail": "ELEC576-Lec10.pdf, Page 70",
    "lecture": "ELEC/COMP 576:",
    "lecture_number": "576",
    "page": 70,
    "content_type": "text",
    "doc_id": "slide_576_70",
    "doc_type": "slide",
    "is_definition": false,
    "contains_equation": false,
    "importance": "high",
    "tags": [
      "rnn",
      "neural networks"
    ]
  },
  {
    "text": "Goals Model the probability distribution of the next word \u2022 in a sequence Given the previous words \u2022 [Nicholas Leonard]",
    "source": "ELEC/COMP 576: - Slide 71",
    "source_detail": "ELEC576-Lec10.pdf, Page 71",
    "lecture": "ELEC/COMP 576:",
    "lecture_number": "576",
    "page": 71,
    "content_type": "text",
    "doc_id": "slide_576_71",
    "doc_type": "slide",
    "is_definition": false,
    "contains_equation": false,
    "importance": "high",
    "tags": [
      "sequence",
      "previous words",
      "next word",
      "probability distribution"
    ]
  },
  {
    "text": "Global Vectors for Word Representation (GloVe) Provide semantic information/context for words \u2022 Unsupervised method for learning word \u2022 representations [Richard Socher]",
    "source": "ELEC/COMP 576: - Slide 72",
    "source_detail": "ELEC576-Lec10.pdf, Page 72",
    "lecture": "ELEC/COMP 576:",
    "lecture_number": "576",
    "page": 72,
    "content_type": "text",
    "doc_id": "slide_576_72",
    "doc_type": "slide",
    "is_definition": true,
    "contains_equation": false,
    "importance": "high",
    "tags": [
      "GloVe",
      "semantic information",
      "unsupervised learning",
      "word representation"
    ]
  },
  {
    "text": "Glove Visualization [Richard Socher]",
    "source": "ELEC/COMP 576: - Slide 73",
    "source_detail": "ELEC576-Lec10.pdf, Page 73",
    "lecture": "ELEC/COMP 576:",
    "lecture_number": "576",
    "page": 73,
    "content_type": "text",
    "doc_id": "slide_576_73",
    "doc_type": "slide",
    "is_definition": false,
    "contains_equation": false,
    "importance": "medium",
    "tags": [
      "Glove Visualization",
      "Natural Language Processing",
      "Richard Socher",
      "Word Embeddings"
    ]
  },
  {
    "text": "Word2Vec Learn word embeddings \u2022 Shallow, two-layer neural network \u2022 Trained to reconstruct linguistic context between \u2022 words Produces a vector space for the words \u2022",
    "source": "ELEC/COMP 576: - Slide 74",
    "source_detail": "ELEC576-Lec10.pdf, Page 74",
    "lecture": "ELEC/COMP 576:",
    "lecture_number": "576",
    "page": 74,
    "content_type": "text",
    "doc_id": "slide_576_74",
    "doc_type": "slide",
    "is_definition": true,
    "contains_equation": false,
    "importance": "high",
    "tags": [
      "neural networks"
    ]
  },
  {
    "text": "Word2Vec Visualization [Tensorflow]",
    "source": "ELEC/COMP 576: - Slide 75",
    "source_detail": "ELEC576-Lec10.pdf, Page 75",
    "lecture": "ELEC/COMP 576:",
    "lecture_number": "576",
    "page": 75,
    "content_type": "text",
    "doc_id": "slide_576_75",
    "doc_type": "slide",
    "is_definition": false,
    "contains_equation": true,
    "importance": "high",
    "tags": [
      "Visualization",
      "Word2Vec",
      "Tensorflow"
    ]
  },
  {
    "text": "Question Time What is the main difference between word2vec and \u2022 GloVe?",
    "source": "ELEC/COMP 576: - Slide 76",
    "source_detail": "ELEC576-Lec10.pdf, Page 76",
    "lecture": "ELEC/COMP 576:",
    "lecture_number": "576",
    "page": 76,
    "content_type": "text",
    "doc_id": "slide_576_76",
    "doc_type": "slide",
    "is_definition": false,
    "contains_equation": false,
    "importance": "high",
    "tags": [
      "embedding techniques",
      "GloVe",
      "word2vec",
      "difference"
    ]
  },
  {
    "text": "Word2vec with RNNs [Mikolov, Yih, Zweig]",
    "source": "ELEC/COMP 576: - Slide 77",
    "source_detail": "ELEC576-Lec10.pdf, Page 77",
    "lecture": "ELEC/COMP 576:",
    "lecture_number": "576",
    "page": 77,
    "content_type": "text",
    "doc_id": "slide_576_77",
    "doc_type": "slide",
    "is_definition": false,
    "contains_equation": true,
    "importance": "high",
    "tags": [
      "rnn",
      "neural networks"
    ]
  },
  {
    "text": "Word RNN trained on Shakespeare [Sung Kim]",
    "source": "ELEC/COMP 576: - Slide 78",
    "source_detail": "ELEC576-Lec10.pdf, Page 78",
    "lecture": "ELEC/COMP 576:",
    "lecture_number": "576",
    "page": 78,
    "content_type": "text",
    "doc_id": "slide_576_78",
    "doc_type": "slide",
    "is_definition": false,
    "contains_equation": false,
    "importance": "medium",
    "tags": [
      "rnn",
      "neural networks"
    ]
  },
  {
    "text": "Gated Word RNN [Miyamoto, Cho]",
    "source": "ELEC/COMP 576: - Slide 79",
    "source_detail": "ELEC576-Lec10.pdf, Page 79",
    "lecture": "ELEC/COMP 576:",
    "lecture_number": "576",
    "page": 79,
    "content_type": "text",
    "doc_id": "slide_576_79",
    "doc_type": "slide",
    "is_definition": false,
    "contains_equation": true,
    "importance": "high",
    "tags": [
      "rnn",
      "neural networks"
    ]
  },
  {
    "text": "Gated Word RNN Results [Miyamoto, Cho]",
    "source": "ELEC/COMP 576: - Slide 80",
    "source_detail": "ELEC576-Lec10.pdf, Page 80",
    "lecture": "ELEC/COMP 576:",
    "lecture_number": "576",
    "page": 80,
    "content_type": "text",
    "doc_id": "slide_576_80",
    "doc_type": "slide",
    "is_definition": false,
    "contains_equation": true,
    "importance": "high",
    "tags": [
      "rnn",
      "neural networks"
    ]
  },
  {
    "text": "Combining Character & Word Level [Bojanowski, Joulin, Mikolov]",
    "source": "ELEC/COMP 576: - Slide 81",
    "source_detail": "ELEC576-Lec10.pdf, Page 81",
    "lecture": "ELEC/COMP 576:",
    "lecture_number": "576",
    "page": 81,
    "content_type": "text",
    "doc_id": "slide_576_81",
    "doc_type": "slide",
    "is_definition": false,
    "contains_equation": true,
    "importance": "high",
    "tags": [
      "Character Level",
      "Mikolov",
      "Bojanowski",
      "Word Level",
      "Joulin"
    ]
  },
  {
    "text": "Question Time In which situation(s) can you see character-level \u2022 RNN more suitable than a word-level RNN?",
    "source": "ELEC/COMP 576: - Slide 82",
    "source_detail": "ELEC576-Lec10.pdf, Page 82",
    "lecture": "ELEC/COMP 576:",
    "lecture_number": "576",
    "page": 82,
    "content_type": "text",
    "doc_id": "slide_576_82",
    "doc_type": "slide",
    "is_definition": false,
    "contains_equation": false,
    "importance": "medium",
    "tags": [
      "rnn",
      "neural networks"
    ]
  },
  {
    "text": "Character vs Word Level Models",
    "source": "ELEC/COMP 576: - Slide 83",
    "source_detail": "ELEC576-Lec10.pdf, Page 83",
    "lecture": "ELEC/COMP 576:",
    "lecture_number": "576",
    "page": 83,
    "content_type": "text",
    "doc_id": "slide_576_83",
    "doc_type": "slide",
    "is_definition": false,
    "contains_equation": false,
    "importance": "medium",
    "tags": [
      "Character Level Models",
      "Text Representation",
      "Word Level Models",
      "Natural Language Processing"
    ]
  },
  {
    "text": "Character vs Word-Level Models [Kim, Jernite, Sontag, Rush]",
    "source": "ELEC/COMP 576: - Slide 84",
    "source_detail": "ELEC576-Lec10.pdf, Page 84",
    "lecture": "ELEC/COMP 576:",
    "lecture_number": "576",
    "page": 84,
    "content_type": "text",
    "doc_id": "slide_576_84",
    "doc_type": "slide",
    "is_definition": false,
    "contains_equation": false,
    "importance": "high",
    "tags": [
      "Text Representation",
      "Word-Level Models",
      "Natural Language Processing",
      "Character-Level Models"
    ]
  },
  {
    "text": "Word Representations of Character & Word Models [Kim, Jernite, Sontag, Rush]",
    "source": "ELEC/COMP 576: - Slide 85",
    "source_detail": "ELEC576-Lec10.pdf, Page 85",
    "lecture": "ELEC/COMP 576:",
    "lecture_number": "576",
    "page": 85,
    "content_type": "text",
    "doc_id": "slide_576_85",
    "doc_type": "slide",
    "is_definition": false,
    "contains_equation": true,
    "importance": "high",
    "tags": [
      "Word Representations",
      "Character Models",
      "Word Models",
      "Natural Language Processing"
    ]
  },
  {
    "text": "Reinforcement Learning",
    "source": "Deep Reinforcement Learning - Slide 2",
    "source_detail": "ELEC576-Lec11.pdf, Page 2",
    "lecture": "Deep Reinforcement Learning",
    "lecture_number": "576",
    "page": 2,
    "content_type": "text",
    "doc_id": "slide_576_2",
    "doc_type": "slide",
    "is_definition": true,
    "contains_equation": false,
    "importance": "high",
    "tags": [
      "Decision Making",
      "Machine Learning",
      "Artificial Intelligence",
      "Algorithms",
      "Reinforcement Learning"
    ]
  },
  {
    "text": "What is Reinforcement Learning Reinforcement Learning (RL) is a framework for \u2022 decision-making Have an agent with acts in an environment \u2022 Each action influences the agent\u2019s future state \u2022 Success is measured by reward \u2022 Find actions that maximise your future reward \u2022",
    "source": "Deep Reinforcement Learning - Slide 3",
    "source_detail": "ELEC576-Lec11.pdf, Page 3",
    "lecture": "Deep Reinforcement Learning",
    "lecture_number": "576",
    "page": 3,
    "content_type": "text",
    "doc_id": "slide_576_3",
    "doc_type": "slide",
    "is_definition": true,
    "contains_equation": false,
    "importance": "high",
    "tags": [
      "decision-making",
      "agent",
      "reward",
      "environment",
      "Reinforcement Learning"
    ]
  },
  {
    "text": "Agent and Environment Agent \u2022 Executes action \u2022 Receives observation \u2022 Receives reward \u2022 Environment \u2022 Receives action \u2022 Sends new observation \u2022 Sends new reward \u2022 [David Silver ICML 2016]",
    "source": "Deep Reinforcement Learning - Slide 4",
    "source_detail": "ELEC576-Lec11.pdf, Page 4",
    "lecture": "Deep Reinforcement Learning",
    "lecture_number": "576",
    "page": 4,
    "content_type": "text",
    "doc_id": "slide_576_4",
    "doc_type": "slide",
    "is_definition": true,
    "contains_equation": false,
    "importance": "high",
    "tags": [
      "Environment",
      "Action",
      "Reward",
      "Observation",
      "Agent"
    ]
  },
  {
    "text": "Defining the State Sequence of observations, rewards, and actions \u2022 define experience State is a summary of experiences \u2022 [David Silver ICML 2016]",
    "source": "Deep Reinforcement Learning - Slide 5",
    "source_detail": "ELEC576-Lec11.pdf, Page 5",
    "lecture": "Deep Reinforcement Learning",
    "lecture_number": "576",
    "page": 5,
    "content_type": "text",
    "doc_id": "slide_576_5",
    "doc_type": "slide",
    "is_definition": true,
    "contains_equation": false,
    "importance": "high",
    "tags": [
      "observations",
      "rewards",
      "experience",
      "actions",
      "State Sequence"
    ]
  },
  {
    "text": "Components of an RL Agent Policy \u2022 Agent\u2019s behavior function \u2022 Value Function \u2022 Determine if each state or action is good \u2022 Model \u2022 Agent\u2019s representation \u2022",
    "source": "Deep Reinforcement Learning - Slide 6",
    "source_detail": "ELEC576-Lec11.pdf, Page 6",
    "lecture": "Deep Reinforcement Learning",
    "lecture_number": "576",
    "page": 6,
    "content_type": "text",
    "doc_id": "slide_576_6",
    "doc_type": "slide",
    "is_definition": true,
    "contains_equation": false,
    "importance": "high",
    "tags": [
      "Value Function",
      "Policy",
      "RL Agent",
      "Model",
      "Agent's behavior"
    ]
  },
  {
    "text": "Policy Policy is the agent\u2019s behavior \u2022 Policy is a map from state to action \u2022 Deterministic \u2022 Stochastic \u2022 [David Silver ICML 2016]",
    "source": "Deep Reinforcement Learning - Slide 7",
    "source_detail": "ELEC576-Lec11.pdf, Page 7",
    "lecture": "Deep Reinforcement Learning",
    "lecture_number": "576",
    "page": 7,
    "content_type": "text",
    "doc_id": "slide_576_7",
    "doc_type": "slide",
    "is_definition": true,
    "contains_equation": false,
    "importance": "high",
    "tags": [
      "Policy",
      "Agent Behavior",
      "Stochastic",
      "State to Action",
      "Deterministic"
    ]
  },
  {
    "text": "Value Function Value function is a prediction of the future reward \u2022 What will my reward be given this action a from \u2022 state s? Example: Q-value function \u2022 State s, action a, policy , discount factor \u2022 [David Silver ICML 2016]",
    "source": "Deep Reinforcement Learning - Slide 8",
    "source_detail": "ELEC576-Lec11.pdf, Page 8",
    "lecture": "Deep Reinforcement Learning",
    "lecture_number": "576",
    "page": 8,
    "content_type": "text",
    "doc_id": "slide_576_8",
    "doc_type": "slide",
    "is_definition": true,
    "contains_equation": true,
    "importance": "high",
    "tags": [
      "Value Function",
      "Q-value function",
      "reward prediction",
      "discount factor",
      "state action policy"
    ]
  },
  {
    "text": "Optimal Value Function The goal is to have the maximum achievable \u2022 With that, can act optimally with the policy \u2022 Optimal value maximises over all the decisions \u2022 [David Silver ICML 2016]",
    "source": "Deep Reinforcement Learning - Slide 9",
    "source_detail": "ELEC576-Lec11.pdf, Page 9",
    "lecture": "Deep Reinforcement Learning",
    "lecture_number": "576",
    "page": 9,
    "content_type": "text",
    "doc_id": "slide_576_9",
    "doc_type": "slide",
    "is_definition": true,
    "contains_equation": false,
    "importance": "high",
    "tags": [
      "decisions",
      "policy",
      "Optimal Value Function",
      "maximum achievable",
      "act optimally"
    ]
  },
  {
    "text": "Model The model is learned through experience \u2022 Can act as a proxy for the environment \u2022",
    "source": "Deep Reinforcement Learning - Slide 10",
    "source_detail": "ELEC576-Lec11.pdf, Page 10",
    "lecture": "Deep Reinforcement Learning",
    "lecture_number": "576",
    "page": 10,
    "content_type": "text",
    "doc_id": "slide_576_10",
    "doc_type": "slide",
    "is_definition": false,
    "contains_equation": false,
    "importance": "medium",
    "tags": [
      "model",
      "experience",
      "proxy",
      "environment"
    ]
  },
  {
    "text": "RL Approaches \u2022 Value-based RL \u2022 Estimate the optimal value \u2022 Maximum value achievable under any policy \u2022 Policy-based RL \u2022 Search for the optimal value \u2022 Policy achieving maximum future reward \u2022 Model-based RL \u2022 Build a model of the environment \u2022 Plan using a model [David Silver ICML 2016]",
    "source": "Deep Reinforcement Learning - Slide 11",
    "source_detail": "ELEC576-Lec11.pdf, Page 11",
    "lecture": "Deep Reinforcement Learning",
    "lecture_number": "576",
    "page": 11,
    "content_type": "text",
    "doc_id": "slide_576_11",
    "doc_type": "slide",
    "is_definition": true,
    "contains_equation": false,
    "importance": "high",
    "tags": [
      "Model-based RL",
      "Value-based RL",
      "Policy-based RL",
      "Future reward",
      "Optimal value"
    ]
  },
  {
    "text": "Deep Reinforcement Learning",
    "source": "Deep Reinforcement Learning - Slide 12",
    "source_detail": "ELEC576-Lec11.pdf, Page 12",
    "lecture": "Deep Reinforcement Learning",
    "lecture_number": "576",
    "page": 12,
    "content_type": "text",
    "doc_id": "slide_576_12",
    "doc_type": "slide",
    "is_definition": true,
    "contains_equation": false,
    "importance": "high",
    "tags": [
      "Machine Learning",
      "Deep Reinforcement Learning",
      "Neural Networks",
      "Artificial Intelligence",
      "Algorithms"
    ]
  },
  {
    "text": "Deep RL To have Deep RL, we need \u2022 RL + Deep Learning (DL) = AI \u2022 RL defines the objective \u2022 DL provides the mechanism to learn \u2022",
    "source": "Deep Reinforcement Learning - Slide 13",
    "source_detail": "ELEC576-Lec11.pdf, Page 13",
    "lecture": "Deep Reinforcement Learning",
    "lecture_number": "576",
    "page": 13,
    "content_type": "text",
    "doc_id": "slide_576_13",
    "doc_type": "slide",
    "is_definition": true,
    "contains_equation": true,
    "importance": "high",
    "tags": [
      "Deep Learning",
      "Deep Reinforcement Learning",
      "Artificial Intelligence",
      "Reinforcement Learning"
    ]
  },
  {
    "text": "Deep RL Can use DL to represent \u2022 Value function \u2022 Policy \u2022 Model \u2022 Optimise loss function via Stochastic Gradient \u2022 Descent",
    "source": "Deep Reinforcement Learning - Slide 14",
    "source_detail": "ELEC576-Lec11.pdf, Page 14",
    "lecture": "Deep Reinforcement Learning",
    "lecture_number": "576",
    "page": 14,
    "content_type": "text",
    "doc_id": "slide_576_14",
    "doc_type": "slide",
    "is_definition": false,
    "contains_equation": true,
    "importance": "high",
    "tags": [
      "loss functions"
    ]
  },
  {
    "text": "Value-Based Deep Reinforcement Learning",
    "source": "Deep Reinforcement Learning - Slide 15",
    "source_detail": "ELEC576-Lec11.pdf, Page 15",
    "lecture": "Deep Reinforcement Learning",
    "lecture_number": "576",
    "page": 15,
    "content_type": "text",
    "doc_id": "slide_576_15",
    "doc_type": "slide",
    "is_definition": false,
    "contains_equation": false,
    "importance": "high",
    "tags": [
      "Deep Reinforcement Learning",
      "Value-Based Learning",
      "Machine Learning",
      "Reinforcement Learning"
    ]
  },
  {
    "text": "Value-Based Deep RL \u2022 The value function is represented by Q-network with weights w [David Silver ICML 2016]",
    "source": "Deep Reinforcement Learning - Slide 16",
    "source_detail": "ELEC576-Lec11.pdf, Page 16",
    "lecture": "Deep Reinforcement Learning",
    "lecture_number": "576",
    "page": 16,
    "content_type": "text",
    "doc_id": "slide_576_16",
    "doc_type": "slide",
    "is_definition": true,
    "contains_equation": true,
    "importance": "high",
    "tags": [
      "Value-Based Deep RL",
      "David Silver",
      "ICML 2016",
      "Q-network",
      "weights"
    ]
  },
  {
    "text": "Q-Learning Optimal Q-values obey Bellman Equation \u2022 Minimise MSE loss via SGD \u2022 Diverges due to \u2022 Correlations between samples \u2022 Non-stationary targets \u2022",
    "source": "Deep Reinforcement Learning - Slide 17",
    "source_detail": "ELEC576-Lec11.pdf, Page 17",
    "lecture": "Deep Reinforcement Learning",
    "lecture_number": "576",
    "page": 17,
    "content_type": "text",
    "doc_id": "slide_576_17",
    "doc_type": "slide",
    "is_definition": false,
    "contains_equation": true,
    "importance": "high",
    "tags": [
      "optimization",
      "loss functions"
    ]
  },
  {
    "text": "DQN: Atari 2600 [David Silver ICML 2016]",
    "source": "Deep Reinforcement Learning - Slide 18",
    "source_detail": "ELEC576-Lec11.pdf, Page 18",
    "lecture": "Deep Reinforcement Learning",
    "lecture_number": "576",
    "page": 18,
    "content_type": "text",
    "doc_id": "slide_576_18",
    "doc_type": "slide",
    "is_definition": false,
    "contains_equation": false,
    "importance": "high",
    "tags": [
      "DQN",
      "David Silver",
      "ICML 2016",
      "Atari 2600"
    ]
  },
  {
    "text": "Experience Replay \u2022 Remove correlations \u2022 Build dataset from agent\u2019s own experience \u2022 Sample experiences from the dataset and apply update [David Silver ICML 2016]",
    "source": "Deep Reinforcement Learning - Slide 19",
    "source_detail": "ELEC576-Lec11.pdf, Page 19",
    "lecture": "Deep Reinforcement Learning",
    "lecture_number": "576",
    "page": 19,
    "content_type": "text",
    "doc_id": "slide_576_19",
    "doc_type": "slide",
    "is_definition": false,
    "contains_equation": false,
    "importance": "high",
    "tags": [
      "Agent's own experience",
      "Remove correlations",
      "Build dataset",
      "Experience Replay",
      "Sample experiences"
    ]
  },
  {
    "text": "Benefits of Experience Replay Greater data efficiency \u2022 Breaks the correlations \u2022 Smoothing out learning and avoiding oscillations or \u2022 divergence in parameters",
    "source": "Deep Reinforcement Learning - Slide 20",
    "source_detail": "ELEC576-Lec11.pdf, Page 20",
    "lecture": "Deep Reinforcement Learning",
    "lecture_number": "576",
    "page": 20,
    "content_type": "text",
    "doc_id": "slide_576_20",
    "doc_type": "slide",
    "is_definition": false,
    "contains_equation": false,
    "importance": "high",
    "tags": [
      "Parameter Divergence",
      "Learning Stability",
      "Experience Replay",
      "Data Efficiency",
      "Correlations"
    ]
  },
  {
    "text": "DQN: Atari 2600 End-to-end learning of Q(s,a) from the frames \u2022 Input state is stack of pixels from last 4 frames \u2022 Output is Q(s,a) for the joystick/button positions \u2022 Varies with different games (~3-18) \u2022 Reward is change in score for that step \u2022",
    "source": "Deep Reinforcement Learning - Slide 21",
    "source_detail": "ELEC576-Lec11.pdf, Page 21",
    "lecture": "Deep Reinforcement Learning",
    "lecture_number": "576",
    "page": 21,
    "content_type": "text",
    "doc_id": "slide_576_21",
    "doc_type": "slide",
    "is_definition": true,
    "contains_equation": false,
    "importance": "high",
    "tags": [
      "reward system",
      "Q-learning",
      "input state",
      "DQN",
      "Atari 2600"
    ]
  },
  {
    "text": "DQN w/ Experience Replay [Deepmind 2014]",
    "source": "Deep Reinforcement Learning - Slide 22",
    "source_detail": "ELEC576-Lec11.pdf, Page 22",
    "lecture": "Deep Reinforcement Learning",
    "lecture_number": "576",
    "page": 22,
    "content_type": "text",
    "doc_id": "slide_576_22",
    "doc_type": "slide",
    "is_definition": false,
    "contains_equation": true,
    "importance": "high",
    "tags": [
      "Experience Replay",
      "2014",
      "DQN",
      "Deepmind",
      "Reinforcement Learning"
    ]
  },
  {
    "text": "DQN: Atari 2600 Network architecture and hyper parameters are \u2022 fixed across all the games [David Silver ICML 2016]",
    "source": "Deep Reinforcement Learning - Slide 23",
    "source_detail": "ELEC576-Lec11.pdf, Page 23",
    "lecture": "Deep Reinforcement Learning",
    "lecture_number": "576",
    "page": 23,
    "content_type": "text",
    "doc_id": "slide_576_23",
    "doc_type": "slide",
    "is_definition": false,
    "contains_equation": false,
    "importance": "high",
    "tags": [
      "hyperparameters",
      "DQN",
      "David Silver ICML 2016",
      "network architecture",
      "Atari 2600"
    ]
  },
  {
    "text": "DQN: Atari Video [Jon Juett Youtube]",
    "source": "Deep Reinforcement Learning - Slide 24",
    "source_detail": "ELEC576-Lec11.pdf, Page 24",
    "lecture": "Deep Reinforcement Learning",
    "lecture_number": "576",
    "page": 24,
    "content_type": "text",
    "doc_id": "slide_576_24",
    "doc_type": "slide",
    "is_definition": false,
    "contains_equation": false,
    "importance": "medium",
    "tags": [
      "Video Games",
      "Jon Juett",
      "DQN",
      "Atari",
      "Reinforcement Learning"
    ]
  },
  {
    "text": "DQN: Atari Video [PhysX Vision Youtube]",
    "source": "Deep Reinforcement Learning - Slide 25",
    "source_detail": "ELEC576-Lec11.pdf, Page 25",
    "lecture": "Deep Reinforcement Learning",
    "lecture_number": "576",
    "page": 25,
    "content_type": "text",
    "doc_id": "slide_576_25",
    "doc_type": "slide",
    "is_definition": false,
    "contains_equation": false,
    "importance": "medium",
    "tags": [
      "YouTube",
      "PhysX",
      "DQN",
      "Video",
      "Atari"
    ]
  },
  {
    "text": "Improvements after DQN Double DQN \u2022 Current Q-network w is used to select actions \u2022 Older Q-network is w- is used to evaluate actions \u2022 Prioritized reply \u2022 Store experience in priority queue by the DQN \u2022 error",
    "source": "Deep Reinforcement Learning - Slide 26",
    "source_detail": "ELEC576-Lec11.pdf, Page 26",
    "lecture": "Deep Reinforcement Learning",
    "lecture_number": "576",
    "page": 26,
    "content_type": "text",
    "doc_id": "slide_576_26",
    "doc_type": "slide",
    "is_definition": false,
    "contains_equation": false,
    "importance": "high",
    "tags": [
      "experience replay",
      "Prioritized replay",
      "Double DQN",
      "DQN",
      "Q-network"
    ]
  },
  {
    "text": "Improvements after DQN Duelling Network \u2022 Action-independent value function V(s,v) \u2022 Action-dependent advantage function A(s,a,w) \u2022 Q(s,a) = V(s,v) + A(s,a,w) \u2022",
    "source": "Deep Reinforcement Learning - Slide 27",
    "source_detail": "ELEC576-Lec11.pdf, Page 27",
    "lecture": "Deep Reinforcement Learning",
    "lecture_number": "576",
    "page": 27,
    "content_type": "text",
    "doc_id": "slide_576_27",
    "doc_type": "slide",
    "is_definition": true,
    "contains_equation": true,
    "importance": "high",
    "tags": [
      "value function",
      "Q-learning",
      "advantage function",
      "Duelling Network",
      "DQN"
    ]
  },
  {
    "text": "Improvements after DQN [Marc G. Bellemare Youtube]",
    "source": "Deep Reinforcement Learning - Slide 28",
    "source_detail": "ELEC576-Lec11.pdf, Page 28",
    "lecture": "Deep Reinforcement Learning",
    "lecture_number": "576",
    "page": 28,
    "content_type": "text",
    "doc_id": "slide_576_28",
    "doc_type": "slide",
    "is_definition": false,
    "contains_equation": true,
    "importance": "high",
    "tags": [
      "DQN",
      "YouTube",
      "Marc G. Bellemare",
      "improvements"
    ]
  },
  {
    "text": "General Reinforcement Learning Architecture [David Silver ICML 2016]",
    "source": "Deep Reinforcement Learning - Slide 29",
    "source_detail": "ELEC576-Lec11.pdf, Page 29",
    "lecture": "Deep Reinforcement Learning",
    "lecture_number": "576",
    "page": 29,
    "content_type": "text",
    "doc_id": "slide_576_29",
    "doc_type": "slide",
    "is_definition": false,
    "contains_equation": false,
    "importance": "high",
    "tags": [
      "David Silver",
      "ICML 2016",
      "Architecture",
      "Reinforcement Learning"
    ]
  },
  {
    "text": "Policy-based Deep Reinforcement Learning",
    "source": "Deep Reinforcement Learning - Slide 30",
    "source_detail": "ELEC576-Lec11.pdf, Page 30",
    "lecture": "Deep Reinforcement Learning",
    "lecture_number": "576",
    "page": 30,
    "content_type": "text",
    "doc_id": "slide_576_30",
    "doc_type": "slide",
    "is_definition": false,
    "contains_equation": false,
    "importance": "high",
    "tags": [
      "Deep Reinforcement Learning",
      "Policy-based",
      "Artificial Intelligence",
      "Machine Learning"
    ]
  },
  {
    "text": "Deep Policy Network The policy is represented by a network with weights u \u2022 Define objective function as total discounted reward \u2022 Optimise objectiva via SGD \u2022 Adjust policy parameters u to achieve higher reward \u2022 [David Silver ICML 2016]",
    "source": "Deep Reinforcement Learning - Slide 31",
    "source_detail": "ELEC576-Lec11.pdf, Page 31",
    "lecture": "Deep Reinforcement Learning",
    "lecture_number": "576",
    "page": 31,
    "content_type": "text",
    "doc_id": "slide_576_31",
    "doc_type": "slide",
    "is_definition": true,
    "contains_equation": true,
    "importance": "high",
    "tags": [
      "optimization"
    ]
  },
  {
    "text": "Policy Gradients Gradient of a stochastic policy \u2022 Gradient of a deterministic policy \u2022 [David Silver ICML 2016]",
    "source": "Deep Reinforcement Learning - Slide 32",
    "source_detail": "ELEC576-Lec11.pdf, Page 32",
    "lecture": "Deep Reinforcement Learning",
    "lecture_number": "576",
    "page": 32,
    "content_type": "text",
    "doc_id": "slide_576_32",
    "doc_type": "slide",
    "is_definition": true,
    "contains_equation": false,
    "importance": "high",
    "tags": [
      "David Silver",
      "Policy Gradients",
      "Deterministic Policy",
      "Stochastic Policy",
      "ICML 2016"
    ]
  },
  {
    "text": "Actor Critic Algorithm Estimate value function Q(s, a, w) \u2022 Update policy parameters u via SGD \u2022 [David Silver ICML 2016]",
    "source": "Deep Reinforcement Learning - Slide 33",
    "source_detail": "ELEC576-Lec11.pdf, Page 33",
    "lecture": "Deep Reinforcement Learning",
    "lecture_number": "576",
    "page": 33,
    "content_type": "text",
    "doc_id": "slide_576_33",
    "doc_type": "slide",
    "is_definition": false,
    "contains_equation": true,
    "importance": "high",
    "tags": [
      "optimization"
    ]
  },
  {
    "text": "Asynchronous Advantage Actor-Critic: Labyrinth [DeepMind Youtube]",
    "source": "Deep Reinforcement Learning - Slide 34",
    "source_detail": "ELEC576-Lec11.pdf, Page 34",
    "lecture": "Deep Reinforcement Learning",
    "lecture_number": "576",
    "page": 34,
    "content_type": "text",
    "doc_id": "slide_576_34",
    "doc_type": "slide",
    "is_definition": false,
    "contains_equation": true,
    "importance": "high",
    "tags": [
      "DeepMind",
      "Asynchronous Advantage Actor-Critic",
      "Artificial Intelligence",
      "Labyrinth",
      "Reinforcement Learning"
    ]
  },
  {
    "text": "A3C: Labyrinth End-to-end learning of softmax policy from raw \u2022 pixels Observations are pixels of the current frame \u2022 State is an LSTM \u2022 Outputs both value V(s) & softmax over actions \u2022 Task is to collect apples (+1) and escape (+10) \u2022 [David Silver ICML 2016]",
    "source": "Deep Reinforcement Learning - Slide 35",
    "source_detail": "ELEC576-Lec11.pdf, Page 35",
    "lecture": "Deep Reinforcement Learning",
    "lecture_number": "576",
    "page": 35,
    "content_type": "text",
    "doc_id": "slide_576_35",
    "doc_type": "slide",
    "is_definition": false,
    "contains_equation": false,
    "importance": "high",
    "tags": [
      "rnn"
    ]
  },
  {
    "text": "Improvements on the Basic DQN Algorithm",
    "source": "Deep Reinforcement Learning - Slide 36",
    "source_detail": "ELEC576-Lec11.pdf, Page 36",
    "lecture": "Deep Reinforcement Learning",
    "lecture_number": "576",
    "page": 36,
    "content_type": "text",
    "doc_id": "slide_576_36",
    "doc_type": "slide",
    "is_definition": false,
    "contains_equation": true,
    "importance": "high",
    "tags": [
      "reinforcement learning",
      "artificial intelligence",
      "machine learning",
      "algorithm improvements",
      "DQN"
    ]
  },
  {
    "text": "Double DQN Double DQN \u2022 Current Q-network w is used to select actions \u2022 Older Q-network is w- is used to evaluate actions \u2022 Prioritized reply \u2022 Store experience in priority queue by the DQN \u2022 error",
    "source": "Deep Reinforcement Learning - Slide 37",
    "source_detail": "ELEC576-Lec11.pdf, Page 37",
    "lecture": "Deep Reinforcement Learning",
    "lecture_number": "576",
    "page": 37,
    "content_type": "text",
    "doc_id": "slide_576_37",
    "doc_type": "slide",
    "is_definition": false,
    "contains_equation": false,
    "importance": "high",
    "tags": [
      "experience replay",
      "error evaluation",
      "Prioritized replay",
      "Double DQN",
      "Q-network"
    ]
  },
  {
    "text": "Dueling Network Duelling Network \u2022 Action-independent value function V(s,v) \u2022 Action-dependent advantage function A(s,a,w) \u2022 Q(s,a) = V(s,v) + A(s,a,w) \u2022",
    "source": "Deep Reinforcement Learning - Slide 38",
    "source_detail": "ELEC576-Lec11.pdf, Page 38",
    "lecture": "Deep Reinforcement Learning",
    "lecture_number": "576",
    "page": 38,
    "content_type": "text",
    "doc_id": "slide_576_38",
    "doc_type": "slide",
    "is_definition": true,
    "contains_equation": true,
    "importance": "high",
    "tags": [
      "value function",
      "Dueling Network",
      "advantage function",
      "Q-function"
    ]
  },
  {
    "text": "Prioritized Experience Replay [Schaul et al 2016]",
    "source": "Deep Reinforcement Learning - Slide 39",
    "source_detail": "ELEC576-Lec11.pdf, Page 39",
    "lecture": "Deep Reinforcement Learning",
    "lecture_number": "576",
    "page": 39,
    "content_type": "text",
    "doc_id": "slide_576_39",
    "doc_type": "slide",
    "is_definition": false,
    "contains_equation": false,
    "importance": "high",
    "tags": [
      "experience replay",
      "reinforcement learning",
      "Schaul et al 2016",
      "Prioritized Experience Replay",
      "machine learning"
    ]
  },
  {
    "text": "Prioritized Experience Replay [Schaul et al 2016]",
    "source": "Deep Reinforcement Learning - Slide 40",
    "source_detail": "ELEC576-Lec11.pdf, Page 40",
    "lecture": "Deep Reinforcement Learning",
    "lecture_number": "576",
    "page": 40,
    "content_type": "text",
    "doc_id": "slide_576_40",
    "doc_type": "slide",
    "is_definition": false,
    "contains_equation": false,
    "importance": "high",
    "tags": [
      "experience replay",
      "reinforcement learning",
      "Schaul et al 2016",
      "Prioritized Experience Replay",
      "machine learning"
    ]
  },
  {
    "text": "Improvements after DQN [Marc G. Bellemare Youtube]",
    "source": "Deep Reinforcement Learning - Slide 41",
    "source_detail": "ELEC576-Lec11.pdf, Page 41",
    "lecture": "Deep Reinforcement Learning",
    "lecture_number": "576",
    "page": 41,
    "content_type": "text",
    "doc_id": "slide_576_41",
    "doc_type": "slide",
    "is_definition": false,
    "contains_equation": true,
    "importance": "high",
    "tags": [
      "DQN",
      "YouTube",
      "Marc G. Bellemare",
      "improvements"
    ]
  },
  {
    "text": "General Reinforcement Learning Architecture [David Silver ICML 2016]",
    "source": "Deep Reinforcement Learning - Slide 42",
    "source_detail": "ELEC576-Lec11.pdf, Page 42",
    "lecture": "Deep Reinforcement Learning",
    "lecture_number": "576",
    "page": 42,
    "content_type": "text",
    "doc_id": "slide_576_42",
    "doc_type": "slide",
    "is_definition": false,
    "contains_equation": true,
    "importance": "high",
    "tags": [
      "David Silver",
      "ICML 2016",
      "Architecture",
      "Reinforcement Learning"
    ]
  },
  {
    "text": "Policy-based Deep Reinforcement Learning",
    "source": "Deep Reinforcement Learning - Slide 43",
    "source_detail": "ELEC576-Lec11.pdf, Page 43",
    "lecture": "Deep Reinforcement Learning",
    "lecture_number": "576",
    "page": 43,
    "content_type": "text",
    "doc_id": "slide_576_43",
    "doc_type": "slide",
    "is_definition": false,
    "contains_equation": false,
    "importance": "high",
    "tags": [
      "Deep Reinforcement Learning",
      "Policy-based",
      "Artificial Intelligence",
      "Machine Learning"
    ]
  },
  {
    "text": "Deep Policy Network The policy is represented by a network with weights u \u2022 Define objective function as total discounted reward \u2022 Optimise objective via SGD \u2022 Adjust policy parameters u to achieve higher reward \u2022 [David Silver ICML 2016]",
    "source": "Deep Reinforcement Learning - Slide 44",
    "source_detail": "ELEC576-Lec11.pdf, Page 44",
    "lecture": "Deep Reinforcement Learning",
    "lecture_number": "576",
    "page": 44,
    "content_type": "text",
    "doc_id": "slide_576_44",
    "doc_type": "slide",
    "is_definition": true,
    "contains_equation": true,
    "importance": "high",
    "tags": [
      "optimization"
    ]
  },
  {
    "text": "Policy Gradients Gradient of a stochastic policy \u2022 Gradient of a deterministic policy \u2022 [David Silver ICML 2016]",
    "source": "Deep Reinforcement Learning - Slide 45",
    "source_detail": "ELEC576-Lec11.pdf, Page 45",
    "lecture": "Deep Reinforcement Learning",
    "lecture_number": "576",
    "page": 45,
    "content_type": "text",
    "doc_id": "slide_576_45",
    "doc_type": "slide",
    "is_definition": false,
    "contains_equation": true,
    "importance": "high",
    "tags": [
      "David Silver",
      "Policy Gradients",
      "Deterministic Policy",
      "Stochastic Policy",
      "ICML 2016"
    ]
  },
  {
    "text": "Actor Critic Algorithm Estimate value function Q(s, a, w) \u2022 Update policy parameters u via SGD \u2022 [David Silver ICML 2016]",
    "source": "Deep Reinforcement Learning - Slide 46",
    "source_detail": "ELEC576-Lec11.pdf, Page 46",
    "lecture": "Deep Reinforcement Learning",
    "lecture_number": "576",
    "page": 46,
    "content_type": "text",
    "doc_id": "slide_576_46",
    "doc_type": "slide",
    "is_definition": false,
    "contains_equation": true,
    "importance": "high",
    "tags": [
      "optimization"
    ]
  },
  {
    "text": "Asynchronous Advantage Actor-Critic: Labyrinth [DeepMind Youtube]",
    "source": "Deep Reinforcement Learning - Slide 47",
    "source_detail": "ELEC576-Lec11.pdf, Page 47",
    "lecture": "Deep Reinforcement Learning",
    "lecture_number": "576",
    "page": 47,
    "content_type": "text",
    "doc_id": "slide_576_47",
    "doc_type": "slide",
    "is_definition": false,
    "contains_equation": true,
    "importance": "high",
    "tags": [
      "DeepMind",
      "Asynchronous Advantage Actor-Critic",
      "Artificial Intelligence",
      "Labyrinth",
      "Reinforcement Learning"
    ]
  },
  {
    "text": "A3C: Labyrinth End-to-end learning of softmax policy from raw \u2022 pixels Observations are pixels of the current frame \u2022 State is an LSTM \u2022 Outputs both value V(s) & softmax over actions \u2022 Task is to collect apples (+1) and escape (+10) \u2022 [David Silver ICML 2016]",
    "source": "Deep Reinforcement Learning - Slide 48",
    "source_detail": "ELEC576-Lec11.pdf, Page 48",
    "lecture": "Deep Reinforcement Learning",
    "lecture_number": "576",
    "page": 48,
    "content_type": "text",
    "doc_id": "slide_576_48",
    "doc_type": "slide",
    "is_definition": false,
    "contains_equation": false,
    "importance": "high",
    "tags": [
      "rnn"
    ]
  },
  {
    "text": "Model-based Deep Reinforcement Learning",
    "source": "Deep Reinforcement Learning - Slide 49",
    "source_detail": "ELEC576-Lec11.pdf, Page 49",
    "lecture": "Deep Reinforcement Learning",
    "lecture_number": "576",
    "page": 49,
    "content_type": "text",
    "doc_id": "slide_576_49",
    "doc_type": "slide",
    "is_definition": false,
    "contains_equation": false,
    "importance": "high",
    "tags": [
      "Model-based",
      "Deep Reinforcement Learning",
      "Artificial Intelligence",
      "Machine Learning"
    ]
  },
  {
    "text": "Learning Models of the Environment Generative model of Atari 2600 \u2022 Issues \u2022 Errors in transition model compound over the \u2022 trajectory Planning trajectory differ from executed \u2022 trajectories Long, unusual trajectory rewards are totally wrong \u2022 [David Silver ICML 2016]",
    "source": "Deep Reinforcement Learning - Slide 50",
    "source_detail": "ELEC576-Lec11.pdf, Page 50",
    "lecture": "Deep Reinforcement Learning",
    "lecture_number": "576",
    "page": 50,
    "content_type": "text",
    "doc_id": "slide_576_50",
    "doc_type": "slide",
    "is_definition": false,
    "contains_equation": false,
    "importance": "high",
    "tags": [
      "generative models",
      "neural networks"
    ]
  },
  {
    "text": "Learning Models of the Environment [Junhyuk Oh Youtube]",
    "source": "Deep Reinforcement Learning - Slide 51",
    "source_detail": "ELEC576-Lec11.pdf, Page 51",
    "lecture": "Deep Reinforcement Learning",
    "lecture_number": "576",
    "page": 51,
    "content_type": "text",
    "doc_id": "slide_576_51",
    "doc_type": "slide",
    "is_definition": false,
    "contains_equation": false,
    "importance": "medium",
    "tags": [
      "Environment",
      "Learning Models",
      "Junhyuk Oh",
      "YouTube"
    ]
  },
  {
    "text": "Newer Implementations",
    "source": "Deep Reinforcement Learning - Slide 52",
    "source_detail": "ELEC576-Lec11.pdf, Page 52",
    "lecture": "Deep Reinforcement Learning",
    "lecture_number": "576",
    "page": 52,
    "content_type": "text",
    "doc_id": "slide_576_52",
    "doc_type": "slide",
    "is_definition": false,
    "contains_equation": false,
    "importance": "low",
    "tags": [
      "Newer Implementations"
    ]
  },
  {
    "text": "AlphaGo [Deepmind Nature]",
    "source": "Deep Reinforcement Learning - Slide 53",
    "source_detail": "ELEC576-Lec11.pdf, Page 53",
    "lecture": "Deep Reinforcement Learning",
    "lecture_number": "576",
    "page": 53,
    "content_type": "text",
    "doc_id": "slide_576_53",
    "doc_type": "slide",
    "is_definition": false,
    "contains_equation": false,
    "importance": "high",
    "tags": [
      "AlphaGo",
      "Machine Learning",
      "DeepMind",
      "Game Strategy",
      "Artificial Intelligence"
    ]
  },
  {
    "text": "Policy and Value Networks [Deepmind Nature]",
    "source": "Deep Reinforcement Learning - Slide 54",
    "source_detail": "ELEC576-Lec11.pdf, Page 54",
    "lecture": "Deep Reinforcement Learning",
    "lecture_number": "576",
    "page": 54,
    "content_type": "text",
    "doc_id": "slide_576_54",
    "doc_type": "slide",
    "is_definition": false,
    "contains_equation": true,
    "importance": "high",
    "tags": [
      "Value Networks",
      "DeepMind",
      "Policy Networks",
      "Artificial Intelligence",
      "Reinforcement Learning"
    ]
  },
  {
    "text": "Monte Carlo Tree Search [Deepmind Nature]",
    "source": "Deep Reinforcement Learning - Slide 55",
    "source_detail": "ELEC576-Lec11.pdf, Page 55",
    "lecture": "Deep Reinforcement Learning",
    "lecture_number": "576",
    "page": 55,
    "content_type": "text",
    "doc_id": "slide_576_55",
    "doc_type": "slide",
    "is_definition": false,
    "contains_equation": false,
    "importance": "high",
    "tags": [
      "DeepMind",
      "Game Theory",
      "Artificial Intelligence",
      "Monte Carlo Tree Search",
      "Reinforcement Learning"
    ]
  },
  {
    "text": "AlphaGo Results [Deepmind Nature]",
    "source": "Deep Reinforcement Learning - Slide 56",
    "source_detail": "ELEC576-Lec11.pdf, Page 56",
    "lecture": "Deep Reinforcement Learning",
    "lecture_number": "576",
    "page": 56,
    "content_type": "text",
    "doc_id": "slide_576_56",
    "doc_type": "slide",
    "is_definition": false,
    "contains_equation": false,
    "importance": "high",
    "tags": [
      "AlphaGo",
      "Go",
      "AI",
      "DeepMind",
      "machine learning"
    ]
  },
  {
    "text": "Which Move to Make [Deepmind Nature]",
    "source": "Deep Reinforcement Learning - Slide 57",
    "source_detail": "ELEC576-Lec11.pdf, Page 57",
    "lecture": "Deep Reinforcement Learning",
    "lecture_number": "576",
    "page": 57,
    "content_type": "text",
    "doc_id": "slide_576_57",
    "doc_type": "slide",
    "is_definition": false,
    "contains_equation": true,
    "importance": "high",
    "tags": [
      "Nature",
      "Deepmind",
      "Move",
      "Decision Making"
    ]
  },
  {
    "text": "Five Matches Against Fan Hui [Deepmind Nature]",
    "source": "Deep Reinforcement Learning - Slide 58",
    "source_detail": "ELEC576-Lec11.pdf, Page 58",
    "lecture": "Deep Reinforcement Learning",
    "lecture_number": "576",
    "page": 58,
    "content_type": "text",
    "doc_id": "slide_576_58",
    "doc_type": "slide",
    "is_definition": false,
    "contains_equation": false,
    "importance": "medium",
    "tags": [
      "Go",
      "matches",
      "AI",
      "DeepMind",
      "Fan Hui"
    ]
  },
  {
    "text": "Neural Architecture Search with Reinforcement Learning Uses an RNN to generate model descriptions of the \u2022 NNs Trains the RNN with RL to maximize expected \u2022 accuracy of generated architectures on validation set",
    "source": "Deep Reinforcement Learning - Slide 59",
    "source_detail": "ELEC576-Lec11.pdf, Page 59",
    "lecture": "Deep Reinforcement Learning",
    "lecture_number": "576",
    "page": 59,
    "content_type": "text",
    "doc_id": "slide_576_59",
    "doc_type": "slide",
    "is_definition": false,
    "contains_equation": true,
    "importance": "high",
    "tags": [
      "rnn",
      "neural networks"
    ]
  },
  {
    "text": "Neural Architecture Search [Zoph & Le Arxiv 2016]",
    "source": "Deep Reinforcement Learning - Slide 60",
    "source_detail": "ELEC576-Lec11.pdf, Page 60",
    "lecture": "Deep Reinforcement Learning",
    "lecture_number": "576",
    "page": 60,
    "content_type": "text",
    "doc_id": "slide_576_60",
    "doc_type": "slide",
    "is_definition": false,
    "contains_equation": false,
    "importance": "high",
    "tags": [
      "Neural Architecture Search",
      "2016",
      "Le",
      "Arxiv",
      "Zoph"
    ]
  },
  {
    "text": "RNN Controller [Zoph & Le Arxiv 2016]",
    "source": "Deep Reinforcement Learning - Slide 61",
    "source_detail": "ELEC576-Lec11.pdf, Page 61",
    "lecture": "Deep Reinforcement Learning",
    "lecture_number": "576",
    "page": 61,
    "content_type": "text",
    "doc_id": "slide_576_61",
    "doc_type": "slide",
    "is_definition": false,
    "contains_equation": false,
    "importance": "high",
    "tags": [
      "rnn",
      "neural networks"
    ]
  },
  {
    "text": "Training with REINFORCE [Zoph & Le Arxiv 2016]",
    "source": "Deep Reinforcement Learning - Slide 62",
    "source_detail": "ELEC576-Lec11.pdf, Page 62",
    "lecture": "Deep Reinforcement Learning",
    "lecture_number": "576",
    "page": 62,
    "content_type": "text",
    "doc_id": "slide_576_62",
    "doc_type": "slide",
    "is_definition": false,
    "contains_equation": true,
    "importance": "high",
    "tags": [
      "2016",
      "REINFORCE",
      "Le",
      "Arxiv",
      "Zoph"
    ]
  },
  {
    "text": "Parallel Training [Zoph & Le Arxiv 2016]",
    "source": "Deep Reinforcement Learning - Slide 63",
    "source_detail": "ELEC576-Lec11.pdf, Page 63",
    "lecture": "Deep Reinforcement Learning",
    "lecture_number": "576",
    "page": 63,
    "content_type": "text",
    "doc_id": "slide_576_63",
    "doc_type": "slide",
    "is_definition": false,
    "contains_equation": false,
    "importance": "high",
    "tags": [
      "2016",
      "Parallel Training",
      "Le",
      "Arxiv",
      "Zoph"
    ]
  },
  {
    "text": "Increase Architecture Complexity [Zoph & Le Arxiv 2016]",
    "source": "Deep Reinforcement Learning - Slide 64",
    "source_detail": "ELEC576-Lec11.pdf, Page 64",
    "lecture": "Deep Reinforcement Learning",
    "lecture_number": "576",
    "page": 64,
    "content_type": "text",
    "doc_id": "slide_576_64",
    "doc_type": "slide",
    "is_definition": false,
    "contains_equation": true,
    "importance": "high",
    "tags": [
      "Le",
      "Zoph",
      "Architecture Complexity",
      "Arxiv 2016"
    ]
  },
  {
    "text": "Constructing the Network [Zoph & Le Arxiv 2016]",
    "source": "Deep Reinforcement Learning - Slide 65",
    "source_detail": "ELEC576-Lec11.pdf, Page 65",
    "lecture": "Deep Reinforcement Learning",
    "lecture_number": "576",
    "page": 65,
    "content_type": "text",
    "doc_id": "slide_576_65",
    "doc_type": "slide",
    "is_definition": false,
    "contains_equation": true,
    "importance": "high",
    "tags": [
      "2016",
      "Le",
      "Constructing the Network",
      "Arxiv",
      "Zoph"
    ]
  },
  {
    "text": "Results [Zoph & Le Arxiv 2016]",
    "source": "Deep Reinforcement Learning - Slide 66",
    "source_detail": "ELEC576-Lec11.pdf, Page 66",
    "lecture": "Deep Reinforcement Learning",
    "lecture_number": "576",
    "page": 66,
    "content_type": "text",
    "doc_id": "slide_576_66",
    "doc_type": "slide",
    "is_definition": false,
    "contains_equation": false,
    "importance": "low",
    "tags": [
      "2016",
      "Le",
      "Results",
      "Arxiv",
      "Zoph"
    ]
  },
  {
    "text": "Reinforcement Learning with Unsupervised Auxiliary Tasks Train an agent that maximises other pseudo-reward \u2022 functions simultaneously by RL Those tasks have to develop in absence of \u2022 extrinsic rewards Outperforms previous state-of-the-art on atari \u2022 Averaging 880% expert human performance \u2022",
    "source": "Deep Reinforcement Learning - Slide 67",
    "source_detail": "ELEC576-Lec11.pdf, Page 67",
    "lecture": "Deep Reinforcement Learning",
    "lecture_number": "576",
    "page": 67,
    "content_type": "text",
    "doc_id": "slide_576_67",
    "doc_type": "slide",
    "is_definition": false,
    "contains_equation": false,
    "importance": "high",
    "tags": [
      "Pseudo-reward Functions",
      "Atari Performance",
      "Expert Human Performance",
      "Unsupervised Auxiliary Tasks",
      "Reinforcement Learning"
    ]
  },
  {
    "text": "UNREAL Agent [Jaderberg et. al Arxiv 2016]",
    "source": "Deep Reinforcement Learning - Slide 68",
    "source_detail": "ELEC576-Lec11.pdf, Page 68",
    "lecture": "Deep Reinforcement Learning",
    "lecture_number": "576",
    "page": 68,
    "content_type": "text",
    "doc_id": "slide_576_68",
    "doc_type": "slide",
    "is_definition": false,
    "contains_equation": true,
    "importance": "high",
    "tags": [
      "UNREAL",
      "reinforcement learning",
      "agent-based learning",
      "Jaderberg",
      "Arxiv 2016"
    ]
  },
  {
    "text": "Auxiliary Control Tasks [Jaderberg et. al Arxiv 2016]",
    "source": "Deep Reinforcement Learning - Slide 69",
    "source_detail": "ELEC576-Lec11.pdf, Page 69",
    "lecture": "Deep Reinforcement Learning",
    "lecture_number": "576",
    "page": 69,
    "content_type": "text",
    "doc_id": "slide_576_69",
    "doc_type": "slide",
    "is_definition": false,
    "contains_equation": true,
    "importance": "high",
    "tags": [
      "Auxiliary Control Tasks",
      "Arxiv 2016",
      "Jaderberg"
    ]
  },
  {
    "text": "Auxiliary Tasks [Jaderberg et. al Arxiv 2016]",
    "source": "Deep Reinforcement Learning - Slide 70",
    "source_detail": "ELEC576-Lec11.pdf, Page 70",
    "lecture": "Deep Reinforcement Learning",
    "lecture_number": "576",
    "page": 70,
    "content_type": "text",
    "doc_id": "slide_576_70",
    "doc_type": "slide",
    "is_definition": false,
    "contains_equation": false,
    "importance": "medium",
    "tags": [
      "Auxiliary Tasks",
      "Jaderberg",
      "Arxiv 2016"
    ]
  },
  {
    "text": "UNREAL Algorithm A3C Loss is minimised on policy Value function is optimised from replayed data Auxiliary control loss is optimised off-policy from replied data Reward loss is optimised from rebalanced replay data [Jaderberg et. al Arxiv 2016]",
    "source": "Deep Reinforcement Learning - Slide 71",
    "source_detail": "ELEC576-Lec11.pdf, Page 71",
    "lecture": "Deep Reinforcement Learning",
    "lecture_number": "576",
    "page": 71,
    "content_type": "text",
    "doc_id": "slide_576_71",
    "doc_type": "slide",
    "is_definition": false,
    "contains_equation": true,
    "importance": "high",
    "tags": [
      "loss functions"
    ]
  },
  {
    "text": "Atari Results [Jaderberg et. al Arxiv 2016]",
    "source": "Deep Reinforcement Learning - Slide 72",
    "source_detail": "ELEC576-Lec11.pdf, Page 72",
    "lecture": "Deep Reinforcement Learning",
    "lecture_number": "576",
    "page": 72,
    "content_type": "text",
    "doc_id": "slide_576_72",
    "doc_type": "slide",
    "is_definition": false,
    "contains_equation": true,
    "importance": "high",
    "tags": [
      "2016",
      "reinforcement learning",
      "Jaderberg",
      "Arxiv",
      "Atari"
    ]
  },
  {
    "text": "Reinforcement Learning with Unsupervised Auxiliary Tasks Video [DeepMind Youtube]",
    "source": "Deep Reinforcement Learning - Slide 73",
    "source_detail": "ELEC576-Lec11.pdf, Page 73",
    "lecture": "Deep Reinforcement Learning",
    "lecture_number": "576",
    "page": 73,
    "content_type": "text",
    "doc_id": "slide_576_73",
    "doc_type": "slide",
    "is_definition": false,
    "contains_equation": false,
    "importance": "high",
    "tags": [
      "DeepMind",
      "Auxiliary Tasks",
      "Unsupervised Learning",
      "Video",
      "Reinforcement Learning"
    ]
  },
  {
    "text": "Deep Sensorimotor Learning https://research.googleblog.com/2016/03/deep-learning-for- robots-learning-from.html",
    "source": "Deep Reinforcement Learning - Slide 74",
    "source_detail": "ELEC576-Lec11.pdf, Page 74",
    "lecture": "Deep Reinforcement Learning",
    "lecture_number": "576",
    "page": 74,
    "content_type": "text",
    "doc_id": "slide_576_74",
    "doc_type": "slide",
    "is_definition": false,
    "contains_equation": true,
    "importance": "high",
    "tags": [
      "Machine Learning",
      "Robotics",
      "Learning from Experience",
      "Deep Learning",
      "Deep Sensorimotor Learning"
    ]
  },
  {
    "text": "Deep Learning: The Future",
    "source": "Deep Reinforcement Learning - Slide 75",
    "source_detail": "ELEC576-Lec11.pdf, Page 75",
    "lecture": "Deep Reinforcement Learning",
    "lecture_number": "576",
    "page": 75,
    "content_type": "text",
    "doc_id": "slide_576_75",
    "doc_type": "slide",
    "is_definition": false,
    "contains_equation": false,
    "importance": "high",
    "tags": [
      "Deep Learning",
      "Future",
      "Machine Learning",
      "Artificial Intelligence"
    ]
  },
  {
    "text": "Major areas of Focus Semi-Supervised Learning \u2022 Reinforcement Learning & Deep Sensorimotor Learning \u2022 Neural Networks with Memory \u2022 True Language Understanding (Not Just Statistical) \u2022 Deep Learning for Hardware and Systems (Low Power) \u2022 Theory of Deep Learning \u2022 \u2026. \u2022",
    "source": "Deep Reinforcement Learning - Slide 76",
    "source_detail": "ELEC576-Lec11.pdf, Page 76",
    "lecture": "Deep Reinforcement Learning",
    "lecture_number": "576",
    "page": 76,
    "content_type": "text",
    "doc_id": "slide_576_76",
    "doc_type": "slide",
    "is_definition": false,
    "contains_equation": false,
    "importance": "high",
    "tags": [
      "neural networks"
    ]
  },
  {
    "text": "Resources UFLDL Course \u2022 Chris Olah's Blog \u2022 Google Plus Deep Learning Community \u2022 Deep Learning First Textbook \u2022 List of Must-Read Papers \u2022",
    "source": "Deep Reinforcement Learning - Slide 77",
    "source_detail": "ELEC576-Lec11.pdf, Page 77",
    "lecture": "Deep Reinforcement Learning",
    "lecture_number": "576",
    "page": 77,
    "content_type": "text",
    "doc_id": "slide_576_77",
    "doc_type": "slide",
    "is_definition": false,
    "contains_equation": false,
    "importance": "low",
    "tags": [
      "UFLDL Course",
      "Must-Read Papers",
      "Google Plus Community",
      "Chris Olah",
      "Deep Learning"
    ]
  },
  {
    "text": "Future of Work The Guardian",
    "source": "Deep Reinforcement Learning - Slide 78",
    "source_detail": "ELEC576-Lec11.pdf, Page 78",
    "lecture": "Deep Reinforcement Learning",
    "lecture_number": "576",
    "page": 78,
    "content_type": "text",
    "doc_id": "slide_576_78",
    "doc_type": "slide",
    "is_definition": false,
    "contains_equation": false,
    "importance": "high",
    "tags": [
      "The Guardian",
      "technology impact",
      "remote work",
      "employment trends",
      "Future of Work"
    ]
  },
  {
    "text": "Future of Work Blake Irving\u2019s Blog",
    "source": "Deep Reinforcement Learning - Slide 79",
    "source_detail": "ELEC576-Lec11.pdf, Page 79",
    "lecture": "Deep Reinforcement Learning",
    "lecture_number": "576",
    "page": 79,
    "content_type": "text",
    "doc_id": "slide_576_79",
    "doc_type": "slide",
    "is_definition": false,
    "contains_equation": false,
    "importance": "high",
    "tags": [
      "Future of Work",
      "Blog",
      "Blake Irving"
    ]
  },
  {
    "text": "Outline Problem: Many perplexing phenomena in NNs lack clear theoretical \u2022 explanations: Try to understand phenomena with artificial NNs \u2022 This leads to a new theory for understanding the representation/ \u2022 learning of NNs \u201cNNs as Splines\u201d, \u201cNNs as Continuous Basis Expansions\u201d \u2022 Then circle back to neuronal networks with Implications/Applications \u2022 to Theoretical & Computational Neuroscience",
    "source": "ELEC/COMP 576 Lecture - Slide 2",
    "source_detail": "ELEC576_NNasSpine.pdf, Page 2",
    "lecture": "ELEC/COMP 576 Lecture",
    "lecture_number": "576",
    "page": 2,
    "content_type": "text",
    "doc_id": "slide_576_2",
    "doc_type": "slide",
    "is_definition": false,
    "contains_equation": false,
    "importance": "high",
    "tags": [
      "neural networks"
    ]
  },
  {
    "text": "Issues in the Learning Theory of Deep Neural Networks",
    "source": "ELEC/COMP 576 Lecture - Slide 3",
    "source_detail": "ELEC576_NNasSpine.pdf, Page 3",
    "lecture": "ELEC/COMP 576 Lecture",
    "lecture_number": "576",
    "page": 3,
    "content_type": "text",
    "doc_id": "slide_576_3",
    "doc_type": "slide",
    "is_definition": false,
    "contains_equation": true,
    "importance": "high",
    "tags": [
      "neural networks"
    ]
  },
  {
    "text": "Unexplained Phenomena Problem: Many perplexing phenomena lack theoretical explanations: \u2022 OverParametrization: The need for Overparametrization for training not \u2022 expressivity Inits: Lottery Ticket Hypothesis \u2022 Loss Surface: Highly non-convex and yet so many local minima near global \u2022 minima Generalization: Implicit Regularization despite highly underdetermined \u2022 optimization problem Potential Solution: Pass to function space parametrization (spline) \u2022",
    "source": "ELEC/COMP 576 Lecture - Slide 4",
    "source_detail": "ELEC576_NNasSpine.pdf, Page 4",
    "lecture": "ELEC/COMP 576 Lecture",
    "lecture_number": "576",
    "page": 4,
    "content_type": "text",
    "doc_id": "slide_576_4",
    "doc_type": "slide",
    "is_definition": false,
    "contains_equation": false,
    "importance": "high",
    "tags": [
      "regularization",
      "cnn",
      "optimization",
      "loss functions"
    ]
  },
  {
    "text": "Related Work Du et al, Arora et al (2018-): Circumvent dynamics of weights and instead track dynamics of \u2022 predictions (i.e. the approx. function) Neyshabur, Serebro et al (2015-).: Implicit regularization in highly underdetermined optimization \u2022 problems in ML due to parametrization and/or optimization algorithm. Focus on low weight norm solutions\u2026 recent ICLR 2020 paper characterizing class of low-weight norm ReLu NNs Baraniuk et al (2018-19): the Spline Perspective and the Geometry of deep nets \u2022 Neural Tangent Kernel: Jacot et al NeurIPS 2018, NTK valid in massively overparametrized regime, \u2022 reduces to linear dynamics Double Descent Curve: Belkin et al 2019 show when traditional U-shaped generalization curve is \u2022 replaced by a new doubled curve Williams et al (2019): Similar results re Implicit Reg in Shallow Univariate ReLu NNs; but different \u2022 abstruse parametrization and no results re the initialization and Hessian of loss surface.",
    "source": "ELEC/COMP 576 Lecture - Slide 5",
    "source_detail": "ELEC576_NNasSpine.pdf, Page 5",
    "lecture": "ELEC/COMP 576 Lecture",
    "lecture_number": "576",
    "page": 5,
    "content_type": "text",
    "doc_id": "slide_576_5",
    "doc_type": "slide",
    "is_definition": false,
    "contains_equation": false,
    "importance": "high",
    "tags": [
      "regularization",
      "loss functions",
      "optimization",
      "neural networks"
    ]
  },
  {
    "text": "To Function Space: Reparametrizing Neural Nets as Splines",
    "source": "ELEC/COMP 576 Lecture - Slide 6",
    "source_detail": "ELEC576_NNasSpine.pdf, Page 6",
    "lecture": "ELEC/COMP 576 Lecture",
    "lecture_number": "576",
    "page": 6,
    "content_type": "text",
    "doc_id": "slide_576_6",
    "doc_type": "slide",
    "is_definition": false,
    "contains_equation": true,
    "importance": "high",
    "tags": [
      "Splines",
      "Reparametrizing",
      "Function Space",
      "Neural Nets"
    ]
  },
  {
    "text": "Motivating Function Space Neural Net many:1 Spline Params Params (Weights & Biases) (Breakpoints, Curvatures & Orientations ) many:1 \u201cunfunctional\u201d dof Mod out \u201cgauge\u201d group or fix gauge dof \u2022 \u2022 Symmetry Group(\u201cgauge\u201d) is large Every dof matters for the function / loss \u2022 \u2022",
    "source": "ELEC/COMP 576 Lecture - Slide 7",
    "source_detail": "ELEC576_NNasSpine.pdf, Page 7",
    "lecture": "ELEC/COMP 576 Lecture",
    "lecture_number": "576",
    "page": 7,
    "content_type": "text",
    "doc_id": "slide_576_7",
    "doc_type": "slide",
    "is_definition": false,
    "contains_equation": true,
    "importance": "high",
    "tags": [
      "loss functions"
    ]
  },
  {
    "text": "What is the role of individual neurons? A simple neural net example We\u2019ll focus on Univariate Shallow/Deep ReLu NNs: Shallow Univariate ReLu NN",
    "source": "ELEC/COMP 576 Lecture - Slide 8",
    "source_detail": "ELEC576_NNasSpine.pdf, Page 8",
    "lecture": "ELEC/COMP 576 Lecture",
    "lecture_number": "576",
    "page": 8,
    "content_type": "text",
    "doc_id": "slide_576_8",
    "doc_type": "slide",
    "is_definition": false,
    "contains_equation": false,
    "importance": "medium",
    "tags": [
      "neural networks"
    ]
  },
  {
    "text": "What is the role of individual neurons? A simple neural net example We\u2019ll focus on Univariate Shallow/Deep ReLu NNs: Shallow Univariate ReLu NN",
    "source": "ELEC/COMP 576 Lecture - Slide 9",
    "source_detail": "ELEC576_NNasSpine.pdf, Page 9",
    "lecture": "ELEC/COMP 576 Lecture",
    "lecture_number": "576",
    "page": 9,
    "content_type": "text",
    "doc_id": "slide_576_9",
    "doc_type": "slide",
    "is_definition": false,
    "contains_equation": false,
    "importance": "medium",
    "tags": [
      "neural networks"
    ]
  },
  {
    "text": "ReLu Neural Nets as Continuous PieceWise Linear (CPWL) Functions Reparametrization from NN to BDSO: Breakpoint Orientation Shallow Univariate ReLu NN Delta-Slope (\u201cCurvature\u201d)",
    "source": "ELEC/COMP 576 Lecture - Slide 10",
    "source_detail": "ELEC576_NNasSpine.pdf, Page 10",
    "lecture": "ELEC/COMP 576 Lecture",
    "lecture_number": "576",
    "page": 10,
    "content_type": "text",
    "doc_id": "slide_576_10",
    "doc_type": "slide",
    "is_definition": true,
    "contains_equation": false,
    "importance": "high",
    "tags": [
      "neural networks"
    ]
  },
  {
    "text": "Recasting the Simple ReLu Neural Net as a Continuous Piece-Wise Linear (CPWL) Function We\u2019ll focus on Univariate Shallow/Deep ReLu NNs: Breakpoints+Delta-Slopes Breakpoint enable the modeling of curvature Orientation (right/left) Each Breakpoint only \u201csees\u201d data/residuals Shallow Univariate ReLu NN in the direction it is facing/Oriented Delta-Slope (\u201cCurvature\u201d)",
    "source": "ELEC/COMP 576 Lecture - Slide 11",
    "source_detail": "ELEC576_NNasSpine.pdf, Page 11",
    "lecture": "ELEC/COMP 576 Lecture",
    "lecture_number": "576",
    "page": 11,
    "content_type": "text",
    "doc_id": "slide_576_11",
    "doc_type": "slide",
    "is_definition": false,
    "contains_equation": false,
    "importance": "high",
    "tags": [
      "neural networks"
    ]
  },
  {
    "text": "Ongoing Work: Generalizing ReLU NN to Multivariate Inputs Multivariate Spline 2-Dimensional Inputs with Parametrization of a Data Gap ReLU NN",
    "source": "ELEC/COMP 576 Lecture - Slide 12",
    "source_detail": "ELEC576_NNasSpine.pdf, Page 12",
    "lecture": "ELEC/COMP 576 Lecture",
    "lecture_number": "576",
    "page": 12,
    "content_type": "text",
    "doc_id": "slide_576_12",
    "doc_type": "slide",
    "is_definition": false,
    "contains_equation": true,
    "importance": "high",
    "tags": [
      "neural networks"
    ]
  },
  {
    "text": "Ongoing Work: Generalizing to Multivariate Inputs & Arbitrary Activation Functions Representation of NN: Approximating a Function via A Continuous Basis Expansion Neuron Neuron Neuron Coefficient Measure Response/Activation Function Neuron { Basis Function Implication: The (well-developed) tools & mathematics of function space and basis expansions can be brought to bear on NN problems. I\u2019ll talk about this more later if there\u2019s time and interest\u2026",
    "source": "ELEC/COMP 576 Lecture - Slide 13",
    "source_detail": "ELEC576_NNasSpine.pdf, Page 13",
    "lecture": "ELEC/COMP 576 Lecture",
    "lecture_number": "576",
    "page": 13,
    "content_type": "text",
    "doc_id": "slide_576_13",
    "doc_type": "slide",
    "is_definition": false,
    "contains_equation": true,
    "importance": "high",
    "tags": [
      "neural networks"
    ]
  },
  {
    "text": "Random Initializations",
    "source": "ELEC/COMP 576 Lecture - Slide 14",
    "source_detail": "ELEC576_NNasSpine.pdf, Page 14",
    "lecture": "ELEC/COMP 576 Lecture",
    "lecture_number": "576",
    "page": 14,
    "content_type": "text",
    "doc_id": "slide_576_14",
    "doc_type": "slide",
    "is_definition": false,
    "contains_equation": false,
    "importance": "low",
    "tags": [
      "Random Initializations",
      "Training Techniques",
      "Machine Learning",
      "Neural Networks",
      "Optimization"
    ]
  },
  {
    "text": "Joint + Conditional Density b/w Breakpoints and Delta-Slopes Non-obvious correlation b/w Breakpoint location and curvature",
    "source": "ELEC/COMP 576 Lecture - Slide 15",
    "source_detail": "ELEC576_NNasSpine.pdf, Page 15",
    "lecture": "ELEC/COMP 576 Lecture",
    "lecture_number": "576",
    "page": 15,
    "content_type": "text",
    "doc_id": "slide_576_15",
    "doc_type": "slide",
    "is_definition": false,
    "contains_equation": false,
    "importance": "high",
    "tags": [
      "Joint Density",
      "Breakpoints",
      "Curvature",
      "Conditional Density",
      "Delta-Slopes"
    ]
  },
  {
    "text": "Marginal Density of Delta-Slopes Empirical Observations Depth yields delta-slopes closer to zero",
    "source": "ELEC/COMP 576 Lecture - Slide 16",
    "source_detail": "ELEC576_NNasSpine.pdf, Page 16",
    "lecture": "ELEC/COMP 576 Lecture",
    "lecture_number": "576",
    "page": 16,
    "content_type": "text",
    "doc_id": "slide_576_16",
    "doc_type": "slide",
    "is_definition": false,
    "contains_equation": false,
    "importance": "high",
    "tags": [
      "Empirical Observations",
      "Delta-Slopes",
      "Marginal Density",
      "Depth"
    ]
  },
  {
    "text": "Marginal Density of Breakpoints Empirical Observations",
    "source": "ELEC/COMP 576 Lecture - Slide 17",
    "source_detail": "ELEC576_NNasSpine.pdf, Page 17",
    "lecture": "ELEC/COMP 576 Lecture",
    "lecture_number": "576",
    "page": 17,
    "content_type": "text",
    "doc_id": "slide_576_17",
    "doc_type": "slide",
    "is_definition": false,
    "contains_equation": false,
    "importance": "medium",
    "tags": [
      "Empirical Observations",
      "Marginal Density",
      "Breakpoints"
    ]
  },
  {
    "text": "Breaking Bad: Mismatch b/w Breakpoints and Function Curvature leads to poor optimization with GD\u2026",
    "source": "ELEC/COMP 576 Lecture - Slide 18",
    "source_detail": "ELEC576_NNasSpine.pdf, Page 18",
    "lecture": "ELEC/COMP 576 Lecture",
    "lecture_number": "576",
    "page": 18,
    "content_type": "text",
    "doc_id": "slide_576_18",
    "doc_type": "slide",
    "is_definition": false,
    "contains_equation": true,
    "importance": "high",
    "tags": [
      "optimization"
    ]
  },
  {
    "text": ".. but this can be Rescued by a Better Data- dependent Initialization of the Breakpoints Data-Dependent Init: Exploit Reparam. to Shape Breakpoint Density",
    "source": "ELEC/COMP 576 Lecture - Slide 19",
    "source_detail": "ELEC576_NNasSpine.pdf, Page 19",
    "lecture": "ELEC/COMP 576 Lecture",
    "lecture_number": "576",
    "page": 19,
    "content_type": "text",
    "doc_id": "slide_576_19",
    "doc_type": "slide",
    "is_definition": false,
    "contains_equation": true,
    "importance": "high",
    "tags": [
      "Data-dependent Initialization",
      "Breakpoint Density",
      "Reparameterization",
      "Breakpoints"
    ]
  },
  {
    "text": "Degeneracies in Loss Surface",
    "source": "ELEC/COMP 576 Lecture - Slide 21",
    "source_detail": "ELEC576_NNasSpine.pdf, Page 21",
    "lecture": "ELEC/COMP 576 Lecture",
    "lecture_number": "576",
    "page": 21,
    "content_type": "text",
    "doc_id": "slide_576_21",
    "doc_type": "slide",
    "is_definition": false,
    "contains_equation": false,
    "importance": "medium",
    "tags": [
      "loss functions"
    ]
  },
  {
    "text": "Overparametrization ==> Lonely Partitions ==> Global Minima Induced Partition of Inputs Typical x Overparametrization Lonely x",
    "source": "ELEC/COMP 576 Lecture - Slide 22",
    "source_detail": "ELEC576_NNasSpine.pdf, Page 22",
    "lecture": "ELEC/COMP 576 Lecture",
    "lecture_number": "576",
    "page": 22,
    "content_type": "equation",
    "doc_id": "slide_576_22",
    "doc_type": "slide",
    "is_definition": false,
    "contains_equation": true,
    "importance": "high",
    "tags": [
      "Overparametrization",
      "Induced Partition",
      "Global Minima",
      "Inputs",
      "Lonely Partitions"
    ]
  },
  {
    "text": "Overparametrization ==> Lonely Partitions ==> Global Minima",
    "source": "ELEC/COMP 576 Lecture - Slide 23",
    "source_detail": "ELEC576_NNasSpine.pdf, Page 23",
    "lecture": "ELEC/COMP 576 Lecture",
    "lecture_number": "576",
    "page": 23,
    "content_type": "equation",
    "doc_id": "slide_576_23",
    "doc_type": "slide",
    "is_definition": false,
    "contains_equation": false,
    "importance": "high",
    "tags": [
      "Overparametrization",
      "Global Minima",
      "Lonely Partitions"
    ]
  },
  {
    "text": "Hessian of the Loss and Degenerate Directions If Two Neurons have the same Activation Pattern, Then there will be a Zero Eigenvalue Simplified Hessian Critical Points fall into a 6 types: is a Gram Matrix\u2014> Pos.Semi-Def.\u2026 Local minima (1), Degenerate (5) Remember these neurons\u2026 \u2026whose generating vectors are\u2026 Properties of Loss Hessian: PSD \u2022 PD iff gen. vectors are Linearly Independent \u2022 Has 0 eigenvalues iff vectors are Linearly \u2022 Dependent (flat in that direction, valley)",
    "source": "ELEC/COMP 576 Lecture - Slide 24",
    "source_detail": "ELEC576_NNasSpine.pdf, Page 24",
    "lecture": "ELEC/COMP 576 Lecture",
    "lecture_number": "576",
    "page": 24,
    "content_type": "text",
    "doc_id": "slide_576_24",
    "doc_type": "slide",
    "is_definition": true,
    "contains_equation": true,
    "importance": "high",
    "tags": [
      "loss functions",
      "neural networks"
    ]
  },
  {
    "text": "Gradient Descent: Suboptimality, Breakpoint + Delta-Slope Dynamics, & the Role of Depth",
    "source": "ELEC/COMP 576 Lecture - Slide 25",
    "source_detail": "ELEC576_NNasSpine.pdf, Page 25",
    "lecture": "ELEC/COMP 576 Lecture",
    "lecture_number": "576",
    "page": 25,
    "content_type": "text",
    "doc_id": "slide_576_25",
    "doc_type": "slide",
    "is_definition": true,
    "contains_equation": true,
    "importance": "high",
    "tags": [
      "backpropagation"
    ]
  },
  {
    "text": "How Suboptimal is Gradient Descent? Comparisons to Globally Optimal PWL Regression Algos",
    "source": "ELEC/COMP 576 Lecture - Slide 26",
    "source_detail": "ELEC576_NNasSpine.pdf, Page 26",
    "lecture": "ELEC/COMP 576 Lecture",
    "lecture_number": "576",
    "page": 26,
    "content_type": "text",
    "doc_id": "slide_576_26",
    "doc_type": "slide",
    "is_definition": false,
    "contains_equation": true,
    "importance": "high",
    "tags": [
      "backpropagation"
    ]
  },
  {
    "text": "Can we improve GD by including global moves? Relocating \u201cBad\u201d Breakpoints During Training Rescues GD",
    "source": "ELEC/COMP 576 Lecture - Slide 27",
    "source_detail": "ELEC576_NNasSpine.pdf, Page 27",
    "lecture": "ELEC/COMP 576 Lecture",
    "lecture_number": "576",
    "page": 27,
    "content_type": "text",
    "doc_id": "slide_576_27",
    "doc_type": "slide",
    "is_definition": false,
    "contains_equation": false,
    "importance": "high",
    "tags": [
      "Gradient Descent",
      "Training Improvement",
      "Global Moves",
      "Breakpoints"
    ]
  },
  {
    "text": "Dynamical Laws for Breakpoints, Curvatures, Fcn",
    "source": "ELEC/COMP 576 Lecture - Slide 28",
    "source_detail": "ELEC576_NNasSpine.pdf, Page 28",
    "lecture": "ELEC/COMP 576 Lecture",
    "lecture_number": "576",
    "page": 28,
    "content_type": "text",
    "doc_id": "slide_576_28",
    "doc_type": "slide",
    "is_definition": false,
    "contains_equation": true,
    "importance": "high",
    "tags": [
      "Dynamical Laws",
      "Curvatures",
      "Functions",
      "Breakpoints"
    ]
  },
  {
    "text": "Dynamical Laws for the Function (Neural Outputs): Relation to the Neural Tangent Kernel (NTK) Relation to Neural Tangent Kernel",
    "source": "ELEC/COMP 576 Lecture - Slide 29",
    "source_detail": "ELEC576_NNasSpine.pdf, Page 29",
    "lecture": "ELEC/COMP 576 Lecture",
    "lecture_number": "576",
    "page": 29,
    "content_type": "text",
    "doc_id": "slide_576_29",
    "doc_type": "slide",
    "is_definition": false,
    "contains_equation": false,
    "importance": "high",
    "tags": [
      "Dynamical Laws",
      "Neural Outputs",
      "Neural Tangent Kernel",
      "NTK"
    ]
  },
  {
    "text": "The Value of Depth: Expressivity or Learnability?",
    "source": "ELEC/COMP 576 Lecture - Slide 30",
    "source_detail": "ELEC576_NNasSpine.pdf, Page 30",
    "lecture": "ELEC/COMP 576 Lecture",
    "lecture_number": "576",
    "page": 30,
    "content_type": "text",
    "doc_id": "slide_576_30",
    "doc_type": "slide",
    "is_definition": false,
    "contains_equation": false,
    "importance": "medium",
    "tags": [
      "Expressivity",
      "Value",
      "Depth",
      "Learnability"
    ]
  },
  {
    "text": "Depth doesn\u2019t add much Expressivity\u2026 Consistent with recent surprising findings from Hanin & Rolnick 2019:",
    "source": "ELEC/COMP 576 Lecture - Slide 31",
    "source_detail": "ELEC576_NNasSpine.pdf, Page 31",
    "lecture": "ELEC/COMP 576 Lecture",
    "lecture_number": "576",
    "page": 31,
    "content_type": "text",
    "doc_id": "slide_576_31",
    "doc_type": "slide",
    "is_definition": false,
    "contains_equation": false,
    "importance": "medium",
    "tags": [
      "Expressivity",
      "Hanin & Rolnick 2019",
      "findings",
      "Depth"
    ]
  },
  {
    "text": "\u2026then what is Depth good for? Defining & Visualizing Breakpoints in Deep Nets The Fine Print: Definition of Active Breakpoints is more subtle for Deep Nets",
    "source": "ELEC/COMP 576 Lecture - Slide 32",
    "source_detail": "ELEC576_NNasSpine.pdf, Page 32",
    "lecture": "ELEC/COMP 576 Lecture",
    "lecture_number": "576",
    "page": 32,
    "content_type": "text",
    "doc_id": "slide_576_32",
    "doc_type": "slide",
    "is_definition": true,
    "contains_equation": false,
    "importance": "medium",
    "tags": [
      "Visualizing Breakpoints",
      "Breakpoints",
      "Depth in Deep Nets",
      "Active Breakpoints",
      "Defining Breakpoints"
    ]
  },
  {
    "text": "What is Depth good for? Depth helps with Breakpoint Mobility",
    "source": "ELEC/COMP 576 Lecture - Slide 33",
    "source_detail": "ELEC576_NNasSpine.pdf, Page 33",
    "lecture": "ELEC/COMP 576 Lecture",
    "lecture_number": "576",
    "page": 33,
    "content_type": "text",
    "doc_id": "slide_576_33",
    "doc_type": "slide",
    "is_definition": false,
    "contains_equation": false,
    "importance": "medium",
    "tags": [
      "Breakpoint",
      "Mobility",
      "Depth"
    ]
  },
  {
    "text": "What is Depth good for? Depth \u2014> Breakpoint Speed, Birth & Death",
    "source": "ELEC/COMP 576 Lecture - Slide 34",
    "source_detail": "ELEC576_NNasSpine.pdf, Page 34",
    "lecture": "ELEC/COMP 576 Lecture",
    "lecture_number": "576",
    "page": 34,
    "content_type": "text",
    "doc_id": "slide_576_34",
    "doc_type": "slide",
    "is_definition": true,
    "contains_equation": false,
    "importance": "high",
    "tags": [
      "Breakpoint Speed",
      "Death",
      "Birth",
      "Depth"
    ]
  },
  {
    "text": "What is Depth good for? Breakpoints in Deeper Nets are more Attracted to Curvature For Shallow ReLu Net (1 layer): Corr(Final BPs, Target Fcn Curvature) = 0.32 Deep nets have higher correlation b/w Breakpoint and Curvature locations than Shallow nets Deep ReLu Net (4 layers): Corr(Final BPs, Target Fcn Curvature) = 0.49",
    "source": "ELEC/COMP 576 Lecture - Slide 35",
    "source_detail": "ELEC576_NNasSpine.pdf, Page 35",
    "lecture": "ELEC/COMP 576 Lecture",
    "lecture_number": "576",
    "page": 35,
    "content_type": "equation",
    "doc_id": "slide_576_35",
    "doc_type": "slide",
    "is_definition": false,
    "contains_equation": true,
    "importance": "high",
    "tags": [
      "Breakpoints",
      "Depth in Neural Networks",
      "Curvature",
      "Deep ReLu Net",
      "Correlation"
    ]
  },
  {
    "text": "Generalization: Explaining Implicit Regularization",
    "source": "ELEC/COMP 576 Lecture - Slide 36",
    "source_detail": "ELEC576_NNasSpine.pdf, Page 36",
    "lecture": "ELEC/COMP 576 Lecture",
    "lecture_number": "576",
    "page": 36,
    "content_type": "text",
    "doc_id": "slide_576_36",
    "doc_type": "slide",
    "is_definition": true,
    "contains_equation": false,
    "importance": "high",
    "tags": [
      "regularization"
    ]
  },
  {
    "text": "Implicit Reg.: Impact of Width for Two Lines Width = 20 units Width = 40 units Width = 200 units",
    "source": "ELEC/COMP 576 Lecture - Slide 37",
    "source_detail": "ELEC576_NNasSpine.pdf, Page 37",
    "lecture": "ELEC/COMP 576 Lecture",
    "lecture_number": "576",
    "page": 37,
    "content_type": "text",
    "doc_id": "slide_576_37",
    "doc_type": "slide",
    "is_definition": false,
    "contains_equation": false,
    "importance": "medium",
    "tags": [
      "Implicit Regularization",
      "Two Lines",
      "Width Measurements",
      "Impact of Width"
    ]
  },
  {
    "text": "Implicit Reg.: Impact of Width for Smooth Target",
    "source": "ELEC/COMP 576 Lecture - Slide 38",
    "source_detail": "ELEC576_NNasSpine.pdf, Page 38",
    "lecture": "ELEC/COMP 576 Lecture",
    "lecture_number": "576",
    "page": 38,
    "content_type": "text",
    "doc_id": "slide_576_38",
    "doc_type": "slide",
    "is_definition": false,
    "contains_equation": true,
    "importance": "high",
    "tags": [
      "Implicit Regularization",
      "Smooth Target",
      "Impact of Width"
    ]
  },
  {
    "text": "Implicit Reg.: Impact of Width for Sharp Target",
    "source": "ELEC/COMP 576 Lecture - Slide 39",
    "source_detail": "ELEC576_NNasSpine.pdf, Page 39",
    "lecture": "ELEC/COMP 576 Lecture",
    "lecture_number": "576",
    "page": 39,
    "content_type": "text",
    "doc_id": "slide_576_39",
    "doc_type": "slide",
    "is_definition": false,
    "contains_equation": true,
    "importance": "high",
    "tags": [
      "Sharp Target",
      "Impact of Width",
      "Implicit Regulation"
    ]
  },
  {
    "text": "Implicit Reg.: Impact of Init Smoothness wollahS peeD Initial Final 1. Spiky Inits are remembered thru training and significantly increase generalization error 2. Going Deeper can improve error but doesn\u2019t always help",
    "source": "ELEC/COMP 576 Lecture - Slide 40",
    "source_detail": "ELEC576_NNasSpine.pdf, Page 40",
    "lecture": "ELEC/COMP 576 Lecture",
    "lecture_number": "576",
    "page": 40,
    "content_type": "text",
    "doc_id": "slide_576_40",
    "doc_type": "slide",
    "is_definition": false,
    "contains_equation": false,
    "importance": "high",
    "tags": [
      "Implicit Regularization",
      "Initialization Smoothness",
      "Generalization Error",
      "Neural Network Depth"
    ]
  },
  {
    "text": "Quantifying Implicit Regularization: Final Smoothness vs. Init Smoothness & Width Smoothness Measured via (proportional to Init. Roughness) Roughness:",
    "source": "ELEC/COMP 576 Lecture - Slide 41",
    "source_detail": "ELEC576_NNasSpine.pdf, Page 41",
    "lecture": "ELEC/COMP 576 Lecture",
    "lecture_number": "576",
    "page": 41,
    "content_type": "text",
    "doc_id": "slide_576_41",
    "doc_type": "slide",
    "is_definition": false,
    "contains_equation": true,
    "importance": "high",
    "tags": [
      "regularization"
    ]
  },
  {
    "text": "Dynamical Laws for Breakpoints, Curvatures, Fcn",
    "source": "ELEC/COMP 576 Lecture - Slide 42",
    "source_detail": "ELEC576_NNasSpine.pdf, Page 42",
    "lecture": "ELEC/COMP 576 Lecture",
    "lecture_number": "576",
    "page": 42,
    "content_type": "text",
    "doc_id": "slide_576_42",
    "doc_type": "slide",
    "is_definition": false,
    "contains_equation": true,
    "importance": "high",
    "tags": [
      "Dynamical Laws",
      "Curvatures",
      "Functions",
      "Breakpoints"
    ]
  },
  {
    "text": "Dynamical Laws for the Function (Neural Outputs)",
    "source": "ELEC/COMP 576 Lecture - Slide 43",
    "source_detail": "ELEC576_NNasSpine.pdf, Page 43",
    "lecture": "ELEC/COMP 576 Lecture",
    "lecture_number": "576",
    "page": 43,
    "content_type": "text",
    "doc_id": "slide_576_43",
    "doc_type": "slide",
    "is_definition": false,
    "contains_equation": true,
    "importance": "high",
    "tags": [
      "Dynamical Laws",
      "Neural Outputs",
      "Function"
    ]
  },
  {
    "text": "A Theoretical Explanation for Implicit Reg.: 1. Standard Random Inits are very Flat Smoothness Measured via Roughness: Width = 200 units Smoothness is Highly Concentrated near zero \u2014> Delta-Slopes near zero w.h.p.",
    "source": "ELEC/COMP 576 Lecture - Slide 44",
    "source_detail": "ELEC576_NNasSpine.pdf, Page 44",
    "lecture": "ELEC/COMP 576 Lecture",
    "lecture_number": "576",
    "page": 44,
    "content_type": "text",
    "doc_id": "slide_576_44",
    "doc_type": "slide",
    "is_definition": false,
    "contains_equation": true,
    "importance": "high",
    "tags": [
      "Implicit Regularization",
      "Standard Random Initializations",
      "Roughness",
      "Smoothness Measurement",
      "Delta-Slopes"
    ]
  },
  {
    "text": "A Theoretical Explanation for Implicit Reg. in Kernel Regime: 2. Flat Init + GD + ReLu Parametrization \u2014> Cubic Spline Main Theoretical Results",
    "source": "ELEC/COMP 576 Lecture - Slide 45",
    "source_detail": "ELEC576_NNasSpine.pdf, Page 45",
    "lecture": "ELEC/COMP 576 Lecture",
    "lecture_number": "576",
    "page": 45,
    "content_type": "text",
    "doc_id": "slide_576_45",
    "doc_type": "slide",
    "is_definition": false,
    "contains_equation": true,
    "importance": "high",
    "tags": [
      "Implicit Regularization",
      "Cubic Spline",
      "Gradient Descent",
      "Flat Initialization",
      "Kernel Regime"
    ]
  },
  {
    "text": "A Theoretical Explanation for Implicit Reg. in Kernel Regime: 2. Flat Init + GD + ReLu Parametrization \u2014> Cubic Spline Intuitive Proof Sketch GD Dynamics of Individual (Discrete) Curvatures: Width = 200 units Vectorize: Neurons in data gap all see very similar gradients Take Continuum Limit Solve: (Overparametrization) + Init Curvature is Flat (essential for smoothness) Integrate twice in x (Curvature-based Param) Surprise: 2nd+3rd order terms 0th order PBCs (loss): \u2014> a piecewise cubic spline 1st order PBCs (param): (Continuity constraint for slope of approximation)",
    "source": "ELEC/COMP 576 Lecture - Slide 46",
    "source_detail": "ELEC576_NNasSpine.pdf, Page 46",
    "lecture": "ELEC/COMP 576 Lecture",
    "lecture_number": "576",
    "page": 46,
    "content_type": "text",
    "doc_id": "slide_576_46",
    "doc_type": "slide",
    "is_definition": false,
    "contains_equation": true,
    "importance": "high",
    "tags": [
      "loss functions"
    ]
  },
  {
    "text": "A Theoretical Explanation for Implicit Reg. in Kernel Regime: 3. Test theory with simulations Width = 40 units Width = 100 units",
    "source": "ELEC/COMP 576 Lecture - Slide 47",
    "source_detail": "ELEC576_NNasSpine.pdf, Page 47",
    "lecture": "ELEC/COMP 576 Lecture",
    "lecture_number": "576",
    "page": 47,
    "content_type": "text",
    "doc_id": "slide_576_47",
    "doc_type": "slide",
    "is_definition": false,
    "contains_equation": true,
    "importance": "high",
    "tags": [
      "Implicit Regularization",
      "Test Theory",
      "Simulations",
      "Width",
      "Kernel Regime"
    ]
  },
  {
    "text": "A Theoretical Explanation for Implicit Reg. in Kernel Regime: 3. Compare Predicted Spline to Trained NN",
    "source": "ELEC/COMP 576 Lecture - Slide 48",
    "source_detail": "ELEC576_NNasSpine.pdf, Page 48",
    "lecture": "ELEC/COMP 576 Lecture",
    "lecture_number": "576",
    "page": 48,
    "content_type": "text",
    "doc_id": "slide_576_48",
    "doc_type": "slide",
    "is_definition": false,
    "contains_equation": true,
    "importance": "high",
    "tags": [
      "neural networks"
    ]
  },
  {
    "text": "A Theoretical Explanation for Implicit Reg. in Rich Regime: What Happens in the Rich Regime? Rich Regime (alpha=1) Rich Regime (alpha=0.1)",
    "source": "ELEC/COMP 576 Lecture - Slide 49",
    "source_detail": "ELEC576_NNasSpine.pdf, Page 49",
    "lecture": "ELEC/COMP 576 Lecture",
    "lecture_number": "576",
    "page": 49,
    "content_type": "text",
    "doc_id": "slide_576_49",
    "doc_type": "slide",
    "is_definition": false,
    "contains_equation": true,
    "importance": "high",
    "tags": [
      "Theoretical Explanation",
      "Alpha Values",
      "Rich Regime",
      "Implicit Regulation"
    ]
  },
  {
    "text": "A Theoretical Explanation for Implicit Reg. in Rich Regime: What happens in the Rich Regime? Why? Init Weight Scale controls Less Smoothness, More Concentration of Relative Learning Rate of Curvature amongst Breakpoints Breakpoints vs. Delta-Slopes",
    "source": "ELEC/COMP 576 Lecture - Slide 50",
    "source_detail": "ELEC576_NNasSpine.pdf, Page 50",
    "lecture": "ELEC/COMP 576 Lecture",
    "lecture_number": "576",
    "page": 50,
    "content_type": "text",
    "doc_id": "slide_576_50",
    "doc_type": "slide",
    "is_definition": false,
    "contains_equation": false,
    "importance": "high",
    "tags": [
      "optimization"
    ]
  },
  {
    "text": "A Theoretical Explanation for Implicit Reg. in Rich Regime: What happens in the Rich Regime? Theoretical Explanation: Piecewise Quadratic Loss Surface exhibits three types Of Critical Points, corresponding to the three types of Breakpoint attractors",
    "source": "ELEC/COMP 576 Lecture - Slide 51",
    "source_detail": "ELEC576_NNasSpine.pdf, Page 51",
    "lecture": "ELEC/COMP 576 Lecture",
    "lecture_number": "576",
    "page": 51,
    "content_type": "text",
    "doc_id": "slide_576_51",
    "doc_type": "slide",
    "is_definition": true,
    "contains_equation": false,
    "importance": "high",
    "tags": [
      "loss functions"
    ]
  },
  {
    "text": "A Theoretical Explanation for Implicit Reg. in Rich Regime: What Happens in Rich Regime? Rich Regime (alpha=1) Rich Regime (alpha=0.1)",
    "source": "ELEC/COMP 576 Lecture - Slide 52",
    "source_detail": "ELEC576_NNasSpine.pdf, Page 52",
    "lecture": "ELEC/COMP 576 Lecture",
    "lecture_number": "576",
    "page": 52,
    "content_type": "text",
    "doc_id": "slide_576_52",
    "doc_type": "slide",
    "is_definition": false,
    "contains_equation": true,
    "importance": "high",
    "tags": [
      "Theoretical Explanation",
      "Alpha Values",
      "Rich Regime",
      "Implicit Regulation"
    ]
  },
  {
    "text": "Implications for Theoretical and Computational Neuroscience & Future Directions",
    "source": "ELEC/COMP 576 Lecture - Slide 53",
    "source_detail": "ELEC576_NNasSpine.pdf, Page 53",
    "lecture": "ELEC/COMP 576 Lecture",
    "lecture_number": "576",
    "page": 53,
    "content_type": "text",
    "doc_id": "slide_576_53",
    "doc_type": "slide",
    "is_definition": false,
    "contains_equation": false,
    "importance": "high",
    "tags": [
      "Theoretical Neuroscience",
      "Implications",
      "Future Directions",
      "Computational Neuroscience"
    ]
  },
  {
    "text": "The Spline PoV strongly encourages us to re- examine Neuronal Networks \u2022 Inference: The role of individual neurons in representing/approximating a function: \u2022 Each neuron is a basis function; Each neuronal cell type is a type of basis function \u2022 ==> A population of neurons forms an over complete basis: distributed code with mixed selectivity is \u201cnormal\u201d and efficient; IR determines how distributed/concentrated the code is \u2022 Saturating Neuronal response functions and neuronal cell types will have a dramatic impact on the representation and IR due to basis functions being saturated (vs.",
    "source": "ELEC/COMP 576 Lecture - Slide 54",
    "source_detail": "ELEC576_NNasSpine.pdf, Page 54",
    "lecture": "ELEC/COMP 576 Lecture",
    "lecture_number": "576",
    "page": 54,
    "content_type": "text",
    "doc_id": "slide_576_54_chunk1",
    "doc_type": "slide",
    "parent_doc_id": "slide_576_54",
    "chunk_index": 1,
    "total_chunks": 3,
    "is_definition": true,
    "contains_equation": true,
    "importance": "high",
    "tags": [
      "regularization",
      "neural networks"
    ]
  },
  {
    "text": "non-saturating e.g.",
    "source": "ELEC/COMP 576 Lecture - Slide 54",
    "source_detail": "ELEC576_NNasSpine.pdf, Page 54",
    "lecture": "ELEC/COMP 576 Lecture",
    "lecture_number": "576",
    "page": 54,
    "content_type": "text",
    "doc_id": "slide_576_54_chunk2",
    "doc_type": "slide",
    "parent_doc_id": "slide_576_54",
    "chunk_index": 2,
    "total_chunks": 3,
    "is_definition": false,
    "contains_equation": false,
    "importance": "low",
    "tags": [
      "regularization",
      "neural networks"
    ]
  },
  {
    "text": "ReLu) \u2022 Learning: Implicit Regularization should occur for any gradual learning algorithm (described by a corresponding PDE for the neuron population spline dynamics) \u2022 NN initialization is critical; strong pressure for Evolution to select for specific implicit biases (stored in genome & established during development/lifetime via cell types, plasticity rules, etc.) \u2022 Neuronal cell types could be a very efficient way to genetically store this implicit bias; precludes the need to train from scratch in each lifetime; E/I balance should have a dramatic impact on representation/IR \u2022 Neuron-Neuron response correlations are a Feature not a Bug: they do not need to be \u201cdecorrelated\u201d, instead they could signal IR.",
    "source": "ELEC/COMP 576 Lecture - Slide 54",
    "source_detail": "ELEC576_NNasSpine.pdf, Page 54",
    "lecture": "ELEC/COMP 576 Lecture",
    "lecture_number": "576",
    "page": 54,
    "content_type": "text",
    "doc_id": "slide_576_54_chunk3",
    "doc_type": "slide",
    "parent_doc_id": "slide_576_54",
    "chunk_index": 3,
    "total_chunks": 3,
    "is_definition": false,
    "contains_equation": true,
    "importance": "high",
    "tags": [
      "regularization",
      "neural networks"
    ]
  },
  {
    "text": "Summary & Future Work Function space is very useful for: \u2022 Understanding Overparametrization, Loss Surface, Implicit \u2022 Regularization Visualization and Probing \u2022 Developing New Inits & Learning Algorithms \u2022 Future Work: \u2022 (We\u2019re hiring!) Develop theory for Deeper FFNNs, RNNs, GANs, etc. \u2022 Scale theory to high dimensions \u2022 Web: ankitlab.co/ Twitter: @abp4_ankit Fast (approximate) Viz tools \u2022 Apply theory and tools to understanding Inductive Bias of neurally \u2022 consistent models (Conductance-weighted averaging, Dale\u2019s Law) Thanks!",
    "source": "ELEC/COMP 576 Lecture - Slide 55",
    "source_detail": "ELEC576_NNasSpine.pdf, Page 55",
    "lecture": "ELEC/COMP 576 Lecture",
    "lecture_number": "576",
    "page": 55,
    "content_type": "text",
    "doc_id": "slide_576_55",
    "doc_type": "slide",
    "is_definition": false,
    "contains_equation": false,
    "importance": "high",
    "tags": [
      "generative models",
      "loss functions",
      "regularization",
      "rnn",
      "neural networks"
    ]
  },
  {
    "text": "Future Work: Developing Probing & Visualization Tools Extending to Deep & Multivariate NNs Arbitrary Activation Functions Neuronal Consistent Nets with Cell Types and Saturating Responses",
    "source": "ELEC/COMP 576 Lecture - Slide 56",
    "source_detail": "ELEC576_NNasSpine.pdf, Page 56",
    "lecture": "ELEC/COMP 576 Lecture",
    "lecture_number": "576",
    "page": 56,
    "content_type": "text",
    "doc_id": "slide_576_56",
    "doc_type": "slide",
    "is_definition": false,
    "contains_equation": false,
    "importance": "high",
    "tags": [
      "neural networks"
    ]
  },
  {
    "text": "Ongoing Work: Generalizing ReLU NN to Multivariate Inputs Multivariate Spline 2-Dimensional Inputs with Parametrization of a Data Gap ReLU NN",
    "source": "ELEC/COMP 576 Lecture - Slide 57",
    "source_detail": "ELEC576_NNasSpine.pdf, Page 57",
    "lecture": "ELEC/COMP 576 Lecture",
    "lecture_number": "576",
    "page": 57,
    "content_type": "text",
    "doc_id": "slide_576_57",
    "doc_type": "slide",
    "is_definition": false,
    "contains_equation": true,
    "importance": "high",
    "tags": [
      "neural networks"
    ]
  },
  {
    "text": "Ongoing Work: Generalizing to Multivariate Inputs w/ Arbitrary Activation Functions Representation of NN: Approximating a Function via A Continuous Basis Expansion Neuron Neuron Neuron Coefficient Measure Response/Activation Function Neuron { Basis Function Implication: The (well-developed) tools & mathematics of function space and basis expansions can be brought to bear on NN problems.",
    "source": "ELEC/COMP 576 Lecture - Slide 58",
    "source_detail": "ELEC576_NNasSpine.pdf, Page 58",
    "lecture": "ELEC/COMP 576 Lecture",
    "lecture_number": "576",
    "page": 58,
    "content_type": "text",
    "doc_id": "slide_576_58",
    "doc_type": "slide",
    "is_definition": true,
    "contains_equation": true,
    "importance": "high",
    "tags": [
      "neural networks"
    ]
  },
  {
    "text": "Ongoing Work: Generalizing to Multivariate Inputs Representation of NN: Approximating a Function via A Continuous Basis Expansion Neuron Neuron Neuron Coefficient Measure Response Function Neuron { Basis Function A NN representation aan be written as a (dual) Radon Transform (related to Fourier Transform)",
    "source": "ELEC/COMP 576 Lecture - Slide 59",
    "source_detail": "ELEC576_NNasSpine.pdf, Page 59",
    "lecture": "ELEC/COMP 576 Lecture",
    "lecture_number": "576",
    "page": 59,
    "content_type": "text",
    "doc_id": "slide_576_59",
    "doc_type": "slide",
    "is_definition": true,
    "contains_equation": true,
    "importance": "high",
    "tags": [
      "neural networks"
    ]
  },
  {
    "text": "Ongoing Work: Generalizing to Multivariate Inputs Representation of NN: The role of each neuron is to represent coefficient x basis function",
    "source": "ELEC/COMP 576 Lecture - Slide 60",
    "source_detail": "ELEC576_NNasSpine.pdf, Page 60",
    "lecture": "ELEC/COMP 576 Lecture",
    "lecture_number": "576",
    "page": 60,
    "content_type": "text",
    "doc_id": "slide_576_60",
    "doc_type": "slide",
    "is_definition": false,
    "contains_equation": true,
    "importance": "high",
    "tags": [
      "neural networks"
    ]
  },
  {
    "text": "Ongoing Work: Generalizing to Multivariate Inputs Neuron Response Functions Control the Basis: ReLu",
    "source": "ELEC/COMP 576 Lecture - Slide 61",
    "source_detail": "ELEC576_NNasSpine.pdf, Page 61",
    "lecture": "ELEC/COMP 576 Lecture",
    "lecture_number": "576",
    "page": 61,
    "content_type": "text",
    "doc_id": "slide_576_61",
    "doc_type": "slide",
    "is_definition": false,
    "contains_equation": false,
    "importance": "high",
    "tags": [
      "ReLu",
      "Multivariate Inputs",
      "Neuron Response Functions",
      "Control the Basis",
      "Generalization"
    ]
  },
  {
    "text": "Ongoing Work: Generalizing to Multivariate Inputs Neuron Response Functions Control the Basis: Step",
    "source": "ELEC/COMP 576 Lecture - Slide 62",
    "source_detail": "ELEC576_NNasSpine.pdf, Page 62",
    "lecture": "ELEC/COMP 576 Lecture",
    "lecture_number": "576",
    "page": 62,
    "content_type": "text",
    "doc_id": "slide_576_62",
    "doc_type": "slide",
    "is_definition": false,
    "contains_equation": true,
    "importance": "high",
    "tags": [
      "Neuron Response Functions",
      "Control the Basis",
      "Multivariate Inputs"
    ]
  },
  {
    "text": "Ongoing Work: Generalizing to Multivariate Inputs Neuron Response Functions Control the Basis: Saturating ReLu",
    "source": "ELEC/COMP 576 Lecture - Slide 63",
    "source_detail": "ELEC576_NNasSpine.pdf, Page 63",
    "lecture": "ELEC/COMP 576 Lecture",
    "lecture_number": "576",
    "page": 63,
    "content_type": "text",
    "doc_id": "slide_576_63",
    "doc_type": "slide",
    "is_definition": false,
    "contains_equation": true,
    "importance": "high",
    "tags": [
      "Neuron Response Functions",
      "Saturating ReLu",
      "Multivariate Inputs"
    ]
  },
  {
    "text": "Ongoing Work: Generalizing to Multivariate Inputs Neuron Response Functions Control the Basis: PowerReLU",
    "source": "ELEC/COMP 576 Lecture - Slide 64",
    "source_detail": "ELEC576_NNasSpine.pdf, Page 64",
    "lecture": "ELEC/COMP 576 Lecture",
    "lecture_number": "576",
    "page": 64,
    "content_type": "text",
    "doc_id": "slide_576_64",
    "doc_type": "slide",
    "is_definition": false,
    "contains_equation": true,
    "importance": "high",
    "tags": [
      "Neuron Response Functions",
      "Multivariate Inputs",
      "PowerReLU"
    ]
  },
  {
    "text": "Future Work: Developing Probing & Visualization Tools To better understand and improve DL",
    "source": "ELEC/COMP 576 Lecture - Slide 65",
    "source_detail": "ELEC576_NNasSpine.pdf, Page 65",
    "lecture": "ELEC/COMP 576 Lecture",
    "lecture_number": "576",
    "page": 65,
    "content_type": "text",
    "doc_id": "slide_576_65",
    "doc_type": "slide",
    "is_definition": false,
    "contains_equation": false,
    "importance": "high",
    "tags": [
      "Understanding and Improvement",
      "Probing Tools",
      "Future Work",
      "Deep Learning",
      "Visualization Tools"
    ]
  },
  {
    "text": "Breakpoint Dynamics during Training: Random vs. Adversarial (Targeted) Directions Random Direction BPs Adversarial Direction BPs",
    "source": "ELEC/COMP 576 Lecture - Slide 66",
    "source_detail": "ELEC576_NNasSpine.pdf, Page 66",
    "lecture": "ELEC/COMP 576 Lecture",
    "lecture_number": "576",
    "page": 66,
    "content_type": "text",
    "doc_id": "slide_576_66",
    "doc_type": "slide",
    "is_definition": false,
    "contains_equation": false,
    "importance": "high",
    "tags": [
      "Random Directions",
      "Breakpoint Dynamics",
      "Training",
      "Targeted Directions",
      "Adversarial Directions"
    ]
  },
  {
    "text": "Learning Dynamics in GANs: Deeper Discriminators mitigate Mode Collapse Shallow Discriminator (1,8,1) Data Distrib. Training Loss for Gen. & Gen. & Discr. Discr. Mapping Breakpoints, Discr. Prob[Real] Basis Fcns for Shallow Generator Gen. Distribution Deep Discriminator (1,16,16,1)",
    "source": "ELEC/COMP 576 Lecture - Slide 67",
    "source_detail": "ELEC576_NNasSpine.pdf, Page 67",
    "lecture": "ELEC/COMP 576 Lecture",
    "lecture_number": "576",
    "page": 67,
    "content_type": "text",
    "doc_id": "slide_576_67",
    "doc_type": "slide",
    "is_definition": false,
    "contains_equation": true,
    "importance": "high",
    "tags": [
      "generative models",
      "loss functions"
    ]
  },
  {
    "text": "Learning Dynamics in GANs: Implicit Regularization makes it difficult for SimGD algorithm to approximate Discontinuities \u2014> Mode Collapse",
    "source": "ELEC/COMP 576 Lecture - Slide 68",
    "source_detail": "ELEC576_NNasSpine.pdf, Page 68",
    "lecture": "ELEC/COMP 576 Lecture",
    "lecture_number": "576",
    "page": 68,
    "content_type": "text",
    "doc_id": "slide_576_68",
    "doc_type": "slide",
    "is_definition": false,
    "contains_equation": false,
    "importance": "high",
    "tags": [
      "regularization",
      "generative models"
    ]
  },
  {
    "text": "Learning Dynamics in GANs: Switching to a minimax-guaranteed algorithm (Follow-the-Ridge) helps improve mode coverage but still not good enough\u2026",
    "source": "ELEC/COMP 576 Lecture - Slide 69",
    "source_detail": "ELEC576_NNasSpine.pdf, Page 69",
    "lecture": "ELEC/COMP 576 Lecture",
    "lecture_number": "576",
    "page": 69,
    "content_type": "text",
    "doc_id": "slide_576_69",
    "doc_type": "slide",
    "is_definition": false,
    "contains_equation": true,
    "importance": "high",
    "tags": [
      "generative models"
    ]
  },
  {
    "text": "Learning Dynamics in GANs: Adding a Preconditioner not only helps SimGD optimization/training speed But more importantly it induced implicit regularization to be more adaptive\u2026",
    "source": "ELEC/COMP 576 Lecture - Slide 70",
    "source_detail": "ELEC576_NNasSpine.pdf, Page 70",
    "lecture": "ELEC/COMP 576 Lecture",
    "lecture_number": "576",
    "page": 70,
    "content_type": "text",
    "doc_id": "slide_576_70",
    "doc_type": "slide",
    "is_definition": false,
    "contains_equation": false,
    "importance": "high",
    "tags": [
      "regularization",
      "generative models",
      "optimization"
    ]
  },
  {
    "text": "Learning Dynamics in GANs: Combining MiniMax + Preconditioning together \u2014> Adaptive Regularization \u2014> Discontinuities approximated more sharply and quickly \u2014> greatly improved mode coverage very early on.",
    "source": "ELEC/COMP 576 Lecture - Slide 71",
    "source_detail": "ELEC576_NNasSpine.pdf, Page 71",
    "lecture": "ELEC/COMP 576 Lecture",
    "lecture_number": "576",
    "page": 71,
    "content_type": "text",
    "doc_id": "slide_576_71",
    "doc_type": "slide",
    "is_definition": false,
    "contains_equation": false,
    "importance": "high",
    "tags": [
      "regularization",
      "generative models"
    ]
  },
  {
    "text": "Thanks! DL is a powerful tool for approximating functions which are too complex to \u2022 specify directly but can instead by specified by many input-output examples\u2026 \u2026 BUT it is not a magical blackbox \u2014 sometimes it fails badly. We must \u2022 develop a theory that specifies the underlying modeling assumptions. We are also studying the brain to see how to alleviate many current limitations. We can and must combine principled domain knowledge with the \u2022 flexibility of DL, in order to achieve generalization/extrapolation, low sample complexity, few and interpretable parameters. \u2022",
    "source": "ELEC/COMP 576 Lecture - Slide 72",
    "source_detail": "ELEC576_NNasSpine.pdf, Page 72",
    "lecture": "ELEC/COMP 576 Lecture",
    "lecture_number": "576",
    "page": 72,
    "content_type": "text",
    "doc_id": "slide_576_72",
    "doc_type": "slide",
    "is_definition": false,
    "contains_equation": false,
    "importance": "high",
    "tags": [
      "modeling assumptions",
      "domain knowledge",
      "function approximation",
      "brain study",
      "deep learning"
    ]
  },
  {
    "text": "Thanks! Future Directions: \u2022 Univariate Deep \u2022 Multivariate BDSO Expansions (ongoing) \u2022 Other Activation Functions (sigmoid, step, saturating ReLu) \u2022 Neuronal Networks and Cell Types \u2022",
    "source": "ELEC/COMP 576 Lecture - Slide 73",
    "source_detail": "ELEC576_NNasSpine.pdf, Page 73",
    "lecture": "ELEC/COMP 576 Lecture",
    "lecture_number": "576",
    "page": 73,
    "content_type": "text",
    "doc_id": "slide_576_73",
    "doc_type": "slide",
    "is_definition": false,
    "contains_equation": false,
    "importance": "medium",
    "tags": [
      "neural networks"
    ]
  },
  {
    "text": "Calculating Gradients & Hessian of Loss Surface",
    "source": "ELEC/COMP 576 Lecture - Slide 75",
    "source_detail": "ELEC576_NNasSpine.pdf, Page 75",
    "lecture": "ELEC/COMP 576 Lecture",
    "lecture_number": "576",
    "page": 75,
    "content_type": "text",
    "doc_id": "slide_576_75",
    "doc_type": "slide",
    "is_definition": false,
    "contains_equation": true,
    "importance": "high",
    "tags": [
      "loss functions"
    ]
  },
  {
    "text": "Gradients & Critical Points of the Loss (for Shallow Univariate ReLu NNs) Gradients of Function/Residuals: Gradients of Loss:",
    "source": "ELEC/COMP 576 Lecture - Slide 76",
    "source_detail": "ELEC576_NNasSpine.pdf, Page 76",
    "lecture": "ELEC/COMP 576 Lecture",
    "lecture_number": "576",
    "page": 76,
    "content_type": "text",
    "doc_id": "slide_576_76",
    "doc_type": "slide",
    "is_definition": false,
    "contains_equation": true,
    "importance": "high",
    "tags": [
      "loss functions",
      "neural networks"
    ]
  },
  {
    "text": "Calculating the Hessian of the Loss (for Shallow Univariate ReLu NNs) Full Hessian (with Dirac Delta Function terms):",
    "source": "ELEC/COMP 576 Lecture - Slide 77",
    "source_detail": "ELEC576_NNasSpine.pdf, Page 77",
    "lecture": "ELEC/COMP 576 Lecture",
    "lecture_number": "576",
    "page": 77,
    "content_type": "text",
    "doc_id": "slide_576_77",
    "doc_type": "slide",
    "is_definition": false,
    "contains_equation": true,
    "importance": "high",
    "tags": [
      "loss functions",
      "neural networks"
    ]
  },
  {
    "text": "Simplifying the Hessian of the Loss (for Shallow Univariate ReLu NNs) Assuming Datapoints and Breakpoints don\u2019t Coincide\u2026 (this excludes Dirac Delta : Function terms) Hessian is a Gram Matrix \u2014> PSD iff generating vectors are Linearly Independent Assuming we are at Critical Point\u2026",
    "source": "ELEC/COMP 576 Lecture - Slide 78",
    "source_detail": "ELEC576_NNasSpine.pdf, Page 78",
    "lecture": "ELEC/COMP 576 Lecture",
    "lecture_number": "576",
    "page": 78,
    "content_type": "text",
    "doc_id": "slide_576_78",
    "doc_type": "slide",
    "is_definition": true,
    "contains_equation": true,
    "importance": "high",
    "tags": [
      "loss functions",
      "neural networks"
    ]
  },
  {
    "text": "Hessian of the Loss and Degenerate Directions (for Shallow Univariate ReLu NNs) Simplified Hessian Critical Points fall into a 6 types: is a Gram Matrix\u2014> Pos.Semi-Def.\u2026 Local minima (1), Degenerate (5) \u2026whose generating vectors are\u2026 Hessian is PSD and will be PD iff these vectors are Linearly Independent \u2014> Hessian will have 0 eigenvalues iff vectors are Linearly Dependent",
    "source": "ELEC/COMP 576 Lecture - Slide 79",
    "source_detail": "ELEC576_NNasSpine.pdf, Page 79",
    "lecture": "ELEC/COMP 576 Lecture",
    "lecture_number": "576",
    "page": 79,
    "content_type": "text",
    "doc_id": "slide_576_79",
    "doc_type": "slide",
    "is_definition": true,
    "contains_equation": true,
    "importance": "high",
    "tags": [
      "loss functions",
      "neural networks"
    ]
  },
  {
    "text": "Implicit Reg. for Neuronal Networks with Saturating Response Functions",
    "source": "ELEC/COMP 576 Lecture - Slide 80",
    "source_detail": "ELEC576_NNasSpine.pdf, Page 80",
    "lecture": "ELEC/COMP 576 Lecture",
    "lecture_number": "576",
    "page": 80,
    "content_type": "text",
    "doc_id": "slide_576_80",
    "doc_type": "slide",
    "is_definition": false,
    "contains_equation": true,
    "importance": "high",
    "tags": [
      "Implicit Regularization",
      "Saturating Response Functions",
      "Neuronal Networks"
    ]
  },
  {
    "text": "Generalizing to Other Activation Functions",
    "source": "ELEC/COMP 576 Lecture - Slide 81",
    "source_detail": "ELEC576_NNasSpine.pdf, Page 81",
    "lecture": "ELEC/COMP 576 Lecture",
    "lecture_number": "576",
    "page": 81,
    "content_type": "text",
    "doc_id": "slide_576_81",
    "doc_type": "slide",
    "is_definition": false,
    "contains_equation": false,
    "importance": "medium",
    "tags": [
      "neural networks"
    ]
  },
  {
    "text": "For General Non-Decreasing Activation Functions Step",
    "source": "ELEC/COMP 576 Lecture - Slide 82",
    "source_detail": "ELEC576_NNasSpine.pdf, Page 82",
    "lecture": "ELEC/COMP 576 Lecture",
    "lecture_number": "576",
    "page": 82,
    "content_type": "text",
    "doc_id": "slide_576_82",
    "doc_type": "slide",
    "is_definition": false,
    "contains_equation": false,
    "importance": "medium",
    "tags": [
      "neural networks"
    ]
  },
  {
    "text": "For General Non-Decreasing Activation Functions",
    "source": "ELEC/COMP 576 Lecture - Slide 83",
    "source_detail": "ELEC576_NNasSpine.pdf, Page 83",
    "lecture": "ELEC/COMP 576 Lecture",
    "lecture_number": "576",
    "page": 83,
    "content_type": "text",
    "doc_id": "slide_576_83",
    "doc_type": "slide",
    "is_definition": false,
    "contains_equation": false,
    "importance": "medium",
    "tags": [
      "neural networks"
    ]
  },
  {
    "text": "For General Non-Decreasing Activation Functions",
    "source": "ELEC/COMP 576 Lecture - Slide 84",
    "source_detail": "ELEC576_NNasSpine.pdf, Page 84",
    "lecture": "ELEC/COMP 576 Lecture",
    "lecture_number": "576",
    "page": 84,
    "content_type": "text",
    "doc_id": "slide_576_84",
    "doc_type": "slide",
    "is_definition": false,
    "contains_equation": false,
    "importance": "medium",
    "tags": [
      "neural networks"
    ]
  },
  {
    "text": "For General Non-Decreasing Activation Functions",
    "source": "ELEC/COMP 576 Lecture - Slide 85",
    "source_detail": "ELEC576_NNasSpine.pdf, Page 85",
    "lecture": "ELEC/COMP 576 Lecture",
    "lecture_number": "576",
    "page": 85,
    "content_type": "text",
    "doc_id": "slide_576_85",
    "doc_type": "slide",
    "is_definition": false,
    "contains_equation": false,
    "importance": "medium",
    "tags": [
      "neural networks"
    ]
  },
  {
    "text": "For General Non-Decreasing Activation Functions ReLU",
    "source": "ELEC/COMP 576 Lecture - Slide 86",
    "source_detail": "ELEC576_NNasSpine.pdf, Page 86",
    "lecture": "ELEC/COMP 576 Lecture",
    "lecture_number": "576",
    "page": 86,
    "content_type": "text",
    "doc_id": "slide_576_86",
    "doc_type": "slide",
    "is_definition": false,
    "contains_equation": false,
    "importance": "medium",
    "tags": [
      "neural networks"
    ]
  },
  {
    "text": "For General Non-Decreasing Activation Functions",
    "source": "ELEC/COMP 576 Lecture - Slide 87",
    "source_detail": "ELEC576_NNasSpine.pdf, Page 87",
    "lecture": "ELEC/COMP 576 Lecture",
    "lecture_number": "576",
    "page": 87,
    "content_type": "text",
    "doc_id": "slide_576_87",
    "doc_type": "slide",
    "is_definition": false,
    "contains_equation": false,
    "importance": "medium",
    "tags": [
      "neural networks"
    ]
  },
  {
    "text": "For General Non-Decreasing Activation Functions",
    "source": "ELEC/COMP 576 Lecture - Slide 88",
    "source_detail": "ELEC576_NNasSpine.pdf, Page 88",
    "lecture": "ELEC/COMP 576 Lecture",
    "lecture_number": "576",
    "page": 88,
    "content_type": "text",
    "doc_id": "slide_576_88",
    "doc_type": "slide",
    "is_definition": false,
    "contains_equation": false,
    "importance": "medium",
    "tags": [
      "neural networks"
    ]
  },
  {
    "text": "For General Non-Decreasing Activation Functions ReLU^2",
    "source": "ELEC/COMP 576 Lecture - Slide 89",
    "source_detail": "ELEC576_NNasSpine.pdf, Page 89",
    "lecture": "ELEC/COMP 576 Lecture",
    "lecture_number": "576",
    "page": 89,
    "content_type": "text",
    "doc_id": "slide_576_89",
    "doc_type": "slide",
    "is_definition": false,
    "contains_equation": true,
    "importance": "high",
    "tags": [
      "neural networks"
    ]
  },
  {
    "text": "Implicit Fourier Regularization is responsible for High-Frequency Low-Amplitude Adversarial Attacks",
    "source": "ELEC/COMP 576 Lecture - Slide 90",
    "source_detail": "ELEC576_NNasSpine.pdf, Page 90",
    "lecture": "ELEC/COMP 576 Lecture",
    "lecture_number": "576",
    "page": 90,
    "content_type": "text",
    "doc_id": "slide_576_90",
    "doc_type": "slide",
    "is_definition": false,
    "contains_equation": false,
    "importance": "high",
    "tags": [
      "regularization"
    ]
  },
  {
    "text": "# ELEC 576 / COMP 576 \u2013 Fall 2025   ## Assignment 0    **Due: September 16, 2025, 11:59 p.m. via Canvas**  This assignment is to help you prepare for future assignments. You must submit your report as a **PDF file** on Rice Canvas.  ---  ## 1. Python Machine Learning Stack (Anaconda)  You will use Python in this course.",
    "source": "Assignment 0 - Assignment Overview and Requirements",
    "source_detail": "assignment0.pdf, Section: Assignment Overview and Requirements",
    "assignment": "Assignment 0",
    "assignment_number": "0",
    "section_title": "Assignment Overview and Requirements",
    "doc_id": "assignment_0_Assignment_Overview_and_Requir_chunk1",
    "doc_type": "assignment",
    "parent_doc_id": "assignment_0_Assignment_Overview_and_Requir",
    "chunk_index": 1,
    "total_chunks": 8,
    "tags": [
      "assignment0"
    ]
  },
  {
    "text": "To prepare for future assignments and the final project, install Python and its packages using **Anaconda**, a high-performance distribution of Python and R including 100+ popular packages.  Follow the instructions: **Installing Anaconda**.  Confirm installation using:  ``` conda list ```  You should see the list of installed packages.",
    "source": "Assignment 0 - Assignment Overview and Requirements",
    "source_detail": "assignment0.pdf, Section: Assignment Overview and Requirements",
    "assignment": "Assignment 0",
    "assignment_number": "0",
    "section_title": "Assignment Overview and Requirements",
    "doc_id": "assignment_0_Assignment_Overview_and_Requir_chunk2",
    "doc_type": "assignment",
    "parent_doc_id": "assignment_0_Assignment_Overview_and_Requir",
    "chunk_index": 2,
    "total_chunks": 8,
    "tags": [
      "assignment0"
    ]
  },
  {
    "text": "You can also check using:  ``` python ```  If Anaconda is installed, the startup message will include **\u201cContinuum Analytics, Inc.\u201d**   Exit with:  ``` quit() ```  Read the **Conda Cheat Sheet** to learn basic `conda` commands.  ### Task 1   Run:  ``` conda info ```  Paste the result into your report.  ---  ## 2. Interactive Terminal (IPython/Jupyter)  IPython/Jupyter provides an interactive computational environment with code execution, text, math, plots, and media.",
    "source": "Assignment 0 - Assignment Overview and Requirements",
    "source_detail": "assignment0.pdf, Section: Assignment Overview and Requirements",
    "assignment": "Assignment 0",
    "assignment_number": "0",
    "section_title": "Assignment Overview and Requirements",
    "doc_id": "assignment_0_Assignment_Overview_and_Requir_chunk3",
    "doc_type": "assignment",
    "parent_doc_id": "assignment_0_Assignment_Overview_and_Requir",
    "chunk_index": 3,
    "total_chunks": 8,
    "tags": [
      "assignment0"
    ]
  },
  {
    "text": "Follow:  - IPython Tutorial   - Jupyter Documentation    See also: **Gallery of Jupyter Notebooks**  ---  ## 3. Transition from MATLAB to Python  MATLAB is powerful, but Python offers better memory efficiency and speed for data science.  Read: **NumPy for MATLAB Users**  To run Python on macOS/Linux:  ``` python ```  Windows users: follow **Running Python in Windows**.",
    "source": "Assignment 0 - Assignment Overview and Requirements",
    "source_detail": "assignment0.pdf, Section: Assignment Overview and Requirements",
    "assignment": "Assignment 0",
    "assignment_number": "0",
    "section_title": "Assignment Overview and Requirements",
    "doc_id": "assignment_0_Assignment_Overview_and_Requir_chunk4",
    "doc_type": "assignment",
    "parent_doc_id": "assignment_0_Assignment_Overview_and_Requir",
    "chunk_index": 4,
    "total_chunks": 8,
    "tags": [
      "assignment0"
    ]
  },
  {
    "text": "Before running the examples in the tutorial, import:  ```python import numpy as np import scipy.linalg ```  ### Task 2   Run all Python commands in the **\u201cLinear Algebra Equivalents\u201d** table from the tutorial using IPython.   Paste results in your report using any matrix of your choice.  *(Optional)*   Complete the Stanford NumPy Tutorial.  ---  ## 4. Plotting (Matplotlib/PyPlot)  Matplotlib is the main Python plotting library. See the **Matplotlib Gallery**.",
    "source": "Assignment 0 - Assignment Overview and Requirements",
    "source_detail": "assignment0.pdf, Section: Assignment Overview and Requirements",
    "assignment": "Assignment 0",
    "assignment_number": "0",
    "section_title": "Assignment Overview and Requirements",
    "doc_id": "assignment_0_Assignment_Overview_and_Requir_chunk5",
    "doc_type": "assignment",
    "parent_doc_id": "assignment_0_Assignment_Overview_and_Requir",
    "chunk_index": 5,
    "total_chunks": 8,
    "tags": [
      "assignment0"
    ]
  },
  {
    "text": "Pyplot provides MATLAB-style plotting functions. Read the **Pyplot Tutorial**.  ### Task 3   Run this script in IPython and paste the generated figure into your report:  ```python import matplotlib.pyplot as plt  plt.plot([1,2,3,4], [1,2,7,14]) plt.axis([0, 6, 0, 20]) plt.show() ```  ### Task 4   Use Matplotlib to create a figure of your choice.   Paste the code and figure into your report.  ---  ## 5. Version Control System (GitHub)  Git helps manage changes in collaborative projects.",
    "source": "Assignment 0 - Assignment Overview and Requirements",
    "source_detail": "assignment0.pdf, Section: Assignment Overview and Requirements",
    "assignment": "Assignment 0",
    "assignment_number": "0",
    "section_title": "Assignment Overview and Requirements",
    "doc_id": "assignment_0_Assignment_Overview_and_Requir_chunk6",
    "doc_type": "assignment",
    "parent_doc_id": "assignment_0_Assignment_Overview_and_Requir",
    "chunk_index": 6,
    "total_chunks": 8,
    "tags": [
      "assignment0"
    ]
  },
  {
    "text": "Read: **Why VCS is necessary**  Register for a **GitHub Student Account** for free private repos and complete the GitHub tutorials.  ### Task 5   Paste your GitHub account (username/profile link) into your report.  ---  ## 6.",
    "source": "Assignment 0 - Assignment Overview and Requirements",
    "source_detail": "assignment0.pdf, Section: Assignment Overview and Requirements",
    "assignment": "Assignment 0",
    "assignment_number": "0",
    "section_title": "Assignment Overview and Requirements",
    "doc_id": "assignment_0_Assignment_Overview_and_Requir_chunk7",
    "doc_type": "assignment",
    "parent_doc_id": "assignment_0_Assignment_Overview_and_Requir",
    "chunk_index": 7,
    "total_chunks": 8,
    "tags": [
      "assignment0"
    ]
  },
  {
    "text": "Integrated Development Environment (IDE)  Recommended Python IDEs: **PyCharm**, **Spyder**, **Google Colab**  For PyCharm:  - Apply for a free student license   - Install PyCharm   - Follow PyCharm Tutorials (including VCS setup)   - See PyCharm debugging guide    ### Task 6   Start a new project in your preferred IDE.   Commit and push it to GitHub as a **public project**.   Paste the project link into your report.  ---.",
    "source": "Assignment 0 - Assignment Overview and Requirements",
    "source_detail": "assignment0.pdf, Section: Assignment Overview and Requirements",
    "assignment": "Assignment 0",
    "assignment_number": "0",
    "section_title": "Assignment Overview and Requirements",
    "doc_id": "assignment_0_Assignment_Overview_and_Requir_chunk8",
    "doc_type": "assignment",
    "parent_doc_id": "assignment_0_Assignment_Overview_and_Requir",
    "chunk_index": 8,
    "total_chunks": 8,
    "tags": [
      "assignment0"
    ]
  },
  {
    "text": "## Submission Instructions\n\nSubmit a **PDF** containing intermediate and final results plus any necessary code on Canvas.\n\n---",
    "source": "Assignment 0 - Submission",
    "source_detail": "assignment0.pdf, Section: Submission",
    "assignment": "Assignment 0",
    "assignment_number": "0",
    "section_title": "Submission",
    "doc_id": "assignment_0_Submission",
    "doc_type": "assignment",
    "tags": [
      "assignment0"
    ]
  },
  {
    "text": "## Collaboration Policy\n\nCollaboration on ideas is encouraged, but **write-ups must be done individually**.\n\n---",
    "source": "Assignment 0 - Collaboration",
    "source_detail": "assignment0.pdf, Section: Collaboration",
    "assignment": "Assignment 0",
    "assignment_number": "0",
    "section_title": "Collaboration",
    "doc_id": "assignment_0_Collaboration",
    "doc_type": "assignment",
    "tags": [
      "assignment0"
    ]
  },
  {
    "text": "## Plagiarism Policy\n\nPlagiarism is not tolerated.  \nCredit all external sources explicitly.",
    "source": "Assignment 0 - Plagiarism",
    "source_detail": "assignment0.pdf, Section: Plagiarism",
    "assignment": "Assignment 0",
    "assignment_number": "0",
    "section_title": "Plagiarism",
    "doc_id": "assignment_0_Plagiarism",
    "doc_type": "assignment",
    "tags": [
      "assignment0"
    ]
  },
  {
    "text": "# ELEC 576 / COMP 576 \u2013 Fall 2025  \n## Assignment 1\n\n**Due: Oct 7, 2025, 11:59 p.m. via Canvas**\n\n---",
    "source": "Assignment 1 - Assignment Overview and Requirements",
    "source_detail": "assignment1.pdf, Section: Assignment Overview and Requirements",
    "assignment": "Assignment 1",
    "assignment_number": "1",
    "section_title": "Assignment Overview and Requirements",
    "doc_id": "assignment_1_Assignment_Overview_and_Requir",
    "doc_type": "assignment",
    "tags": [
      "assignment1"
    ]
  },
  {
    "text": "## Submission Instructions\nSubmit your report as a **PDF** and your code as a ZIP file named:\n\n```\nnetid-assignment1.zip\n```\n\nUpload everything to Canvas.\n\n---",
    "source": "Assignment 1 - Submission",
    "source_detail": "assignment1.pdf, Section: Submission",
    "assignment": "Assignment 1",
    "assignment_number": "1",
    "section_title": "Submission",
    "doc_id": "assignment_1_Submission",
    "doc_type": "assignment",
    "tags": [
      "assignment1"
    ]
  },
  {
    "text": "## GPU Resource\nYou may use:\n\n- **AWS GPU instances** (AWS Educate credits + GitHub Student Pack credits)  \n- **Google Colab** (recommended for convenience)\n\n---",
    "source": "Assignment 1 - GPU",
    "source_detail": "assignment1.pdf, Section: GPU",
    "assignment": "Assignment 1",
    "assignment_number": "1",
    "section_title": "GPU",
    "doc_id": "assignment_1_GPU",
    "doc_type": "assignment",
    "tags": [
      "assignment1"
    ]
  },
  {
    "text": "# 1. Backpropagation in a Simple Neural Network  You will implement backpropagation for a 3-layer neural network. Starter code is provided in   `three_layer_neural_network.py`.  ---  ## a) Dataset \u2014 Make Moons  Uncomment the dataset generation section:  ```python # generate and visualize Make-Moons dataset X, y = generate_data() plt.scatter(X[:, 0], X[:, 1], s=40, c=y, cmap=plt.cm.Spectral) ```  Run it and include the figure in your report.  ---  ## b) Activation Functions  Implement:  ### 1.",
    "source": "Assignment 1 - Problem 1: Backpropagation in a Simple Neural Network",
    "source_detail": "assignment1.pdf, Section: Problem 1: Backpropagation in a Simple Neural Network",
    "assignment": "Assignment 1",
    "assignment_number": "1",
    "section_title": "Problem 1: Backpropagation in a Simple Neural Network",
    "doc_id": "assignment_1_Problem_1:_Backpropagation_in__chunk1",
    "doc_type": "assignment",
    "parent_doc_id": "assignment_1_Problem_1:_Backpropagation_in_",
    "chunk_index": 1,
    "total_chunks": 6,
    "tags": [
      "assignment1"
    ]
  },
  {
    "text": "`actFun(self, z, type)` Where `type \u2208 {'Tanh', 'Sigmoid', 'ReLU'}`.  ### 2. Derive derivatives of: - Tanh   - Sigmoid   - ReLU    ### 3. Implement: `diff_actFun(self, z, type)`   Compute derivatives for all three activations.",
    "source": "Assignment 1 - Problem 1: Backpropagation in a Simple Neural Network",
    "source_detail": "assignment1.pdf, Section: Problem 1: Backpropagation in a Simple Neural Network",
    "assignment": "Assignment 1",
    "assignment_number": "1",
    "section_title": "Problem 1: Backpropagation in a Simple Neural Network",
    "doc_id": "assignment_1_Problem_1:_Backpropagation_in__chunk2",
    "doc_type": "assignment",
    "parent_doc_id": "assignment_1_Problem_1:_Backpropagation_in_",
    "chunk_index": 2,
    "total_chunks": 6,
    "tags": [
      "assignment1"
    ]
  },
  {
    "text": "---  ## c) Build the 3-Layer Network  Network structure:  - Input: 2 nodes   - Hidden layer: variable size   - Output: 2 nodes (probabilities for 2 classes)  Equations:  ``` z1 = W1x + b1 a1 = actFun(z1) z2 = W2a1 + b2 a2 = \u0177 = softmax(z2) ```  Loss function (cross entropy):  ``` L = -(1/N) \u03a3_n \u03a3_i y_n,i log(\u0177_n,i) ```  ### Implement:  1. `feedforward(self, X, actFun)`      Computes probabilities.  2. `calculate_loss(self, X, y)`      Computes cross-entropy loss.",
    "source": "Assignment 1 - Problem 1: Backpropagation in a Simple Neural Network",
    "source_detail": "assignment1.pdf, Section: Problem 1: Backpropagation in a Simple Neural Network",
    "assignment": "Assignment 1",
    "assignment_number": "1",
    "section_title": "Problem 1: Backpropagation in a Simple Neural Network",
    "doc_id": "assignment_1_Problem_1:_Backpropagation_in__chunk3",
    "doc_type": "assignment",
    "parent_doc_id": "assignment_1_Problem_1:_Backpropagation_in_",
    "chunk_index": 3,
    "total_chunks": 6,
    "tags": [
      "assignment1"
    ]
  },
  {
    "text": "---  ## d) Backpropagation  ### 1. Derive gradients: - \u2202L/\u2202W2   - \u2202L/\u2202b2   - \u2202L/\u2202W1   - \u2202L/\u2202b1    ### 2. Implement in code: `backprop(self, X, y)`  ---  ## e) Training  Training code is already provided.  ### 1. Train using activation functions: - Tanh   - Sigmoid   - ReLU    Include figures and describe differences.  Remove dataset visualization (as instructed).  ### 2. Vary hidden layer size   Train again (use Tanh). Describe the effect on accuracy and decision boundary.",
    "source": "Assignment 1 - Problem 1: Backpropagation in a Simple Neural Network",
    "source_detail": "assignment1.pdf, Section: Problem 1: Backpropagation in a Simple Neural Network",
    "assignment": "Assignment 1",
    "assignment_number": "1",
    "section_title": "Problem 1: Backpropagation in a Simple Neural Network",
    "doc_id": "assignment_1_Problem_1:_Backpropagation_in__chunk4",
    "doc_type": "assignment",
    "parent_doc_id": "assignment_1_Problem_1:_Backpropagation_in_",
    "chunk_index": 4,
    "total_chunks": 6,
    "tags": [
      "assignment1"
    ]
  },
  {
    "text": "---  ## f) Build a Deeper Network (n-layer)  Write a new file `n_layer_neural_network.py`.  Your implementation must support:  - Arbitrary number of layers   - Arbitrary layer sizes    ### Suggested structure (optional):  1. Create class: `DeepNeuralNetwork(NeuralNetwork)`   2. Override:    - feedforward      - backprop      - calculate_loss      - fit_model   3. Create a `Layer()` class   4. Use it to build feedforward/backprop modularly   5.",
    "source": "Assignment 1 - Problem 1: Backpropagation in a Simple Neural Network",
    "source_detail": "assignment1.pdf, Section: Problem 1: Backpropagation in a Simple Neural Network",
    "assignment": "Assignment 1",
    "assignment_number": "1",
    "section_title": "Problem 1: Backpropagation in a Simple Neural Network",
    "doc_id": "assignment_1_Problem_1:_Backpropagation_in__chunk5",
    "doc_type": "assignment",
    "parent_doc_id": "assignment_1_Problem_1:_Backpropagation_in_",
    "chunk_index": 5,
    "total_chunks": 6,
    "tags": [
      "assignment1"
    ]
  },
  {
    "text": "Include L2 regularization in:    - Loss      - Gradients    ### Experiments:  - Vary:   - Number of layers     - Hidden sizes     - Activation functions     - Regularization    Include: - Decision boundary plots   - Interesting observations    ### Train on a second dataset   Pick any Scikit-learn dataset or another dataset you like.   Describe: - Dataset   - Network configuration   - Observations    ---.",
    "source": "Assignment 1 - Problem 1: Backpropagation in a Simple Neural Network",
    "source_detail": "assignment1.pdf, Section: Problem 1: Backpropagation in a Simple Neural Network",
    "assignment": "Assignment 1",
    "assignment_number": "1",
    "section_title": "Problem 1: Backpropagation in a Simple Neural Network",
    "doc_id": "assignment_1_Problem_1:_Backpropagation_in__chunk6",
    "doc_type": "assignment",
    "parent_doc_id": "assignment_1_Problem_1:_Backpropagation_in_",
    "chunk_index": 6,
    "total_chunks": 6,
    "tags": [
      "assignment1"
    ]
  },
  {
    "text": "# 2. Training a Simple Deep Convolutional Network on MNIST  Starter code provided on Canvas.   Review tutorial: **Getting Started with PyTorch**.  MNIST: - 55,000 training   - 10,000 test   - 5,000 validation   - Each image is 28\u00d728    ---  ## a) Build and Train a 4-Layer DCN  Architecture:  ``` conv1(5\u00d75\u00d71\u219232) \u2192 ReLU \u2192 maxpool(2\u00d72) conv2(5\u00d75\u00d732\u219264) \u2192 ReLU \u2192 maxpool(2\u00d72) fc(1024) \u2192 ReLU \u2192 Dropout(0.5) \u2192 Softmax(10) ```  Steps:  1. Read ConvNet tutorial   2. Load MNIST (use torchvision)   3.",
    "source": "Assignment 1 - Problem 2: Training a Simple Deep Convolutional Network on MNIST",
    "source_detail": "assignment1.pdf, Section: Problem 2: Training a Simple Deep Convolutional Network on MNIST",
    "assignment": "Assignment 1",
    "assignment_number": "1",
    "section_title": "Problem 2: Training a Simple Deep Convolutional Network on MNIST",
    "doc_id": "assignment_1_Problem_2:_Training_a_Simple_D_chunk1",
    "doc_type": "assignment",
    "parent_doc_id": "assignment_1_Problem_2:_Training_a_Simple_D",
    "chunk_index": 1,
    "total_chunks": 4,
    "tags": [
      "assignment1"
    ]
  },
  {
    "text": "Complete class `Net()`   4. Complete training function `train()`   5. Use TensorBoard to visualize training loss   6. Report test accuracy    Include TensorBoard plots.  ---  ## b) More Training Visualization  Add TensorBoard logging for each 100 iterations:  - Weights   - Biases   - Net inputs   - ReLU activations   - Max-pool activations    Also log after each epoch:  - Validation error   - Test error    Include figures.",
    "source": "Assignment 1 - Problem 2: Training a Simple Deep Convolutional Network on MNIST",
    "source_detail": "assignment1.pdf, Section: Problem 2: Training a Simple Deep Convolutional Network on MNIST",
    "assignment": "Assignment 1",
    "assignment_number": "1",
    "section_title": "Problem 2: Training a Simple Deep Convolutional Network on MNIST",
    "doc_id": "assignment_1_Problem_2:_Training_a_Simple_D_chunk2",
    "doc_type": "assignment",
    "parent_doc_id": "assignment_1_Problem_2:_Training_a_Simple_D",
    "chunk_index": 2,
    "total_chunks": 4,
    "tags": [
      "assignment1"
    ]
  },
  {
    "text": "---  ## c) More Experiments  Try different:  - Activations:   - tanh, sigmoid, leaky-ReLU, MaxOut   - Initialization:   - Xavier   - Training algorithms:   - SGD     - Momentum     - Adagrad    Include TensorBoard figures and descriptions.  ---  # Collaboration Policy  Collaboration allowed for ideas.   Write-ups must be individual.  ---  # Plagiarism Policy  No plagiarism allowed.   Cite all sources.",
    "source": "Assignment 1 - Problem 2: Training a Simple Deep Convolutional Network on MNIST",
    "source_detail": "assignment1.pdf, Section: Problem 2: Training a Simple Deep Convolutional Network on MNIST",
    "assignment": "Assignment 1",
    "assignment_number": "1",
    "section_title": "Problem 2: Training a Simple Deep Convolutional Network on MNIST",
    "doc_id": "assignment_1_Problem_2:_Training_a_Simple_D_chunk3",
    "doc_type": "assignment",
    "parent_doc_id": "assignment_1_Problem_2:_Training_a_Simple_D",
    "chunk_index": 3,
    "total_chunks": 4,
    "tags": [
      "assignment1"
    ]
  },
  {
    "text": "---  # LLM Policy  **LLMs (ChatGPT, Copilot, etc.) are *not permitted* for coding in Assignment 1.**   All coding must be your own..",
    "source": "Assignment 1 - Problem 2: Training a Simple Deep Convolutional Network on MNIST",
    "source_detail": "assignment1.pdf, Section: Problem 2: Training a Simple Deep Convolutional Network on MNIST",
    "assignment": "Assignment 1",
    "assignment_number": "1",
    "section_title": "Problem 2: Training a Simple Deep Convolutional Network on MNIST",
    "doc_id": "assignment_1_Problem_2:_Training_a_Simple_D_chunk4",
    "doc_type": "assignment",
    "parent_doc_id": "assignment_1_Problem_2:_Training_a_Simple_D",
    "chunk_index": 4,
    "total_chunks": 4,
    "tags": [
      "assignment1"
    ]
  },
  {
    "text": "# ELEC 576 / COMP 576 \u2013 Fall 2025  \n## Assignment 2\n\n**Due: November 6, 2025, 11:59 PM via Canvas**\n\n---",
    "source": "Assignment 2 - Assignment Overview and Requirements",
    "source_detail": "assignment2.pdf, Section: Assignment Overview and Requirements",
    "assignment": "Assignment 2",
    "assignment_number": "2",
    "section_title": "Assignment Overview and Requirements",
    "doc_id": "assignment_2_Assignment_Overview_and_Requir",
    "doc_type": "assignment",
    "tags": [
      "assignment2"
    ]
  },
  {
    "text": "## Submission Instructions\n\nSubmit your report as a **PDF** on Canvas.\n\nYou may choose:\n\n### **Option 1**\n- Submit all answers, screenshots, and figures in a single PDF report.\n- Submit all code and supporting files as a ZIP named:\n```\nnetid-assignment2.zip\n```\n\n### **Option 2**\n- Submit a **PDF export of your Jupyter Notebook** (must include all code + outputs).\n- Make sure to run all cells before exporting.\n\nTemporary files (e.g., TensorBoard logs) should NOT be included.\n\n---",
    "source": "Assignment 2 - Submission",
    "source_detail": "assignment2.pdf, Section: Submission",
    "assignment": "Assignment 2",
    "assignment_number": "2",
    "section_title": "Submission",
    "doc_id": "assignment_2_Submission",
    "doc_type": "assignment",
    "tags": [
      "assignment2"
    ]
  },
  {
    "text": "## GPU Resource\n\nYou may use:\n\n- **AWS GPU instances** (AWS Educate credits + GitHub Student Pack)\n- **Google Colab**\n\n---",
    "source": "Assignment 2 - GPU",
    "source_detail": "assignment2.pdf, Section: GPU",
    "assignment": "Assignment 2",
    "assignment_number": "2",
    "section_title": "GPU",
    "doc_id": "assignment_2_GPU",
    "doc_type": "assignment",
    "tags": [
      "assignment2"
    ]
  },
  {
    "text": "# 1. Visualizing a CNN with CIFAR10  Train a CNN on CIFAR10 and visualize early-layer filters and activations.  ---  ## a) CIFAR10 Dataset  CIFAR10 consists of **32\u00d732 color images** in 10 classes:  airplane, automobile, bird, cat, deer, dog, frog, horse, ship, truck.",
    "source": "Assignment 2 - Problem 1: Visualizing a CNN with CIFAR10",
    "source_detail": "assignment2.pdf, Section: Problem 1: Visualizing a CNN with CIFAR10",
    "assignment": "Assignment 2",
    "assignment_number": "2",
    "section_title": "Problem 1: Visualizing a CNN with CIFAR10",
    "doc_id": "assignment_2_Problem_1:_Visualizing_a_CNN_w_chunk1",
    "doc_type": "assignment",
    "parent_doc_id": "assignment_2_Problem_1:_Visualizing_a_CNN_w",
    "chunk_index": 1,
    "total_chunks": 3,
    "tags": [
      "assignment2"
    ]
  },
  {
    "text": "Two import options:  ### **Option A (Recommended): TorchVision** - Images are RGB   - Resolution: 32\u00d732    ### **Option B** - Use `trainCifarStarterCode.py` and provided ZIP   - Images are **grayscale 28\u00d728**   - Requires preprocessing + one-hot labels    ---  ## b) Train LeNet5 on CIFAR10  Implement and train the following variant of **LeNet5**:  - Conv (5\u00d75), 6 filters \u2192 tanh   - MaxPool (2\u00d72)   - Conv (5\u00d75), 16 filters \u2192 tanh   - MaxPool (2\u00d72)   - FC: 5\u00d75\u00d716 \u2192 120 \u2192 84 \u2192 10   - Softmax output    ### Required outputs: - Training accuracy plot   - Testing accuracy plot   - Training loss plot   - Hyperparameter experiments (LR, momentum, optimizer, etc.)  ---  ## c) Visualize the Trained Network  ### 1.",
    "source": "Assignment 2 - Problem 1: Visualizing a CNN with CIFAR10",
    "source_detail": "assignment2.pdf, Section: Problem 1: Visualizing a CNN with CIFAR10",
    "assignment": "Assignment 2",
    "assignment_number": "2",
    "section_title": "Problem 1: Visualizing a CNN with CIFAR10",
    "doc_id": "assignment_2_Problem_1:_Visualizing_a_CNN_w_chunk2",
    "doc_type": "assignment",
    "parent_doc_id": "assignment_2_Problem_1:_Visualizing_a_CNN_w",
    "chunk_index": 2,
    "total_chunks": 3,
    "tags": [
      "assignment2"
    ]
  },
  {
    "text": "Visualize first-layer convolution filters   They should resemble **Gabor filters** (edge detectors).  ### 2. Visualize activations on test images   Include summary statistics for each convolutional layer.  ---.",
    "source": "Assignment 2 - Problem 1: Visualizing a CNN with CIFAR10",
    "source_detail": "assignment2.pdf, Section: Problem 1: Visualizing a CNN with CIFAR10",
    "assignment": "Assignment 2",
    "assignment_number": "2",
    "section_title": "Problem 1: Visualizing a CNN with CIFAR10",
    "doc_id": "assignment_2_Problem_1:_Visualizing_a_CNN_w_chunk3",
    "doc_type": "assignment",
    "parent_doc_id": "assignment_2_Problem_1:_Visualizing_a_CNN_w",
    "chunk_index": 3,
    "total_chunks": 3,
    "tags": [
      "assignment2"
    ]
  },
  {
    "text": "# 2. Visualizing and Understanding Convolutional Networks\n\nRead the paper:  \n**\"Visualizing and Understanding Convolutional Networks\" \u2014 Zeiler & Fergus**\n\n### Task:\n- Summarize the key ideas of the paper.\n\n### Optional:\nApply a visualization method (e.g., deconvolutional network) to the model trained in Problem 1.\n\n---",
    "source": "Assignment 2 - Problem 2: Visualizing and Understanding Convolutional Networks",
    "source_detail": "assignment2.pdf, Section: Problem 2: Visualizing and Understanding Convolutional Networks",
    "assignment": "Assignment 2",
    "assignment_number": "2",
    "section_title": "Problem 2: Visualizing and Understanding Convolutional Networks",
    "doc_id": "assignment_2_Problem_2:_Visualizing_and_Und",
    "doc_type": "assignment",
    "tags": [
      "assignment2"
    ]
  },
  {
    "text": "# 3. Build and Train an RNN on MNIST\n\nUse the starter code `rnnMNISTStarterCode.py`.\n\nMNIST images are 28\u00d728; the RNN will process input **one row (28 pixels) at a time**.\n\n---\n\n## a) Set Up an RNN\n\nModify the following:\n\n- Hidden layer size  \n- Learning rate  \n- Training iterations  \n- Cost function (use softmax cross entropy with logits)  \n- Optimizer  \n\n---\n\n## b) Try LSTM or GRU\n\nExperiment using:\n\n- `torch.nn.GRU`\n- `torch.nn.LSTM`\n\n### Required outputs:\n- Train accuracy  \n- Test accuracy  \n- Train loss  \n\nTry varying hidden units and compare performance.\n\n---\n\n## c) Compare Against the CNN\n\nCompare results from:\n\n- This RNN  \n- The CNN you built in Assignment 1  \n\nDiscuss differences in:\n\n- Accuracy  \n- Training behavior  \n- Strengths/weaknesses  \n\n---\n\n# Collaboration Policy\n\nCollaboration is encouraged for discussing ideas, but all write-ups must be done **independently**.\n\n---\n\n# Plagiarism Policy\n\nPlagiarism is strictly prohibited.  \nCite all external sources explicitly.",
    "source": "Assignment 2 - Problem 3: Build and Train an RNN on MNIST",
    "source_detail": "assignment2.pdf, Section: Problem 3: Build and Train an RNN on MNIST",
    "assignment": "Assignment 2",
    "assignment_number": "2",
    "section_title": "Problem 3: Build and Train an RNN on MNIST",
    "doc_id": "assignment_2_Problem_3:_Build_and_Train_an_",
    "doc_type": "assignment",
    "tags": [
      "assignment2"
    ]
  },
  {
    "text": "Presentation logistics (cross-posted on Canvas) 1. Poster Time Slots & Rescheduling Please view your assigned poster time slot in this spreadsheet If the time does not work , please leave a comment on your team's row indicating your availability (Possible times: Wed/Thurs, 12:00 PM \u2013 5:00 PM ). If your team does not have a row: Post your availability on Piazza immediately. 2. Presentation Details Presentations will primarily take place on the virtual Gathertown platform.",
    "source": "Piazza Note: Presentation logistics (cross-posted on Canvas)",
    "source_detail": "Piazza Instructor Note",
    "subject": "Presentation logistics (cross-posted on Canvas)",
    "tags": [
      "instructor-note",
      "pin",
      "project"
    ],
    "doc_id": "piazza_note_0_chunk1",
    "doc_type": "piazza_note",
    "parent_doc_id": "piazza_note_0",
    "chunk_index": 1,
    "total_chunks": 5
  },
  {
    "text": "Unfortunately, Gathertown does not have enough tables for each project. The spreadsheet above indicates whether your presentation will take place on Gathertown or Zoom. 3. If you're presenting on Zoom Join my office hour Zoom link. Join the breakout room named after the TA grading your poster. 4. If you're presenting on Gathertown Please verify you have received the Gathertown email granting you edit access for poster uploading.",
    "source": "Piazza Note: Presentation logistics (cross-posted on Canvas)",
    "source_detail": "Piazza Instructor Note",
    "subject": "Presentation logistics (cross-posted on Canvas)",
    "tags": [
      "instructor-note",
      "pin",
      "project"
    ],
    "doc_id": "piazza_note_0_chunk2",
    "doc_type": "piazza_note",
    "parent_doc_id": "piazza_note_0",
    "chunk_index": 2,
    "total_chunks": 5
  },
  {
    "text": "If you did NOT receive it, please leave a comment on your team's row in the spreadsheet. When uploading your poster in gathertown, use this link . Here are the instructions for accessing and uploading your poster to Gathertown. By default, each table's poster is from last year; please replace it with your updated poster. During your presentation itself, use this link.",
    "source": "Piazza Note: Presentation logistics (cross-posted on Canvas)",
    "source_detail": "Piazza Instructor Note",
    "subject": "Presentation logistics (cross-posted on Canvas)",
    "tags": [
      "instructor-note",
      "pin",
      "project"
    ],
    "doc_id": "piazza_note_0_chunk3",
    "doc_type": "piazza_note",
    "parent_doc_id": "piazza_note_0",
    "chunk_index": 3,
    "total_chunks": 5
  },
  {
    "text": "Unfortunately, only a maximum of 25 students can use this link at a time from Tuesday to Thursday ( the link won't work before Monday ). Thus, we kindly request that you leave the Gathertown environment once your presentation is complete . Based on last year, I believe this limit will be sufficient (if not, we will purchase more) If you happen to require a password, use DeepLearn 5. General Reminders Deadline: Submit your final poster to Canvas (and Gathertown if applicable) by Tuesday 5:00 p.m.",
    "source": "Piazza Note: Presentation logistics (cross-posted on Canvas)",
    "source_detail": "Piazza Instructor Note",
    "subject": "Presentation logistics (cross-posted on Canvas)",
    "tags": [
      "instructor-note",
      "pin",
      "project"
    ],
    "doc_id": "piazza_note_0_chunk4",
    "doc_type": "piazza_note",
    "parent_doc_id": "piazza_note_0",
    "chunk_index": 4,
    "total_chunks": 5
  },
  {
    "text": "Please re-read the project logistics document in general Proposal Feedback & Grades: Team captains, all proposals should be graded by now. Please verify you have received your feedback/grade on Canvas and ensure it has been disseminated to all team members. If you are missing a grade, please make a post on Piazza immediately..",
    "source": "Piazza Note: Presentation logistics (cross-posted on Canvas)",
    "source_detail": "Piazza Instructor Note",
    "subject": "Presentation logistics (cross-posted on Canvas)",
    "tags": [
      "instructor-note",
      "pin",
      "project"
    ],
    "doc_id": "piazza_note_0_chunk5",
    "doc_type": "piazza_note",
    "parent_doc_id": "piazza_note_0",
    "chunk_index": 5,
    "total_chunks": 5
  },
  {
    "text": "Max project team size is 5, moving OH for this week (cross-posted on Canvas)\nHi everyone, please note that the maximum project team size is 5 people. I changed this on Piazza a week ago, but I forgot to announce this more formally. Also, as I'm not feeling well, my office hour will take place tomorrow (Wednesday) 10-11 am, same Zoom link. This change is only for this week",
    "source": "Piazza Note: Max project team size is 5, moving OH for this week (cross-posted on Canvas)",
    "source_detail": "Piazza Instructor Note",
    "subject": "Max project team size is 5, moving OH for this week (cross-posted on Canvas)",
    "tags": [
      "instructor-note",
      "logistics",
      "pin",
      "project"
    ],
    "doc_id": "piazza_note_1",
    "doc_type": "piazza_note"
  },
  {
    "text": "Project logistics, proposal due Nov 18 (cross-posted on Canvas)\nNow that HW2 is behind us, it is time to think about your final project proposal due next Tuesday (November 18). Please see the Canvas Assignment named Final Project Proposal. We will provide feedback by Nov 24, which is when the Poster Availability Form will open. For the final project beyond the proposal, please refer to the following rubric and timeline: https://docs.google.com/document/d/1aKTF0AukOG933Dx19-r3Onf2joci_dBqoAUnwnYbq-I/edit?usp=sharinLinks to an external site. . Please also see the Canvas assignments titled \"Final Project Poster\" and \"Final Project Writeup.\"",
    "source": "Piazza Note: Project logistics, proposal due Nov 18 (cross-posted on Canvas)",
    "source_detail": "Piazza Instructor Note",
    "subject": "Project logistics, proposal due Nov 18 (cross-posted on Canvas)",
    "tags": [
      "instructor-note",
      "logistics",
      "pin",
      "project"
    ],
    "doc_id": "piazza_note_2",
    "doc_type": "piazza_note"
  },
  {
    "text": "Free Colab Pro subscriptions\nA couple of students asked me how to get the Colab Pro plan (for faster GPU run-times) -- here it is: These free subscriptions are available to anyone who can verify their identity as a faculty member or student at a U.S.-based higher education institution. See our FAQ for more. Simply visit our sign up page (look for the \u201cNo cost to students and educators\u201d button) to begin the verification process and claim your free Colab Pro subscription. -Yuhao",
    "source": "Piazza Note: Free Colab Pro subscriptions",
    "source_detail": "Piazza Instructor Note",
    "subject": "Free Colab Pro subscriptions",
    "tags": [
      "instructor-note",
      "logistics",
      "pin"
    ],
    "doc_id": "piazza_note_3",
    "doc_type": "piazza_note"
  },
  {
    "text": "Search for Project Teammates!\nHi everyone, I hope post @5 can help you find teammates for your project. Teams can have 1-5 members. It may be helpful to post the following: interests skills/strengths you would bring to the team (coding, organizational, time management skills, etc) requests for certain skills your team is looking for (looking for someone with Python experience, etc). scheduling information (i.e., I can meet during evenings, except on Wednesdays). #pin",
    "source": "Piazza Note: Search for Project Teammates!",
    "source_detail": "Piazza Instructor Note",
    "subject": "Search for Project Teammates!",
    "tags": [
      "instructor-note",
      "pin",
      "project"
    ],
    "doc_id": "piazza_note_4",
    "doc_type": "piazza_note"
  },
  {
    "text": "Search for Teammates!\nPA.load(\"/dashboard/project_partners\", null, function(data){ $('#' + 'questionText').html(data);}); #pin",
    "source": "Piazza Note: Search for Teammates!",
    "source_detail": "Piazza Instructor Note",
    "subject": "Search for Teammates!",
    "tags": [
      "pin"
    ],
    "doc_id": "piazza_note_5",
    "doc_type": "piazza_note"
  },
  {
    "text": "FAQ for HW2 (cross-posted on Canvas) Credit to Zishen :) Here are some common questions and answers for HW2. Hope this would be helpful. Reminder : The submission deadline for HW2 is Nov 6, 11:59 PM. Q1: How do I import the CIFAR10 dataset? Do I need to use the provided zip folder? Answer: As stated in the HW2 instructions, there are two ways to import CIFAR-10: \u2022 If you import it using the Torch dataset, the images are RGB with a resolution of 32\u00d732.",
    "source": "Piazza Note: FAQ for HW2 (cross-posted on Canvas)",
    "source_detail": "Piazza Instructor Note",
    "subject": "FAQ for HW2 (cross-posted on Canvas)",
    "tags": [
      "assignment2",
      "instructor-note",
      "pin"
    ],
    "doc_id": "piazza_note_6_chunk1",
    "doc_type": "piazza_note",
    "parent_doc_id": "piazza_note_6",
    "chunk_index": 1,
    "total_chunks": 4
  },
  {
    "text": "\u2022 If you import it from the provided zip folder, the images are grayscale with a resolution of 28\u00d728. You\u2019ll need to adjust your network architecture according to the chosen method. Q2: The output size of my neural network layers doesn\u2019t match the instructions. Answer: The instructions only provided a reference for the network structure. The actual layer sizes will depend on the input image dimensions, your choice of padding, pooling, and stride.",
    "source": "Piazza Note: FAQ for HW2 (cross-posted on Canvas)",
    "source_detail": "Piazza Instructor Note",
    "subject": "FAQ for HW2 (cross-posted on Canvas)",
    "tags": [
      "assignment2",
      "instructor-note",
      "pin"
    ],
    "doc_id": "piazza_note_6_chunk2",
    "doc_type": "piazza_note",
    "parent_doc_id": "piazza_note_6",
    "chunk_index": 2,
    "total_chunks": 4
  },
  {
    "text": "Q3: Can I modify the network architecture? Can I modify the code skeleton? Answer: Yes, you\u2019re encouraged to experiment with different settings\u2014such as the number of output channels, dropout layers, activation functions, learning rates, etc. Q4: What\u2019s the late submission policy? Answer: As stated on the class website: \u2022 You have 2 late days total across all 3 assignments, after that, a 25% penalty per day applies. \u2022 If you submit an assignment 0.01 days late, that counts as one whole late day.",
    "source": "Piazza Note: FAQ for HW2 (cross-posted on Canvas)",
    "source_detail": "Piazza Instructor Note",
    "subject": "FAQ for HW2 (cross-posted on Canvas)",
    "tags": [
      "assignment2",
      "instructor-note",
      "pin"
    ],
    "doc_id": "piazza_note_6_chunk3",
    "doc_type": "piazza_note",
    "parent_doc_id": "piazza_note_6",
    "chunk_index": 3,
    "total_chunks": 4
  },
  {
    "text": "Q5: My PDF file is very long with output images. Answer: We highly encourage you to use plt.subplots to arange the images. Please make sure to include titles and necessary descriptions. Q6: What's the LLM policy? Answer: No LLMs allowed @88.",
    "source": "Piazza Note: FAQ for HW2 (cross-posted on Canvas)",
    "source_detail": "Piazza Instructor Note",
    "subject": "FAQ for HW2 (cross-posted on Canvas)",
    "tags": [
      "assignment2",
      "instructor-note",
      "pin"
    ],
    "doc_id": "piazza_note_6_chunk4",
    "doc_type": "piazza_note",
    "parent_doc_id": "piazza_note_6",
    "chunk_index": 4,
    "total_chunks": 4
  },
  {
    "text": "HW2 checklist\nHere is the link to the HW2 checklist: https://docs.google.com/document/d/14DuAQtDk5cytMTzvdqUYfC1r8_77ThuGKWbPuDC2qr0/edit?usp=sharing",
    "source": "Piazza Note: HW2 checklist",
    "source_detail": "Piazza Instructor Note",
    "subject": "HW2 checklist",
    "tags": [
      "assignment2",
      "instructor-note",
      "pin"
    ],
    "doc_id": "piazza_note_7",
    "doc_type": "piazza_note"
  },
  {
    "text": "Looking for teammates: Scientific Image Forgery Detection Hello everyone, My name is Shichen, I am a first year MCS student looking for team members for the final project. I am interested in this Kaggle competition: https://www.kaggle.com/competitions/recodai-luc-scientific-image-forgery-detection/overview where we need train a model to find copy-move incidents in scientific images. CNN + Attention looks like a compelling idea to me, but I can't work this out alone.",
    "source": "Piazza Note: Looking for teammates: Scientific Image Forgery Detection",
    "source_detail": "Piazza Instructor Note",
    "subject": "Looking for teammates: Scientific Image Forgery Detection",
    "tags": [
      "project"
    ],
    "doc_id": "piazza_note_8_chunk1",
    "doc_type": "piazza_note",
    "parent_doc_id": "piazza_note_8",
    "chunk_index": 1,
    "total_chunks": 3
  },
  {
    "text": "Please join my team so we can work together on this! About me : I have a solid background (PhD degree) in math, and about 4 years of python coding experiences. I am interested in learning new ideas and building new things. What I can bring to the team : Provide the general idea and generate a demo repository, assign specific tasks to team members, manage progress and schedule meeting. What I am looking for : Anyone who is interested in this project and willing to spend time on it.",
    "source": "Piazza Note: Looking for teammates: Scientific Image Forgery Detection",
    "source_detail": "Piazza Instructor Note",
    "subject": "Looking for teammates: Scientific Image Forgery Detection",
    "tags": [
      "project"
    ],
    "doc_id": "piazza_note_8_chunk2",
    "doc_type": "piazza_note",
    "parent_doc_id": "piazza_note_8",
    "chunk_index": 2,
    "total_chunks": 3
  },
  {
    "text": "I am pretty flexible with many things. As long as you want to work hard on it, I am sure there is a way to collaborate. Just talk to me! Scheduling : Flexible. If you are interested or just want to learn more, feel free to reply to this post or send me an email at Shichen.Tang@rice.edu.",
    "source": "Piazza Note: Looking for teammates: Scientific Image Forgery Detection",
    "source_detail": "Piazza Instructor Note",
    "subject": "Looking for teammates: Scientific Image Forgery Detection",
    "tags": [
      "project"
    ],
    "doc_id": "piazza_note_8_chunk3",
    "doc_type": "piazza_note",
    "parent_doc_id": "piazza_note_8",
    "chunk_index": 3,
    "total_chunks": 3
  },
  {
    "text": "HW1 checklist\nTo make sure you don't accidentally forget to include something for this homework, please refer to this checklist: https://docs.google.com/document/d/18BJRqHrrlT6xlL-6LRpRzbdWegvL2fYLeIG1AG40cIQ/edit?usp=sharing . Based on my experience last year, most students forgot to include some things for Q2b (which has been addressed a while ago on @24)",
    "source": "Piazza Note: HW1 checklist",
    "source_detail": "Piazza Instructor Note",
    "subject": "HW1 checklist",
    "tags": [
      "assignment1",
      "instructor-note"
    ],
    "doc_id": "piazza_note_9",
    "doc_type": "piazza_note"
  },
  {
    "text": "Oct 7 Tuesday OH 8:30-9:30\nDue to a medical appointment, my office hours next week (Oct 7) will be 8:30-9:30 am. If you can't make it, please ask questions via Piazza.",
    "source": "Piazza Note: Oct 7 Tuesday OH 8:30-9:30",
    "source_detail": "Piazza Instructor Note",
    "subject": "Oct 7 Tuesday OH 8:30-9:30",
    "tags": [
      "instructor-note",
      "logistics"
    ],
    "doc_id": "piazza_note_10",
    "doc_type": "piazza_note"
  },
  {
    "text": "Tuesday OH 10-11\nDue to a medical apppointment, my office hour tommorow is 10-11am, instead of the normal 10:30-11:30. If you can't make it, feel free to ask questions on Piazza!",
    "source": "Piazza Note: Tuesday OH 10-11",
    "source_detail": "Piazza Instructor Note",
    "subject": "Tuesday OH 10-11",
    "tags": [
      "instructor-note",
      "logistics"
    ],
    "doc_id": "piazza_note_11",
    "doc_type": "piazza_note"
  },
  {
    "text": "Welcome to Piazza! Piazza is a Q&A platform designed to get you great answers from classmates and instructors fast. We've put together this list of tips you might find handy as you get started: Ask questions! The best way to get answers is to ask questions! Ask questions on Piazza rather than emailing your teaching staff so everyone can benefit from the response (and so you can get answers from classmates who are up as late as you are). Edit questions and answers wiki-style.",
    "source": "Piazza Note: Welcome to Piazza!",
    "source_detail": "Piazza Instructor Note",
    "subject": "Welcome to Piazza!",
    "tags": [],
    "doc_id": "piazza_note_12_chunk1",
    "doc_type": "piazza_note",
    "parent_doc_id": "piazza_note_12",
    "chunk_index": 1,
    "total_chunks": 4
  },
  {
    "text": "Think of Piazza as a Q&A wiki for your class. Every question has just a single students' answer that students can edit collectively (and a single instructors\u2019 answer for instructors). Add a followup to comment or ask further questions. To comment on or ask further questions about a post, start a followup discussion . Mark it resolved when the issue has been addressed, and add any relevant information back into the Q&A above. Go anonymous. Shy? No problem.",
    "source": "Piazza Note: Welcome to Piazza!",
    "source_detail": "Piazza Instructor Note",
    "subject": "Welcome to Piazza!",
    "tags": [],
    "doc_id": "piazza_note_12_chunk2",
    "doc_type": "piazza_note",
    "parent_doc_id": "piazza_note_12",
    "chunk_index": 2,
    "total_chunks": 4
  },
  {
    "text": "You can always opt to post or edit anonymously. Tag your posts. It's far more convenient to find all posts about your Homework 3 or Midterm 1 when the posts are tagged. Type a \u201c#\u201d before a key word to tag. Click a blue tag in a post or the question feed to filter for all posts that share that tag. Format code and equations. Adding a code snippet? Click the pre or tt button in the question editor to add pre-formatted or inline teletype text.",
    "source": "Piazza Note: Welcome to Piazza!",
    "source_detail": "Piazza Instructor Note",
    "subject": "Welcome to Piazza!",
    "tags": [],
    "doc_id": "piazza_note_12_chunk3",
    "doc_type": "piazza_note",
    "parent_doc_id": "piazza_note_12",
    "chunk_index": 3,
    "total_chunks": 4
  },
  {
    "text": "Mathematical equation? Click the Fx button to access the LaTeX editor to build a nicely formatted equation. View and download class details and resources. Click the Course Page button in your top bar to access the class syllabus, staff contact information, office hours details, and course resources\u2014all in one place! Contact the Piazza Team anytime with questions or comments at team@piazza.com . We love feedback!.",
    "source": "Piazza Note: Welcome to Piazza!",
    "source_detail": "Piazza Instructor Note",
    "subject": "Welcome to Piazza!",
    "tags": [],
    "doc_id": "piazza_note_12_chunk4",
    "doc_type": "piazza_note",
    "parent_doc_id": "piazza_note_12",
    "chunk_index": 4,
    "total_chunks": 4
  },
  {
    "text": "Q: Final Project Presentation\nI noticed that the date of the final project presentation on the schedule is from December 10th to December 17th. Do we need to present it in class or just upload and submit it within this period of time?\n\nA: Sorry for the late response. On December 10, we will have a virtual poster conference on the platform Gathertown. Please plan to be in a location with good internet. After you/your group fills in a survey with the times you're available on December 10, you/your group will be given a ten-minute time slot where a TA will listen to your presentation. More info will be released later! EDIT: For more info, please see the Canvas assignment named Final Project Proposal",
    "source": "Piazza Q&A",
    "source_detail": "Piazza Question & Answer",
    "question": "Final Project Presentation\nI noticed that the date of the final project presentation on the schedule is from December 10th to December 17th. Do we need to present it in class or just upload and submit it within this period of time?",
    "answer": "Sorry for the late response. On December 10, we will have a virtual poster conference on the platform Gathertown. Please plan to be in a location with good internet. After you/your group fills in a survey with the times you're available on December 10, you/your group will be given a ten-minute time slot where a TA will listen to your presentation. More info will be released later! EDIT: For more info, please see the Canvas assignment named Final Project Proposal",
    "tags": [
      "project",
      "pin"
    ],
    "doc_id": "piazza_qa_1",
    "doc_type": "piazza_qa",
    "is_followup": false
  },
  {
    "text": "Parent Q: Final Project Presentation\nI noticed that the date of the final project presentation on the schedule is from December 10th to December 17th. Do we need to present it in class or just upload and submit it within this period of time?\n\nFollowup Q: Are there any restrictions for the final project? Can I undertake the project of LLM for extracting case information and completing RS?\n\nA: The only restriction is that the final project must use deep learning, which LLMs fall under. You'll get further feedback when you submit your project proposal.",
    "source": "Piazza Q&A (Followup)",
    "source_detail": "Piazza Followup Question & Answer",
    "parent_question": "Final Project Presentation\nI noticed that the date of the final project presentation on the schedule is from December 10th to December 17th. Do we need to present it in class or just upload and submit it within this period of time?",
    "question": "Are there any restrictions for the final project? Can I undertake the project of LLM for extracting case information and completing RS?",
    "answer": "The only restriction is that the final project must use deep learning, which LLMs fall under. You'll get further feedback when you submit your project proposal.",
    "tags": [
      "project",
      "pin"
    ],
    "doc_id": "piazza_qa_2",
    "doc_type": "piazza_qa",
    "is_followup": true
  },
  {
    "text": "Parent Q: Final Project Presentation\nI noticed that the date of the final project presentation on the schedule is from December 10th to December 17th. Do we need to present it in class or just upload and submit it within this period of time?\n\nFollowup Q: Will there be a Q&A session after the presentation?\n\nA: From the google doc in @109, \"Duration of poster presentations will be 5 min for presenting, 5 minutes for questions\"",
    "source": "Piazza Q&A (Followup)",
    "source_detail": "Piazza Followup Question & Answer",
    "parent_question": "Final Project Presentation\nI noticed that the date of the final project presentation on the schedule is from December 10th to December 17th. Do we need to present it in class or just upload and submit it within this period of time?",
    "question": "Will there be a Q&A session after the presentation?",
    "answer": "From the google doc in @109, \"Duration of poster presentations will be 5 min for presenting, 5 minutes for questions\"",
    "tags": [
      "project",
      "pin"
    ],
    "doc_id": "piazza_qa_3",
    "doc_type": "piazza_qa",
    "is_followup": true
  },
  {
    "text": "Q: Issue with Gathertown Access\nEveryone in our group don't have access to the Gathertown links, both for editing and for presentation, as demonstrated in the attached screenshots. We've also not received the email for Gathertown links either. Could you please look into this issue and grant the access fo r our group? Many thanks!\n\nA: The presentation link won't work until Monday due to costs @141. Only the team captain will be given access to edit the room i.e. upload the poster. I've added yg108@rice.edu . Please let me know if it works now",
    "source": "Piazza Q&A",
    "source_detail": "Piazza Question & Answer",
    "question": "Issue with Gathertown Access\nEveryone in our group don't have access to the Gathertown links, both for editing and for presentation, as demonstrated in the attached screenshots. We've also not received the email for Gathertown links either. Could you please look into this issue and grant the access fo r our group? Many thanks!",
    "answer": "The presentation link won't work until Monday due to costs @141. Only the team captain will be given access to edit the room i.e. upload the poster. I've added yg108@rice.edu . Please let me know if it works now",
    "tags": [
      "project"
    ],
    "doc_id": "piazza_qa_4",
    "doc_type": "piazza_qa",
    "is_followup": false
  },
  {
    "text": "Q: Examples of Previous Poster Presentations\nHello! I was just wondering if there were any examples of previous Poster Presentations of this class. I am trying to get a better idea of what it should look like outside of just the grading rubric.\n\nA: Page 3 of @109: Example Posters (Note: criteria from past semesters may have been slightly differ so poster sections may differ): https://drive.google.com/drive/folders/12Yjw4_qU4-wL0_72FOoqCOq3bjPsHdKc?usp=sharing",
    "source": "Piazza Q&A",
    "source_detail": "Piazza Question & Answer",
    "question": "Examples of Previous Poster Presentations\nHello! I was just wondering if there were any examples of previous Poster Presentations of this class. I am trying to get a better idea of what it should look like outside of just the grading rubric.",
    "answer": "Page 3 of @109: Example Posters (Note: criteria from past semesters may have been slightly differ so poster sections may differ): https://drive.google.com/drive/folders/12Yjw4_qU4-wL0_72FOoqCOq3bjPsHdKc?usp=sharing",
    "tags": [
      "project"
    ],
    "doc_id": "piazza_qa_5",
    "doc_type": "piazza_qa",
    "is_followup": false
  },
  {
    "text": "Q: Final Project clarification\nWhat are the exact days available for poster this year? When working on the Poster Availability Form, I saw Wednesday, 12/11 and Thursday, 12/12 are available dates. But for this year, Wednesday is on 12/10 and Thursday is on 12/11. Could you please provide a quick clarification on this matter, so that we can get better prepared for the next following dates?\n\nA: Wednesday December 10th and Thursday December 11th. @132",
    "source": "Piazza Q&A",
    "source_detail": "Piazza Question & Answer",
    "question": "Final Project clarification\nWhat are the exact days available for poster this year? When working on the Poster Availability Form, I saw Wednesday, 12/11 and Thursday, 12/12 are available dates. But for this year, Wednesday is on 12/10 and Thursday is on 12/11. Could you please provide a quick clarification on this matter, so that we can get better prepared for the next following dates?",
    "answer": "Wednesday December 10th and Thursday December 11th. @132",
    "tags": [
      "project"
    ],
    "doc_id": "piazza_qa_6",
    "doc_type": "piazza_qa",
    "is_followup": false
  },
  {
    "text": "Q: Poster Availability Form Typos\nThe dates in the google form are not correct (numerical dates and weekday names), and some of the time slots repeat.\n\nA: Fixed. Sorry, I forgot to update the dates and weekday names from last year. I do not see repeated time slots",
    "source": "Piazza Q&A",
    "source_detail": "Piazza Question & Answer",
    "question": "Poster Availability Form Typos\nThe dates in the google form are not correct (numerical dates and weekday names), and some of the time slots repeat.",
    "answer": "Fixed. Sorry, I forgot to update the dates and weekday names from last year. I do not see repeated time slots",
    "tags": [
      "project"
    ],
    "doc_id": "piazza_qa_7",
    "doc_type": "piazza_qa",
    "is_followup": false
  },
  {
    "text": "Q: Model&#39;s Accuracy on Final Project Hi Instructors, We have questions about the model's accuracy for the final project. Is there a minimum accuracy that we need to achieve to get a good grade? Thank you! Best Regards,  A: You'll be assessed on the thoroughness and systematic nature of your project. We recognize that for some deep learning tasks, achieving exceptional performance is challenging without sufficient data and/or computational resources.",
    "source": "Piazza Q&A",
    "source_detail": "Piazza Question & Answer",
    "question": "Model&#39;s Accuracy on Final Project\nHi Instructors, We have questions about the model's accuracy for the final project. Is there a minimum accuracy that we need to achieve to get a good grade? Thank you! Best Regards,",
    "answer": "You'll be assessed on the thoroughness and systematic nature of your project. We recognize that for some deep learning tasks, achieving exceptional performance is challenging without sufficient data and/or computational resources. I'd recommend showing that your project outperforms a naive approach/baseline. For example, if you had an EEG dataset of 100 patients with aphasia and 100 healthy controls, an 80% accurate diagnostic classifier is significantly better than naively predicting that everyone has aphasia (which would yield 50% accuracy). We wouldn't penalize a student for getting 80% accuracy instead of 90% accuracy. Another example is if you've built a CNN-based regressor that achieves an R-squared value of 0.7, you could demonstrate that it outperforms simpler regression methods, such as linear regression.",
    "tags": [
      "project"
    ],
    "doc_id": "piazza_qa_8_chunk1",
    "doc_type": "piazza_qa",
    "is_followup": false,
    "parent_doc_id": "piazza_qa_8",
    "chunk_index": 1,
    "total_chunks": 3
  },
  {
    "text": "I'd recommend showing that your project outperforms a naive approach/baseline. For example, if you had an EEG dataset of 100 patients with aphasia and 100 healthy controls, an 80% accurate diagnostic classifier is significantly better than naively predicting that everyone has aphasia (which would yield 50% accuracy). We wouldn't penalize a student for getting 80% accuracy instead of 90% accuracy.",
    "source": "Piazza Q&A",
    "source_detail": "Piazza Question & Answer",
    "question": "Model&#39;s Accuracy on Final Project\nHi Instructors, We have questions about the model's accuracy for the final project. Is there a minimum accuracy that we need to achieve to get a good grade? Thank you! Best Regards,",
    "answer": "You'll be assessed on the thoroughness and systematic nature of your project. We recognize that for some deep learning tasks, achieving exceptional performance is challenging without sufficient data and/or computational resources. I'd recommend showing that your project outperforms a naive approach/baseline. For example, if you had an EEG dataset of 100 patients with aphasia and 100 healthy controls, an 80% accurate diagnostic classifier is significantly better than naively predicting that everyone has aphasia (which would yield 50% accuracy). We wouldn't penalize a student for getting 80% accuracy instead of 90% accuracy. Another example is if you've built a CNN-based regressor that achieves an R-squared value of 0.7, you could demonstrate that it outperforms simpler regression methods, such as linear regression.",
    "tags": [
      "project"
    ],
    "doc_id": "piazza_qa_8_chunk2",
    "doc_type": "piazza_qa",
    "is_followup": false,
    "parent_doc_id": "piazza_qa_8",
    "chunk_index": 2,
    "total_chunks": 3
  },
  {
    "text": "Another example is if you've built a CNN-based regressor that achieves an R-squared value of 0.7, you could demonstrate that it outperforms simpler regression methods, such as linear regression..",
    "source": "Piazza Q&A",
    "source_detail": "Piazza Question & Answer",
    "question": "Model&#39;s Accuracy on Final Project\nHi Instructors, We have questions about the model's accuracy for the final project. Is there a minimum accuracy that we need to achieve to get a good grade? Thank you! Best Regards,",
    "answer": "You'll be assessed on the thoroughness and systematic nature of your project. We recognize that for some deep learning tasks, achieving exceptional performance is challenging without sufficient data and/or computational resources. I'd recommend showing that your project outperforms a naive approach/baseline. For example, if you had an EEG dataset of 100 patients with aphasia and 100 healthy controls, an 80% accurate diagnostic classifier is significantly better than naively predicting that everyone has aphasia (which would yield 50% accuracy). We wouldn't penalize a student for getting 80% accuracy instead of 90% accuracy. Another example is if you've built a CNN-based regressor that achieves an R-squared value of 0.7, you could demonstrate that it outperforms simpler regression methods, such as linear regression.",
    "tags": [
      "project"
    ],
    "doc_id": "piazza_qa_8_chunk3",
    "doc_type": "piazza_qa",
    "is_followup": false,
    "parent_doc_id": "piazza_qa_8",
    "chunk_index": 3,
    "total_chunks": 3
  },
  {
    "text": "Q: Clarification on Proposal Requirement 2.b.iii In the rubric for the final project proposal, as well as for the project itself, there is a section for \"Is this problem not previously solved\". I would like some clarification on this requirement.",
    "source": "Piazza Q&A",
    "source_detail": "Piazza Question & Answer",
    "question": "Clarification on Proposal Requirement 2.b.iii\nIn the rubric for the final project proposal, as well as for the project itself, there is a section for \"Is this problem not previously solved\". I would like some clarification on this requirement. How strictly original does our project have to be? Many of the example projects seem to be working on \"solved\" problems, such as the Rice Self-Driving Car paper which is explicitly trying to replicate the results of another paper using their own models, or the poster on artificially generated music, which also notes that it is not the first project to make music using deep learning. Would these examples meet the requirement for \"not previously solved\"?",
    "answer": "Good question. It should be clear how your project advances previous work. What gap is your project filling? This doesn't have to be solving a problem that has never been solved. This can also look like solving a well-established problem in a novel way that surpasses previous work. In the music generation poster, it was stated that SOTA was a single LSTM; the researchers tried to advance previous work by hypothesizing that using GAN and Multi-Feature prediction would \"incorporate rhythm and harmony\" in music generation. I've changed the phrasing of this requirement to clarify this (I did not write the original document)",
    "tags": [
      "project"
    ],
    "doc_id": "piazza_qa_9_chunk1",
    "doc_type": "piazza_qa",
    "is_followup": false,
    "parent_doc_id": "piazza_qa_9",
    "chunk_index": 1,
    "total_chunks": 4
  },
  {
    "text": "How strictly original does our project have to be? Many of the example projects seem to be working on \"solved\" problems, such as the Rice Self-Driving Car paper which is explicitly trying to replicate the results of another paper using their own models, or the poster on artificially generated music, which also notes that it is not the first project to make music using deep learning. Would these examples meet the requirement for \"not previously solved\"?  A: Good question.",
    "source": "Piazza Q&A",
    "source_detail": "Piazza Question & Answer",
    "question": "Clarification on Proposal Requirement 2.b.iii\nIn the rubric for the final project proposal, as well as for the project itself, there is a section for \"Is this problem not previously solved\". I would like some clarification on this requirement. How strictly original does our project have to be? Many of the example projects seem to be working on \"solved\" problems, such as the Rice Self-Driving Car paper which is explicitly trying to replicate the results of another paper using their own models, or the poster on artificially generated music, which also notes that it is not the first project to make music using deep learning. Would these examples meet the requirement for \"not previously solved\"?",
    "answer": "Good question. It should be clear how your project advances previous work. What gap is your project filling? This doesn't have to be solving a problem that has never been solved. This can also look like solving a well-established problem in a novel way that surpasses previous work. In the music generation poster, it was stated that SOTA was a single LSTM; the researchers tried to advance previous work by hypothesizing that using GAN and Multi-Feature prediction would \"incorporate rhythm and harmony\" in music generation. I've changed the phrasing of this requirement to clarify this (I did not write the original document)",
    "tags": [
      "project"
    ],
    "doc_id": "piazza_qa_9_chunk2",
    "doc_type": "piazza_qa",
    "is_followup": false,
    "parent_doc_id": "piazza_qa_9",
    "chunk_index": 2,
    "total_chunks": 4
  },
  {
    "text": "It should be clear how your project advances previous work. What gap is your project filling? This doesn't have to be solving a problem that has never been solved. This can also look like solving a well-established problem in a novel way that surpasses previous work.",
    "source": "Piazza Q&A",
    "source_detail": "Piazza Question & Answer",
    "question": "Clarification on Proposal Requirement 2.b.iii\nIn the rubric for the final project proposal, as well as for the project itself, there is a section for \"Is this problem not previously solved\". I would like some clarification on this requirement. How strictly original does our project have to be? Many of the example projects seem to be working on \"solved\" problems, such as the Rice Self-Driving Car paper which is explicitly trying to replicate the results of another paper using their own models, or the poster on artificially generated music, which also notes that it is not the first project to make music using deep learning. Would these examples meet the requirement for \"not previously solved\"?",
    "answer": "Good question. It should be clear how your project advances previous work. What gap is your project filling? This doesn't have to be solving a problem that has never been solved. This can also look like solving a well-established problem in a novel way that surpasses previous work. In the music generation poster, it was stated that SOTA was a single LSTM; the researchers tried to advance previous work by hypothesizing that using GAN and Multi-Feature prediction would \"incorporate rhythm and harmony\" in music generation. I've changed the phrasing of this requirement to clarify this (I did not write the original document)",
    "tags": [
      "project"
    ],
    "doc_id": "piazza_qa_9_chunk3",
    "doc_type": "piazza_qa",
    "is_followup": false,
    "parent_doc_id": "piazza_qa_9",
    "chunk_index": 3,
    "total_chunks": 4
  },
  {
    "text": "In the music generation poster, it was stated that SOTA was a single LSTM; the researchers tried to advance previous work by hypothesizing that using GAN and Multi-Feature prediction would \"incorporate rhythm and harmony\" in music generation. I've changed the phrasing of this requirement to clarify this (I did not write the original document).",
    "source": "Piazza Q&A",
    "source_detail": "Piazza Question & Answer",
    "question": "Clarification on Proposal Requirement 2.b.iii\nIn the rubric for the final project proposal, as well as for the project itself, there is a section for \"Is this problem not previously solved\". I would like some clarification on this requirement. How strictly original does our project have to be? Many of the example projects seem to be working on \"solved\" problems, such as the Rice Self-Driving Car paper which is explicitly trying to replicate the results of another paper using their own models, or the poster on artificially generated music, which also notes that it is not the first project to make music using deep learning. Would these examples meet the requirement for \"not previously solved\"?",
    "answer": "Good question. It should be clear how your project advances previous work. What gap is your project filling? This doesn't have to be solving a problem that has never been solved. This can also look like solving a well-established problem in a novel way that surpasses previous work. In the music generation poster, it was stated that SOTA was a single LSTM; the researchers tried to advance previous work by hypothesizing that using GAN and Multi-Feature prediction would \"incorporate rhythm and harmony\" in music generation. I've changed the phrasing of this requirement to clarify this (I did not write the original document)",
    "tags": [
      "project"
    ],
    "doc_id": "piazza_qa_9_chunk4",
    "doc_type": "piazza_qa",
    "is_followup": false,
    "parent_doc_id": "piazza_qa_9",
    "chunk_index": 4,
    "total_chunks": 4
  },
  {
    "text": "Q: Are we allowed to use AI to translate the proposal content and then cite the AI we used\nDear instructors, Our team has a question about AI usage for the project proposal. One member would like to draft part of the proposal in another language and then translate it into English using an AI tool for convenience. Would this be permitted if we clearly cite the AI tool and the corresponding chat? If not, we are happy to do the translation ourselves. Thank you for your time and guidance!\n\nA: Yes, you can use AI for translation",
    "source": "Piazza Q&A",
    "source_detail": "Piazza Question & Answer",
    "question": "Are we allowed to use AI to translate the proposal content and then cite the AI we used\nDear instructors, Our team has a question about AI usage for the project proposal. One member would like to draft part of the proposal in another language and then translate it into English using an AI tool for convenience. Would this be permitted if we clearly cite the AI tool and the corresponding chat? If not, we are happy to do the translation ourselves. Thank you for your time and guidance!",
    "answer": "Yes, you can use AI for translation",
    "tags": [
      "project"
    ],
    "doc_id": "piazza_qa_10",
    "doc_type": "piazza_qa",
    "is_followup": false
  },
  {
    "text": "Q: Proposal Title Page\nDoes a title page of our proposal count for the page length requirement of 1-4 pages?\n\nA: No, please use the template provided in the logistics document",
    "source": "Piazza Q&A",
    "source_detail": "Piazza Question & Answer",
    "question": "Proposal Title Page\nDoes a title page of our proposal count for the page length requirement of 1-4 pages?",
    "answer": "No, please use the template provided in the logistics document",
    "tags": [
      "project"
    ],
    "doc_id": "piazza_qa_11",
    "doc_type": "piazza_qa",
    "is_followup": false
  },
  {
    "text": "Parent Q: Proposal Title Page\nDoes a title page of our proposal count for the page length requirement of 1-4 pages?\n\nFollowup Q: My I knwo where can we find the template? I did not find it in canvas.\n\nA: Sorry, I forgot to include @109 in my response",
    "source": "Piazza Q&A (Followup)",
    "source_detail": "Piazza Followup Question & Answer",
    "parent_question": "Proposal Title Page\nDoes a title page of our proposal count for the page length requirement of 1-4 pages?",
    "question": "My I knwo where can we find the template? I did not find it in canvas.",
    "answer": "Sorry, I forgot to include @109 in my response",
    "tags": [
      "project"
    ],
    "doc_id": "piazza_qa_12",
    "doc_type": "piazza_qa",
    "is_followup": true
  },
  {
    "text": "Parent Q: Proposal Title Page\nDoes a title page of our proposal count for the page length requirement of 1-4 pages?\n\nFollowup Q: My I knwo where can we find the template? I did not find it in canvas.\n\nA: On my end, the previous examples seemed to follow the IEEE format. Nevertheless, please use the IEEE template",
    "source": "Piazza Q&A (Followup)",
    "source_detail": "Piazza Followup Question & Answer",
    "parent_question": "Proposal Title Page\nDoes a title page of our proposal count for the page length requirement of 1-4 pages?",
    "question": "My I knwo where can we find the template? I did not find it in canvas.",
    "answer": "On my end, the previous examples seemed to follow the IEEE format. Nevertheless, please use the IEEE template",
    "tags": [
      "project"
    ],
    "doc_id": "piazza_qa_13",
    "doc_type": "piazza_qa",
    "is_followup": true
  },
  {
    "text": "Q: Bibliography/references in Proposal\nFor the page count max being 4, does that include the ciatations/references? Or could I have 4 pages of writing/images and then have an additional page for my references?\n\nA: 4 pages of writing/images + additional pages for references",
    "source": "Piazza Q&A",
    "source_detail": "Piazza Question & Answer",
    "question": "Bibliography/references in Proposal\nFor the page count max being 4, does that include the ciatations/references? Or could I have 4 pages of writing/images and then have an additional page for my references?",
    "answer": "4 pages of writing/images + additional pages for references",
    "tags": [
      "project"
    ],
    "doc_id": "piazza_qa_14",
    "doc_type": "piazza_qa",
    "is_followup": false
  },
  {
    "text": "Q: Deliverables for the Final Project Submission\nI have a quick question\u2026 what are all the deliverables for the Final Submission of the project apart from the proposal and the presentation.. like do we need to give any write ups or code repositories or anything as such??\n\nA: Thank you for the reminder, @109",
    "source": "Piazza Q&A",
    "source_detail": "Piazza Question & Answer",
    "question": "Deliverables for the Final Project Submission\nI have a quick question\u2026 what are all the deliverables for the Final Submission of the project apart from the proposal and the presentation.. like do we need to give any write ups or code repositories or anything as such??",
    "answer": "Thank you for the reminder, @109",
    "tags": [
      "project"
    ],
    "doc_id": "piazza_qa_15",
    "doc_type": "piazza_qa",
    "is_followup": false
  },
  {
    "text": "Q: Final Project Model choice\nFor final project, can we finetune existing models or we have to come up with our own models? Thanks\n\nA: Both are acceptable :)",
    "source": "Piazza Q&A",
    "source_detail": "Piazza Question & Answer",
    "question": "Final Project Model choice\nFor final project, can we finetune existing models or we have to come up with our own models? Thanks",
    "answer": "Both are acceptable :)",
    "tags": [
      "project"
    ],
    "doc_id": "piazza_qa_16",
    "doc_type": "piazza_qa",
    "is_followup": false
  },
  {
    "text": "Q: Q1c\nFor Q1c, do we need to visualize at least three hyperparameter combinations, or just one combination?\n\nA: One combination is good",
    "source": "Piazza Q&A",
    "source_detail": "Piazza Question & Answer",
    "question": "Q1c\nFor Q1c, do we need to visualize at least three hyperparameter combinations, or just one combination?",
    "answer": "One combination is good",
    "tags": [
      "assignment2"
    ],
    "doc_id": "piazza_qa_17",
    "doc_type": "piazza_qa",
    "is_followup": false
  },
  {
    "text": "Q: New version of checklist\nHello, Could I know what are the recent changes/updates to the checklist. As I have already submitted and I would just like to know what was there previously but the previous version of the document seems to be removed so I cannot compare to find the new changes of the checklist. Thank you.\n\nA: Let me know if the link @75 works",
    "source": "Piazza Q&A",
    "source_detail": "Piazza Question & Answer",
    "question": "New version of checklist\nHello, Could I know what are the recent changes/updates to the checklist. As I have already submitted and I would just like to know what was there previously but the previous version of the document seems to be removed so I cannot compare to find the new changes of the checklist. Thank you.",
    "answer": "Let me know if the link @75 works",
    "tags": [
      "assignment2"
    ],
    "doc_id": "piazza_qa_18",
    "doc_type": "piazza_qa",
    "is_followup": false
  },
  {
    "text": "Q: Frequent changes on HW2 checklist I noticed that the HW2 checklist has been updated multiple times, and the requirements appear to keep changing. I have just finished revising my work according to the previous updated checklist, only to find that the requirements have changed again. For example, the latest version asks to \u201cstate the quantitative performance difference, e.g., CNN outperformed RNN by X%,\u201d which was never mentioned in the assignment document.",
    "source": "Piazza Q&A",
    "source_detail": "Piazza Question & Answer",
    "question": "Frequent changes on HW2 checklist\nI noticed that the HW2 checklist has been updated multiple times, and the requirements appear to keep changing. I have just finished revising my work according to the previous updated checklist, only to find that the requirements have changed again. For example, the latest version asks to \u201cstate the quantitative performance difference, e.g., CNN outperformed RNN by X%,\u201d which was never mentioned in the assignment document. Adding such requirements on the last day feels unfair to students who submitted earlier. With the deadline only half a day away, this seems unfair to students who have already completed the assignment based on earlier versions. Such requirements should have been finalized much earlier to ensure fairness.",
    "answer": "I apologize for my earlier response. I will not add any further additions/clarifications to the checklist. The motivation for my additions was not to alter the requirements of the assignment, but to provide a clearer understanding of what we expected from you. I did this in response to Piazza questions from students who were unclear about the requirements. This was done to prevent you from losing points due to differing interpretations of the instructions that would cause you to lose points, e.g., I interpreted comparing the CNN and RNN as comparing their performance. I acknowledge that resubmissions are inconvenient, which is why I made a Canvas announcement to warn everyone. Yes, it would have been better if the checklist had been more comprehensive from the start to avoid these clarifying questions in the first place (I wrongly assumed that this was the case since this checklist has been used in several previous iterations of this class).",
    "tags": [
      "assignment2"
    ],
    "doc_id": "piazza_qa_19_chunk1",
    "doc_type": "piazza_qa",
    "is_followup": false,
    "parent_doc_id": "piazza_qa_19",
    "chunk_index": 1,
    "total_chunks": 4
  },
  {
    "text": "Adding such requirements on the last day feels unfair to students who submitted earlier. With the deadline only half a day away, this seems unfair to students who have already completed the assignment based on earlier versions. Such requirements should have been finalized much earlier to ensure fairness.  A: I apologize for my earlier response. I will not add any further additions/clarifications to the checklist.",
    "source": "Piazza Q&A",
    "source_detail": "Piazza Question & Answer",
    "question": "Frequent changes on HW2 checklist\nI noticed that the HW2 checklist has been updated multiple times, and the requirements appear to keep changing. I have just finished revising my work according to the previous updated checklist, only to find that the requirements have changed again. For example, the latest version asks to \u201cstate the quantitative performance difference, e.g., CNN outperformed RNN by X%,\u201d which was never mentioned in the assignment document. Adding such requirements on the last day feels unfair to students who submitted earlier. With the deadline only half a day away, this seems unfair to students who have already completed the assignment based on earlier versions. Such requirements should have been finalized much earlier to ensure fairness.",
    "answer": "I apologize for my earlier response. I will not add any further additions/clarifications to the checklist. The motivation for my additions was not to alter the requirements of the assignment, but to provide a clearer understanding of what we expected from you. I did this in response to Piazza questions from students who were unclear about the requirements. This was done to prevent you from losing points due to differing interpretations of the instructions that would cause you to lose points, e.g., I interpreted comparing the CNN and RNN as comparing their performance. I acknowledge that resubmissions are inconvenient, which is why I made a Canvas announcement to warn everyone. Yes, it would have been better if the checklist had been more comprehensive from the start to avoid these clarifying questions in the first place (I wrongly assumed that this was the case since this checklist has been used in several previous iterations of this class).",
    "tags": [
      "assignment2"
    ],
    "doc_id": "piazza_qa_19_chunk2",
    "doc_type": "piazza_qa",
    "is_followup": false,
    "parent_doc_id": "piazza_qa_19",
    "chunk_index": 2,
    "total_chunks": 4
  },
  {
    "text": "The motivation for my additions was not to alter the requirements of the assignment, but to provide a clearer understanding of what we expected from you. I did this in response to Piazza questions from students who were unclear about the requirements. This was done to prevent you from losing points due to differing interpretations of the instructions that would cause you to lose points, e.g., I interpreted comparing the CNN and RNN as comparing their performance.",
    "source": "Piazza Q&A",
    "source_detail": "Piazza Question & Answer",
    "question": "Frequent changes on HW2 checklist\nI noticed that the HW2 checklist has been updated multiple times, and the requirements appear to keep changing. I have just finished revising my work according to the previous updated checklist, only to find that the requirements have changed again. For example, the latest version asks to \u201cstate the quantitative performance difference, e.g., CNN outperformed RNN by X%,\u201d which was never mentioned in the assignment document. Adding such requirements on the last day feels unfair to students who submitted earlier. With the deadline only half a day away, this seems unfair to students who have already completed the assignment based on earlier versions. Such requirements should have been finalized much earlier to ensure fairness.",
    "answer": "I apologize for my earlier response. I will not add any further additions/clarifications to the checklist. The motivation for my additions was not to alter the requirements of the assignment, but to provide a clearer understanding of what we expected from you. I did this in response to Piazza questions from students who were unclear about the requirements. This was done to prevent you from losing points due to differing interpretations of the instructions that would cause you to lose points, e.g., I interpreted comparing the CNN and RNN as comparing their performance. I acknowledge that resubmissions are inconvenient, which is why I made a Canvas announcement to warn everyone. Yes, it would have been better if the checklist had been more comprehensive from the start to avoid these clarifying questions in the first place (I wrongly assumed that this was the case since this checklist has been used in several previous iterations of this class).",
    "tags": [
      "assignment2"
    ],
    "doc_id": "piazza_qa_19_chunk3",
    "doc_type": "piazza_qa",
    "is_followup": false,
    "parent_doc_id": "piazza_qa_19",
    "chunk_index": 3,
    "total_chunks": 4
  },
  {
    "text": "I acknowledge that resubmissions are inconvenient, which is why I made a Canvas announcement to warn everyone. Yes, it would have been better if the checklist had been more comprehensive from the start to avoid these clarifying questions in the first place (I wrongly assumed that this was the case since this checklist has been used in several previous iterations of this class)..",
    "source": "Piazza Q&A",
    "source_detail": "Piazza Question & Answer",
    "question": "Frequent changes on HW2 checklist\nI noticed that the HW2 checklist has been updated multiple times, and the requirements appear to keep changing. I have just finished revising my work according to the previous updated checklist, only to find that the requirements have changed again. For example, the latest version asks to \u201cstate the quantitative performance difference, e.g., CNN outperformed RNN by X%,\u201d which was never mentioned in the assignment document. Adding such requirements on the last day feels unfair to students who submitted earlier. With the deadline only half a day away, this seems unfair to students who have already completed the assignment based on earlier versions. Such requirements should have been finalized much earlier to ensure fairness.",
    "answer": "I apologize for my earlier response. I will not add any further additions/clarifications to the checklist. The motivation for my additions was not to alter the requirements of the assignment, but to provide a clearer understanding of what we expected from you. I did this in response to Piazza questions from students who were unclear about the requirements. This was done to prevent you from losing points due to differing interpretations of the instructions that would cause you to lose points, e.g., I interpreted comparing the CNN and RNN as comparing their performance. I acknowledge that resubmissions are inconvenient, which is why I made a Canvas announcement to warn everyone. Yes, it would have been better if the checklist had been more comprehensive from the start to avoid these clarifying questions in the first place (I wrongly assumed that this was the case since this checklist has been used in several previous iterations of this class).",
    "tags": [
      "assignment2"
    ],
    "doc_id": "piazza_qa_19_chunk4",
    "doc_type": "piazza_qa",
    "is_followup": false,
    "parent_doc_id": "piazza_qa_19",
    "chunk_index": 4,
    "total_chunks": 4
  },
  {
    "text": "Q: Should we cite our assignment 1 of the course?\nSince part 1 and part 3 of this assignment share the similar structure as assignment 1 part 2, I utilized the data loading, training and testing structure of assignment 1 part 2 for assignment 2's parts 2 and 3. Do we need to cite our previously written assignment?\n\nA: no, you don't need to",
    "source": "Piazza Q&A",
    "source_detail": "Piazza Question & Answer",
    "question": "Should we cite our assignment 1 of the course?\nSince part 1 and part 3 of this assignment share the similar structure as assignment 1 part 2, I utilized the data loading, training and testing structure of assignment 1 part 2 for assignment 2's parts 2 and 3. Do we need to cite our previously written assignment?",
    "answer": "no, you don't need to",
    "tags": [
      "assignment2"
    ],
    "doc_id": "piazza_qa_20",
    "doc_type": "piazza_qa",
    "is_followup": false
  },
  {
    "text": "Q: MNIST or Cifar10 for assignment 2 part 3?\nFor assignment 2 part 3, we're instructed to build and brain an RNN on MNIST. However, the starter code's comment asks us to download and transform cifar10 training / test data. Can I kindly confirm that the comment is indeed wrong, and we should download and transform MNIST for assignment 2 part 3?\n\nA: yes, the comments are wrong, you should use MNIST",
    "source": "Piazza Q&A",
    "source_detail": "Piazza Question & Answer",
    "question": "MNIST or Cifar10 for assignment 2 part 3?\nFor assignment 2 part 3, we're instructed to build and brain an RNN on MNIST. However, the starter code's comment asks us to download and transform cifar10 training / test data. Can I kindly confirm that the comment is indeed wrong, and we should download and transform MNIST for assignment 2 part 3?",
    "answer": "yes, the comments are wrong, you should use MNIST",
    "tags": [
      "assignment2"
    ],
    "doc_id": "piazza_qa_21",
    "doc_type": "piazza_qa",
    "is_followup": false
  },
  {
    "text": "Q: Confusion about parameters results in Part 3\nHi, What is the least number we need to record of results with different hyperparameters in Part 3 (a) and (b)? Additionally, what metrics of the RNN need to be documented in RNN result documented (10 pts) ? Thanks.\n\nA: For Part 3 (a) and \"RNN result documented\": report the train and test accuracy for at least three hyperparameter combinations (including your best combination). I've added this clarification to the checklist. See updated checklist",
    "source": "Piazza Q&A",
    "source_detail": "Piazza Question & Answer",
    "question": "Confusion about parameters results in Part 3\nHi, What is the least number we need to record of results with different hyperparameters in Part 3 (a) and (b)? Additionally, what metrics of the RNN need to be documented in RNN result documented (10 pts) ? Thanks.",
    "answer": "For Part 3 (a) and \"RNN result documented\": report the train and test accuracy for at least three hyperparameter combinations (including your best combination). I've added this clarification to the checklist. See updated checklist",
    "tags": [
      "assignment2"
    ],
    "doc_id": "piazza_qa_22",
    "doc_type": "piazza_qa",
    "is_followup": false
  },
  {
    "text": "Parent Q: Confusion about parameters results in Part 3\nHi, What is the least number we need to record of results with different hyperparameters in Part 3 (a) and (b)? Additionally, what metrics of the RNN need to be documented in RNN result documented (10 pts) ? Thanks.\n\nFollowup Q: Thanks for your clarification. What is the number of hidden units we need to try in Part 3 (b)? In the PDF, it states, \"Also, change the number of hidden units and see how that a\ufb00ects the loss and accuracy.\"\n\nA: It refers to the variable hidden_size in the provided starter code",
    "source": "Piazza Q&A (Followup)",
    "source_detail": "Piazza Followup Question & Answer",
    "parent_question": "Confusion about parameters results in Part 3\nHi, What is the least number we need to record of results with different hyperparameters in Part 3 (a) and (b)? Additionally, what metrics of the RNN need to be documented in RNN result documented (10 pts) ? Thanks.",
    "question": "Thanks for your clarification. What is the number of hidden units we need to try in Part 3 (b)? In the PDF, it states, \"Also, change the number of hidden units and see how that a\ufb00ects the loss and accuracy.\"",
    "answer": "It refers to the variable hidden_size in the provided starter code",
    "tags": [
      "assignment2"
    ],
    "doc_id": "piazza_qa_23",
    "doc_type": "piazza_qa",
    "is_followup": true
  },
  {
    "text": "Parent Q: Confusion about parameters results in Part 3\nHi, What is the least number we need to record of results with different hyperparameters in Part 3 (a) and (b)? Additionally, what metrics of the RNN need to be documented in RNN result documented (10 pts) ? Thanks.\n\nFollowup Q: It was not mentioned initially that for RNN we have to experiment for three different hyperparamters , nor its mentioned in the doc. Do I need to resubmit?\n\nA: Yes, please resubmit before the assignment deadline",
    "source": "Piazza Q&A (Followup)",
    "source_detail": "Piazza Followup Question & Answer",
    "parent_question": "Confusion about parameters results in Part 3\nHi, What is the least number we need to record of results with different hyperparameters in Part 3 (a) and (b)? Additionally, what metrics of the RNN need to be documented in RNN result documented (10 pts) ? Thanks.",
    "question": "It was not mentioned initially that for RNN we have to experiment for three different hyperparamters , nor its mentioned in the doc. Do I need to resubmit?",
    "answer": "Yes, please resubmit before the assignment deadline",
    "tags": [
      "assignment2"
    ],
    "doc_id": "piazza_qa_24",
    "doc_type": "piazza_qa",
    "is_followup": true
  },
  {
    "text": "Parent Q: Confusion about parameters results in Part 3\nHi, What is the least number we need to record of results with different hyperparameters in Part 3 (a) and (b)? Additionally, what metrics of the RNN need to be documented in RNN result documented (10 pts) ? Thanks.\n\nFollowup Q: what parameters do I need to change? optimizer and all right?\n\nA: Ideas for your 3 hyperparameter combinations: \"You should modify the following parameters in the starter code. \u2022 Number of nodes in the hidden layer \u2022 Learning rate \u2022 Number of iterations \u2022 Cost (hint: use softmax cross entropy with logits) \u2022 Optimizer\"",
    "source": "Piazza Q&A (Followup)",
    "source_detail": "Piazza Followup Question & Answer",
    "parent_question": "Confusion about parameters results in Part 3\nHi, What is the least number we need to record of results with different hyperparameters in Part 3 (a) and (b)? Additionally, what metrics of the RNN need to be documented in RNN result documented (10 pts) ? Thanks.",
    "question": "what parameters do I need to change? optimizer and all right?",
    "answer": "Ideas for your 3 hyperparameter combinations: \"You should modify the following parameters in the starter code. \u2022 Number of nodes in the hidden layer \u2022 Learning rate \u2022 Number of iterations \u2022 Cost (hint: use softmax cross entropy with logits) \u2022 Optimizer\"",
    "tags": [
      "assignment2"
    ],
    "doc_id": "piazza_qa_25",
    "doc_type": "piazza_qa",
    "is_followup": true
  },
  {
    "text": "Parent Q: Confusion about parameters results in Part 3 Hi, What is the least number we need to record of results with different hyperparameters in Part 3 (a) and (b)? Additionally, what metrics of the RNN need to be documented in RNN result documented (10 pts) ? Thanks.  Followup Q: and is it okay if I write a new ipynb file for this, coz I have already trained for one set and will just be a problem otherwise?  A: Sorry, I was misreading the assignment.",
    "source": "Piazza Q&A (Followup)",
    "source_detail": "Piazza Followup Question & Answer",
    "parent_question": "Confusion about parameters results in Part 3\nHi, What is the least number we need to record of results with different hyperparameters in Part 3 (a) and (b)? Additionally, what metrics of the RNN need to be documented in RNN result documented (10 pts) ? Thanks.",
    "question": "and is it okay if I write a new ipynb file for this, coz I have already trained for one set and will just be a problem otherwise?",
    "answer": "Sorry, I was misreading the assignment. Since the assignment didn't explicitly ask to report performance for different hyperparameters of your RNN, I have decided to remove this requirement from the checklist. You only need to report the performance of your (best) RNN, which I suspect everyone was already doing in order to answer the last question comparing RNN vs CNN. Hopefully, this means you won't have to resubmit Since the assignment did explicitly ask to \"change the number of hidden units and see how that affects the loss and accuracy\", I have included this in the checklist.",
    "tags": [
      "assignment2"
    ],
    "doc_id": "piazza_qa_26_chunk1",
    "doc_type": "piazza_qa",
    "is_followup": true,
    "parent_doc_id": "piazza_qa_26",
    "chunk_index": 1,
    "total_chunks": 3
  },
  {
    "text": "Since the assignment didn't explicitly ask to report performance for different hyperparameters of your RNN, I have decided to remove this requirement from the checklist. You only need to report the performance of your (best) RNN, which I suspect everyone was already doing in order to answer the last question comparing RNN vs CNN.",
    "source": "Piazza Q&A (Followup)",
    "source_detail": "Piazza Followup Question & Answer",
    "parent_question": "Confusion about parameters results in Part 3\nHi, What is the least number we need to record of results with different hyperparameters in Part 3 (a) and (b)? Additionally, what metrics of the RNN need to be documented in RNN result documented (10 pts) ? Thanks.",
    "question": "and is it okay if I write a new ipynb file for this, coz I have already trained for one set and will just be a problem otherwise?",
    "answer": "Sorry, I was misreading the assignment. Since the assignment didn't explicitly ask to report performance for different hyperparameters of your RNN, I have decided to remove this requirement from the checklist. You only need to report the performance of your (best) RNN, which I suspect everyone was already doing in order to answer the last question comparing RNN vs CNN. Hopefully, this means you won't have to resubmit Since the assignment did explicitly ask to \"change the number of hidden units and see how that affects the loss and accuracy\", I have included this in the checklist.",
    "tags": [
      "assignment2"
    ],
    "doc_id": "piazza_qa_26_chunk2",
    "doc_type": "piazza_qa",
    "is_followup": true,
    "parent_doc_id": "piazza_qa_26",
    "chunk_index": 2,
    "total_chunks": 3
  },
  {
    "text": "Hopefully, this means you won't have to resubmit Since the assignment did explicitly ask to \"change the number of hidden units and see how that affects the loss and accuracy\", I have included this in the checklist..",
    "source": "Piazza Q&A (Followup)",
    "source_detail": "Piazza Followup Question & Answer",
    "parent_question": "Confusion about parameters results in Part 3\nHi, What is the least number we need to record of results with different hyperparameters in Part 3 (a) and (b)? Additionally, what metrics of the RNN need to be documented in RNN result documented (10 pts) ? Thanks.",
    "question": "and is it okay if I write a new ipynb file for this, coz I have already trained for one set and will just be a problem otherwise?",
    "answer": "Sorry, I was misreading the assignment. Since the assignment didn't explicitly ask to report performance for different hyperparameters of your RNN, I have decided to remove this requirement from the checklist. You only need to report the performance of your (best) RNN, which I suspect everyone was already doing in order to answer the last question comparing RNN vs CNN. Hopefully, this means you won't have to resubmit Since the assignment did explicitly ask to \"change the number of hidden units and see how that affects the loss and accuracy\", I have included this in the checklist.",
    "tags": [
      "assignment2"
    ],
    "doc_id": "piazza_qa_26_chunk3",
    "doc_type": "piazza_qa",
    "is_followup": true,
    "parent_doc_id": "piazza_qa_26",
    "chunk_index": 3,
    "total_chunks": 3
  },
  {
    "text": "Parent Q: Confusion about parameters results in Part 3\nHi, What is the least number we need to record of results with different hyperparameters in Part 3 (a) and (b)? Additionally, what metrics of the RNN need to be documented in RNN result documented (10 pts) ? Thanks.\n\nFollowup Q: Yeah then is it okay if I have only used one hyperparameter combination to train the RNN right? I am not sure if I can classify that as the best model but I got a good accuracy, but here's the thing we wont exactly know which our best model is unless we have explicitly tried different combination, cause idk that seems bit weird!\n\nA: Yes, one hyperparameter combination is good. I've rephrased this to be more clear \"Report Train and test accuracy for your RNN\".",
    "source": "Piazza Q&A (Followup)",
    "source_detail": "Piazza Followup Question & Answer",
    "parent_question": "Confusion about parameters results in Part 3\nHi, What is the least number we need to record of results with different hyperparameters in Part 3 (a) and (b)? Additionally, what metrics of the RNN need to be documented in RNN result documented (10 pts) ? Thanks.",
    "question": "Yeah then is it okay if I have only used one hyperparameter combination to train the RNN right? I am not sure if I can classify that as the best model but I got a good accuracy, but here's the thing we wont exactly know which our best model is unless we have explicitly tried different combination, cause idk that seems bit weird!",
    "answer": "Yes, one hyperparameter combination is good. I've rephrased this to be more clear \"Report Train and test accuracy for your RNN\".",
    "tags": [
      "assignment2"
    ],
    "doc_id": "piazza_qa_27",
    "doc_type": "piazza_qa",
    "is_followup": true
  },
  {
    "text": "Parent Q: Confusion about parameters results in Part 3\nHi, What is the least number we need to record of results with different hyperparameters in Part 3 (a) and (b)? Additionally, what metrics of the RNN need to be documented in RNN result documented (10 pts) ? Thanks.\n\nFollowup Q: Moreover in the document it explicitly asked us to compare different hidden units for only GRUs and LSTMs, is it okay of I have done only for these two..... coz anyways in RNN we only used one set of hyper parameters.\n\nA: Sorry, that was a typo, thank you for catching. Only need to compare number of hidden units for LSTM and GRU",
    "source": "Piazza Q&A (Followup)",
    "source_detail": "Piazza Followup Question & Answer",
    "parent_question": "Confusion about parameters results in Part 3\nHi, What is the least number we need to record of results with different hyperparameters in Part 3 (a) and (b)? Additionally, what metrics of the RNN need to be documented in RNN result documented (10 pts) ? Thanks.",
    "question": "Moreover in the document it explicitly asked us to compare different hidden units for only GRUs and LSTMs, is it okay of I have done only for these two..... coz anyways in RNN we only used one set of hyper parameters.",
    "answer": "Sorry, that was a typo, thank you for catching. Only need to compare number of hidden units for LSTM and GRU",
    "tags": [
      "assignment2"
    ],
    "doc_id": "piazza_qa_28",
    "doc_type": "piazza_qa",
    "is_followup": true
  },
  {
    "text": "Parent Q: Confusion about parameters results in Part 3\nHi, What is the least number we need to record of results with different hyperparameters in Part 3 (a) and (b)? Additionally, what metrics of the RNN need to be documented in RNN result documented (10 pts) ? Thanks.\n\nFollowup Q: And sorry but one last question the comparison (RNN vs CNN) and (LSTM/GRU vs RNN) questions, both can be qualitative right?\n\nA: Please see updated checklist",
    "source": "Piazza Q&A (Followup)",
    "source_detail": "Piazza Followup Question & Answer",
    "parent_question": "Confusion about parameters results in Part 3\nHi, What is the least number we need to record of results with different hyperparameters in Part 3 (a) and (b)? Additionally, what metrics of the RNN need to be documented in RNN result documented (10 pts) ? Thanks.",
    "question": "And sorry but one last question the comparison (RNN vs CNN) and (LSTM/GRU vs RNN) questions, both can be qualitative right?",
    "answer": "Please see updated checklist",
    "tags": [
      "assignment2"
    ],
    "doc_id": "piazza_qa_29",
    "doc_type": "piazza_qa",
    "is_followup": true
  },
  {
    "text": "Q: Techniques to get bouns points in Part 2\nHi, Can we use Occlusion Sensitivity Analysis to visualize features in Part 2? Thanks\n\nA: Yes, occlusion sensitivity is one of the techniques stated in the paper referenced in the instructions \"Apply one of the techniques discussed in the Visualizing and Understanding Convolutional Networks paper on the convnet trained in Problem 1.\"",
    "source": "Piazza Q&A",
    "source_detail": "Piazza Question & Answer",
    "question": "Techniques to get bouns points in Part 2\nHi, Can we use Occlusion Sensitivity Analysis to visualize features in Part 2? Thanks",
    "answer": "Yes, occlusion sensitivity is one of the techniques stated in the paper referenced in the instructions \"Apply one of the techniques discussed in the Visualizing and Understanding Convolutional Networks paper on the convnet trained in Problem 1.\"",
    "tags": [
      "assignment2"
    ],
    "doc_id": "piazza_qa_30",
    "doc_type": "piazza_qa",
    "is_followup": false
  },
  {
    "text": "Q: Hyperparameters in report\nHello, Do we need to report all hyperparameter combinations and their related results? Or just report one hyperparameter combination with higher than 55% accuracy? Thanks.\n\nA: From the checklist \"For at least three hyperparameter combinations (including your best combination)\". Also, please make your post public to help your classmates.",
    "source": "Piazza Q&A",
    "source_detail": "Piazza Question & Answer",
    "question": "Hyperparameters in report\nHello, Do we need to report all hyperparameter combinations and their related results? Or just report one hyperparameter combination with higher than 55% accuracy? Thanks.",
    "answer": "From the checklist \"For at least three hyperparameter combinations (including your best combination)\". Also, please make your post public to help your classmates.",
    "tags": [
      "assignment2"
    ],
    "doc_id": "piazza_qa_31",
    "doc_type": "piazza_qa",
    "is_followup": false
  },
  {
    "text": "Q: A2 Pt. 1 Configuration Change?\nDid the numbers in the instruction configuration for A2 part 1 change? For example, it used to be that: Convolutional layer 1 had 32 filters and convolutional layer 2 had 64 filters. Now it's 6 and 16. Fully connected layer 1 had input 7*7*64, output 1024. Now it's 5*5*16 and 120. Should we still do a tanh after the first fully connected layer as in the starter code? (And, more generally, should we do it after each fully connected layer, of which there are now 3?)\n\nA: Yes, you can continue the assignment with the previous setting. The updated structure is based on the original LeNet. The instructions only provided a reference for the network structure. You\u2019re encouraged to experiment with different settings\u2014such as the number of output channels, dropout layers, activation functions, learning rates, etc.",
    "source": "Piazza Q&A",
    "source_detail": "Piazza Question & Answer",
    "question": "A2 Pt. 1 Configuration Change?\nDid the numbers in the instruction configuration for A2 part 1 change? For example, it used to be that: Convolutional layer 1 had 32 filters and convolutional layer 2 had 64 filters. Now it's 6 and 16. Fully connected layer 1 had input 7*7*64, output 1024. Now it's 5*5*16 and 120. Should we still do a tanh after the first fully connected layer as in the starter code? (And, more generally, should we do it after each fully connected layer, of which there are now 3?)",
    "answer": "Yes, you can continue the assignment with the previous setting. The updated structure is based on the original LeNet. The instructions only provided a reference for the network structure. You\u2019re encouraged to experiment with different settings\u2014such as the number of output channels, dropout layers, activation functions, learning rates, etc.",
    "tags": [
      "assignment2"
    ],
    "doc_id": "piazza_qa_32",
    "doc_type": "piazza_qa",
    "is_followup": false
  },
  {
    "text": "Q: AI usage?\nI'm aware that we are suppose to deliver our own code, but just wondering for trivial part (like logging and formatting plot), can we use AI code? Thanks\n\nA: Dr Patel has decided that generative AI can not be used for any part of HW2",
    "source": "Piazza Q&A",
    "source_detail": "Piazza Question & Answer",
    "question": "AI usage?\nI'm aware that we are suppose to deliver our own code, but just wondering for trivial part (like logging and formatting plot), can we use AI code? Thanks",
    "answer": "Dr Patel has decided that generative AI can not be used for any part of HW2",
    "tags": [
      "assignment2"
    ],
    "doc_id": "piazza_qa_33",
    "doc_type": "piazza_qa",
    "is_followup": false
  },
  {
    "text": "Q: learning rate in part2\nCan we change lr in the assignment#2 part2?\n\nA: By part 2, I assume you don't mean \"Q2: Visualizing and Understanding Convolutional Networks\"? For Part 1 (Visualizing a CNN with CIFAR10) and Part 3 (Build and Train an RNN on MNIST), learning rates are stated as a hyperparameter you should tune (i.e., Yes)",
    "source": "Piazza Q&A",
    "source_detail": "Piazza Question & Answer",
    "question": "learning rate in part2\nCan we change lr in the assignment#2 part2?",
    "answer": "By part 2, I assume you don't mean \"Q2: Visualizing and Understanding Convolutional Networks\"? For Part 1 (Visualizing a CNN with CIFAR10) and Part 3 (Build and Train an RNN on MNIST), learning rates are stated as a hyperparameter you should tune (i.e., Yes)",
    "tags": [
      "assignment2"
    ],
    "doc_id": "piazza_qa_34",
    "doc_type": "piazza_qa",
    "is_followup": false
  },
  {
    "text": "Q: Is this a Typo in Assignment 2?\nIt says the third fully connected layer has an input dimension of 120, while the output dimension of the second feed forward layer is 84. Shouldn't it be 84 in terms of the input dimension of the third fc?\n\nA: It was a typo, I\u2019ve updated the instructions. Thanks for pointing it out.",
    "source": "Piazza Q&A",
    "source_detail": "Piazza Question & Answer",
    "question": "Is this a Typo in Assignment 2?\nIt says the third fully connected layer has an input dimension of 120, while the output dimension of the second feed forward layer is 84. Shouldn't it be 84 in terms of the input dimension of the third fc?",
    "answer": "It was a typo, I\u2019ve updated the instructions. Thanks for pointing it out.",
    "tags": [
      "assignment2"
    ],
    "doc_id": "piazza_qa_35",
    "doc_type": "piazza_qa",
    "is_followup": false
  },
  {
    "text": "Q: size of image\nI'd like to confirm the image size requirements for Assignment 2. The instructions state that the CIFAR10 images should be 28\u00d728 grayscale images, but the original data is 32\u00d732. Should we scale the images to 28\u00d728, or keep the original 32\u00d732 for training the CNN?\n\nA: If you import with torch dataset, the images are RGB, and the resolution is 32 x 32. If you import from the zip folder, the images are grayscale and of size 28 x 28. You will need to modify the network architecture according to your preferred method of importing the dataset.",
    "source": "Piazza Q&A",
    "source_detail": "Piazza Question & Answer",
    "question": "size of image\nI'd like to confirm the image size requirements for Assignment 2. The instructions state that the CIFAR10 images should be 28\u00d728 grayscale images, but the original data is 32\u00d732. Should we scale the images to 28\u00d728, or keep the original 32\u00d732 for training the CNN?",
    "answer": "If you import with torch dataset, the images are RGB, and the resolution is 32 x 32. If you import from the zip folder, the images are grayscale and of size 28 x 28. You will need to modify the network architecture according to your preferred method of importing the dataset.",
    "tags": [
      "assignment2"
    ],
    "doc_id": "piazza_qa_36",
    "doc_type": "piazza_qa",
    "is_followup": false
  },
  {
    "text": "Q: one-hot\nIf I use CrossEntropyLoss, do I still need to use one-hot?\n\nA: Yes, use cross entropy (CE) with one-hot encoding. To give you an example, let's say the ground truth label is '2'. After one hot encoding, the ground truth label then becomes # corresponding label '0' '1' '2' '3' '9' one_hot = [0, 0, 1, 0, ..., 0] Let's say after softmax, your model prediction is [0.2, 0.4, ...]. Simply run CE between the prediction and one-hot encoded ground truth to obtain CE loss. To Anonymous Atom -- I realized the explanation that I gave during my office hour is a bit confusing, use the answer above instead.",
    "source": "Piazza Q&A",
    "source_detail": "Piazza Question & Answer",
    "question": "one-hot\nIf I use CrossEntropyLoss, do I still need to use one-hot?",
    "answer": "Yes, use cross entropy (CE) with one-hot encoding. To give you an example, let's say the ground truth label is '2'. After one hot encoding, the ground truth label then becomes # corresponding label '0' '1' '2' '3' '9' one_hot = [0, 0, 1, 0, ..., 0] Let's say after softmax, your model prediction is [0.2, 0.4, ...]. Simply run CE between the prediction and one-hot encoded ground truth to obtain CE loss. To Anonymous Atom -- I realized the explanation that I gave during my office hour is a bit confusing, use the answer above instead.",
    "tags": [
      "assignment2"
    ],
    "doc_id": "piazza_qa_37",
    "doc_type": "piazza_qa",
    "is_followup": false
  },
  {
    "text": "Q: Question regarding question 1 part c\nWhat are the statistics that we should include about activation for question 1, part c?\n\nA: For each convolution layer, produce a singular figure visualizing the activation mean and standard deviation for each filter (x axis = filter number, y axis is activation, each filter has its own barchart box plot ). Overall, you should have two figures, each with N barcharts boxplots , N = layer's number of filters @74_f4",
    "source": "Piazza Q&A",
    "source_detail": "Piazza Question & Answer",
    "question": "Question regarding question 1 part c\nWhat are the statistics that we should include about activation for question 1, part c?",
    "answer": "For each convolution layer, produce a singular figure visualizing the activation mean and standard deviation for each filter (x axis = filter number, y axis is activation, each filter has its own barchart box plot ). Overall, you should have two figures, each with N barcharts boxplots , N = layer's number of filters @74_f4",
    "tags": [
      "assignment2"
    ],
    "doc_id": "piazza_qa_38",
    "doc_type": "piazza_qa",
    "is_followup": false
  },
  {
    "text": "Parent Q: Question regarding question 1 part c\nWhat are the statistics that we should include about activation for question 1, part c?\n\nFollowup Q: (In general, my question is, should we draw box plots of means and stds, or draw box plots of the original activitions? If it is the former one, how should we group the activitions to calculate means and stds?)\n\nA: Please plot bar charts of the original activations, where the error bars indicate standard deviations. I'd explore the plt.bar() documentation https://towardsdatascience.com/error-bar-plots-from-a-data-frame-using-matplotlib-53026fe95491/ . Boxplots of the original activations will be accepted, as that is what I originally wrote, even though boxplots typically indicate quartiles and medians instead of means and standard deviations.",
    "source": "Piazza Q&A (Followup)",
    "source_detail": "Piazza Followup Question & Answer",
    "parent_question": "Question regarding question 1 part c\nWhat are the statistics that we should include about activation for question 1, part c?",
    "question": "(In general, my question is, should we draw box plots of means and stds, or draw box plots of the original activitions? If it is the former one, how should we group the activitions to calculate means and stds?)",
    "answer": "Please plot bar charts of the original activations, where the error bars indicate standard deviations. I'd explore the plt.bar() documentation https://towardsdatascience.com/error-bar-plots-from-a-data-frame-using-matplotlib-53026fe95491/ . Boxplots of the original activations will be accepted, as that is what I originally wrote, even though boxplots typically indicate quartiles and medians instead of means and standard deviations.",
    "tags": [
      "assignment2"
    ],
    "doc_id": "piazza_qa_39",
    "doc_type": "piazza_qa",
    "is_followup": true
  },
  {
    "text": "Q: Assignment 1 score\nIs the assignment 1 score publish?\n\nA: Only 3 of 7 TAs have completed their HW1 grading so far, which means grades are not available yet for everyone. I'll follow up with the TAs who haven't completed their grading yet, apologies for the delay",
    "source": "Piazza Q&A",
    "source_detail": "Piazza Question & Answer",
    "question": "Assignment 1 score\nIs the assignment 1 score publish?",
    "answer": "Only 3 of 7 TAs have completed their HW1 grading so far, which means grades are not available yet for everyone. I'll follow up with the TAs who haven't completed their grading yet, apologies for the delay",
    "tags": [
      "assignment1"
    ],
    "doc_id": "piazza_qa_40",
    "doc_type": "piazza_qa",
    "is_followup": false
  },
  {
    "text": "Q: Assignment 2 Release Date\nWhen will assignment 2 be released? On the course website it says that it should have been available on Wednesday, but it is still not on Canvas. Since we are given two weeks to complete our assignments, I would assume assignment 2 would be due two weeks after it is released on Canvas.\n\nA: Sorry for the delay. HW2 should be available by tomorrow morning, and we will adjust the deadline accordingly",
    "source": "Piazza Q&A",
    "source_detail": "Piazza Question & Answer",
    "question": "Assignment 2 Release Date\nWhen will assignment 2 be released? On the course website it says that it should have been available on Wednesday, but it is still not on Canvas. Since we are given two weeks to complete our assignments, I would assume assignment 2 would be due two weeks after it is released on Canvas.",
    "answer": "Sorry for the delay. HW2 should be available by tomorrow morning, and we will adjust the deadline accordingly",
    "tags": [
      "assignment2"
    ],
    "doc_id": "piazza_qa_41",
    "doc_type": "piazza_qa",
    "is_followup": false
  },
  {
    "text": "Q: Clarification on the &#34;layer size&#34; for problem f in assignment 1 part 1\nFor question f in assignment 1 part 1, the spec claims that \"Your code must be able to accept as parameters (1) the number of layers and (2) layer size\". In this case, for our DeepNeuralNetwork, should we expect a parameter as a list of integers which are the size of each layer correspondingly?\n\nA: Yes, a parameter should be a list of sizes for the layers in the network.",
    "source": "Piazza Q&A",
    "source_detail": "Piazza Question & Answer",
    "question": "Clarification on the &#34;layer size&#34; for problem f in assignment 1 part 1\nFor question f in assignment 1 part 1, the spec claims that \"Your code must be able to accept as parameters (1) the number of layers and (2) layer size\". In this case, for our DeepNeuralNetwork, should we expect a parameter as a list of integers which are the size of each layer correspondingly?",
    "answer": "Yes, a parameter should be a list of sizes for the layers in the network.",
    "tags": [
      "assignment1"
    ],
    "doc_id": "piazza_qa_42",
    "doc_type": "piazza_qa",
    "is_followup": false
  },
  {
    "text": "Q: Should we consider summation and N when deriving the derivatives?\nProblem 1d in part 1 asks us to derive the derivative of W1, b1, W2, b2 relative to the loss function. To be honest I got a bit confused about whether we should take the summation into account, and if that's the case, how to solve the problem. If we only have to start with calculating the derivative of y * log y_hat without considering the summation and the denominator N, it would be rather easier. Otherwise, we are not sure about how to compute the derivative of a scalar over a vector, and how to deal with individual entry. Screenshot_2025-10-15_at_6.39.07_PM.png\n\nA: Just the relationship between the layers. Piazza post @36 would help you.",
    "source": "Piazza Q&A",
    "source_detail": "Piazza Question & Answer",
    "question": "Should we consider summation and N when deriving the derivatives?\nProblem 1d in part 1 asks us to derive the derivative of W1, b1, W2, b2 relative to the loss function. To be honest I got a bit confused about whether we should take the summation into account, and if that's the case, how to solve the problem. If we only have to start with calculating the derivative of y * log y_hat without considering the summation and the denominator N, it would be rather easier. Otherwise, we are not sure about how to compute the derivative of a scalar over a vector, and how to deal with individual entry. Screenshot_2025-10-15_at_6.39.07_PM.png",
    "answer": "Just the relationship between the layers. Piazza post @36 would help you.",
    "tags": [
      "assignment1"
    ],
    "doc_id": "piazza_qa_43",
    "doc_type": "piazza_qa",
    "is_followup": false
  },
  {
    "text": "Q: question on 2b\nFor question 2b weights and biases, do we need to include all figures, e.g. weights figures of conv1, conv2, fc1, fc2? And for each we need to include max, min, std, mean, and histogram, correct? Thank you.\n\nA: Yes, that's correct @24",
    "source": "Piazza Q&A",
    "source_detail": "Piazza Question & Answer",
    "question": "question on 2b\nFor question 2b weights and biases, do we need to include all figures, e.g. weights figures of conv1, conv2, fc1, fc2? And for each we need to include max, min, std, mean, and histogram, correct? Thank you.",
    "answer": "Yes, that's correct @24",
    "tags": [
      "assignment1"
    ],
    "doc_id": "piazza_qa_44",
    "doc_type": "piazza_qa",
    "is_followup": false
  },
  {
    "text": "Q: A1 1b.2 and 1d.1 Clarification\nFor these parts asking to derive mathematically, do we need to show the step by step process to get there. Or can we simply put in a Jupyter text cell the final calculation? For example: 1b.2 d/dz tanh(z) = ... d/dz sigmoid(z) = ... d/dz relu(z) = ... 1d.1 dL/dW2 = ... dL/db2 = ... dL/dW1 = ... dL/db1 = ... Would this be sufficient for these parts, or should we show the step by step process for each equation?\n\nA: Fo 1.b.2: yes (see @34_f2 for formatting) For 1.d.1: @36",
    "source": "Piazza Q&A",
    "source_detail": "Piazza Question & Answer",
    "question": "A1 1b.2 and 1d.1 Clarification\nFor these parts asking to derive mathematically, do we need to show the step by step process to get there. Or can we simply put in a Jupyter text cell the final calculation? For example: 1b.2 d/dz tanh(z) = ... d/dz sigmoid(z) = ... d/dz relu(z) = ... 1d.1 dL/dW2 = ... dL/db2 = ... dL/dW1 = ... dL/db1 = ... Would this be sufficient for these parts, or should we show the step by step process for each equation?",
    "answer": "Fo 1.b.2: yes (see @34_f2 for formatting) For 1.d.1: @36",
    "tags": [
      "assignment1"
    ],
    "doc_id": "piazza_qa_45",
    "doc_type": "piazza_qa",
    "is_followup": false
  },
  {
    "text": "Q: Are there any suggestions on the environment to use for the assignment?\nThe assignment 1's spec seem to didn't include any suggestion or request about the environmental setup. Are we allowed to set up the environment based on our need, or there's indeed an environmental requirement that I didn't notice?\n\nA: No environmental requirement",
    "source": "Piazza Q&A",
    "source_detail": "Piazza Question & Answer",
    "question": "Are there any suggestions on the environment to use for the assignment?\nThe assignment 1's spec seem to didn't include any suggestion or request about the environmental setup. Are we allowed to set up the environment based on our need, or there's indeed an environmental requirement that I didn't notice?",
    "answer": "No environmental requirement",
    "tags": [
      "assignment1"
    ],
    "doc_id": "piazza_qa_46",
    "doc_type": "piazza_qa",
    "is_followup": false
  },
  {
    "text": "Q: 2.b. Question\nHi, I noticed the instruction says \u201cmonitor the test and validation error after each 1100 iterations (equivalently, after each epoch).\u201d But since one epoch is about 860 iterations for 55,000 training samples with a batch size of 64, should I check the errors every 1100 iterations or at the end of each epoch ?\n\nA: Good question, end of each epoch",
    "source": "Piazza Q&A",
    "source_detail": "Piazza Question & Answer",
    "question": "2.b. Question\nHi, I noticed the instruction says \u201cmonitor the test and validation error after each 1100 iterations (equivalently, after each epoch).\u201d But since one epoch is about 860 iterations for 55,000 training samples with a batch size of 64, should I check the errors every 1100 iterations or at the end of each epoch ?",
    "answer": "Good question, end of each epoch",
    "tags": [
      "assignment1"
    ],
    "doc_id": "piazza_qa_47",
    "doc_type": "piazza_qa",
    "is_followup": false
  },
  {
    "text": "Q: Late Day Usage\nHi Instructors, We have two late days. Do we have to declare that we are using them? Or do we just turn the assignment in late?\n\nA: You don't need to declare. Canvas conveniently tells the instruction staff how late your assignment is.",
    "source": "Piazza Q&A",
    "source_detail": "Piazza Question & Answer",
    "question": "Late Day Usage\nHi Instructors, We have two late days. Do we have to declare that we are using them? Or do we just turn the assignment in late?",
    "answer": "You don't need to declare. Canvas conveniently tells the instruction staff how late your assignment is.",
    "tags": [
      "assignment1"
    ],
    "doc_id": "piazza_qa_48",
    "doc_type": "piazza_qa",
    "is_followup": false
  },
  {
    "text": "Parent Q: Late Day Usage\nHi Instructors, We have two late days. Do we have to declare that we are using them? Or do we just turn the assignment in late?\n\nFollowup Q: What is two late days?\n\nA: From the class website : Late Policy: 2 late days in total are allocated across all 3 assignments, after that 25% penalty per day Note that if you submit an assignment 0.01 days late, that counts as one whole late day.",
    "source": "Piazza Q&A (Followup)",
    "source_detail": "Piazza Followup Question & Answer",
    "parent_question": "Late Day Usage\nHi Instructors, We have two late days. Do we have to declare that we are using them? Or do we just turn the assignment in late?",
    "question": "What is two late days?",
    "answer": "From the class website : Late Policy: 2 late days in total are allocated across all 3 assignments, after that 25% penalty per day Note that if you submit an assignment 0.01 days late, that counts as one whole late day.",
    "tags": [
      "assignment1"
    ],
    "doc_id": "piazza_qa_49",
    "doc_type": "piazza_qa",
    "is_followup": true
  },
  {
    "text": "Q: Report requirements for Q2c\nDo we also need to paste all the figures same as Q2 a and b for each configuration in Q2c? That would be a really large number of figures because I tried a lot of different configurations in Q2c. Edit: I just found that I can plot the lines with different configurations in one chart. Sorry for not noticing this before. Is this what expected in Q2c?\n\nA: For Q2c, produce all the plots for only one combination of your choice (sorry, I didn't realize @48 was private but I have made that public now)",
    "source": "Piazza Q&A",
    "source_detail": "Piazza Question & Answer",
    "question": "Report requirements for Q2c\nDo we also need to paste all the figures same as Q2 a and b for each configuration in Q2c? That would be a really large number of figures because I tried a lot of different configurations in Q2c. Edit: I just found that I can plot the lines with different configurations in one chart. Sorry for not noticing this before. Is this what expected in Q2c?",
    "answer": "For Q2c, produce all the plots for only one combination of your choice (sorry, I didn't realize @48 was private but I have made that public now)",
    "tags": [
      "assignment1"
    ],
    "doc_id": "piazza_qa_50",
    "doc_type": "piazza_qa",
    "is_followup": false
  },
  {
    "text": "Q: 2.b question\nI read the assignment#1 grading rubric, and I saw that the test and validation error after each 1100 iterations [4 pts] (equivalently, after each epoch). Do we need to do this? Because the response for @40 says that we don't have to do this.\n\nA: You're correct, I removed the mention of validation from that section of the grading rubric",
    "source": "Piazza Q&A",
    "source_detail": "Piazza Question & Answer",
    "question": "2.b question\nI read the assignment#1 grading rubric, and I saw that the test and validation error after each 1100 iterations [4 pts] (equivalently, after each epoch). Do we need to do this? Because the response for @40 says that we don't have to do this.",
    "answer": "You're correct, I removed the mention of validation from that section of the grading rubric",
    "tags": [
      "assignment1"
    ],
    "doc_id": "piazza_qa_51",
    "doc_type": "piazza_qa",
    "is_followup": false
  },
  {
    "text": "Q: Regarding Q2 c\nI have made different combinations of activation functions, initialisation techniques and training algorithms, and have trained my model. For the report part I have generated scalars that show train loss, test accuracy and loss, and validation accuracy and loss. Will that meet the checklist requirement. I haven\u2019t generated histograms weights for each layers as it would have been too much. please let me know\n\nA: No, please generate histogram weights for one particular combination, e.g., tanh, random initialization, and SGD. To help your fellow students, please consider making this post public.",
    "source": "Piazza Q&A",
    "source_detail": "Piazza Question & Answer",
    "question": "Regarding Q2 c\nI have made different combinations of activation functions, initialisation techniques and training algorithms, and have trained my model. For the report part I have generated scalars that show train loss, test accuracy and loss, and validation accuracy and loss. Will that meet the checklist requirement. I haven\u2019t generated histograms weights for each layers as it would have been too much. please let me know",
    "answer": "No, please generate histogram weights for one particular combination, e.g., tanh, random initialization, and SGD. To help your fellow students, please consider making this post public.",
    "tags": [
      "assignment1"
    ],
    "doc_id": "piazza_qa_52",
    "doc_type": "piazza_qa",
    "is_followup": false
  },
  {
    "text": "Q: 2.c\nFor part 2.C of the assignment, I want to confirm whether we are expected to run and report all combinations of activations, initializations, and optimizers, or if a representative subset is acceptable.\n\nA: Yes, a subset is good. According to the rubric, you only need to train the network with at least one change, see below. Rubric for that question: Completion of running the network training with at least one other configuration [3 pts] (can include different nonlinearities (tanh, sigmoid, leaky-ReLU, MaxOut,...), initialization techniques (Xavier...) and training algorithms (SGD, Momentum-based Methods, Adagrad..)) Inclusion of resultant figures [3pts]",
    "source": "Piazza Q&A",
    "source_detail": "Piazza Question & Answer",
    "question": "2.c\nFor part 2.C of the assignment, I want to confirm whether we are expected to run and report all combinations of activations, initializations, and optimizers, or if a representative subset is acceptable.",
    "answer": "Yes, a subset is good. According to the rubric, you only need to train the network with at least one change, see below. Rubric for that question: Completion of running the network training with at least one other configuration [3 pts] (can include different nonlinearities (tanh, sigmoid, leaky-ReLU, MaxOut,...), initialization techniques (Xavier...) and training algorithms (SGD, Momentum-based Methods, Adagrad..)) Inclusion of resultant figures [3pts]",
    "tags": [
      "assignment1"
    ],
    "doc_id": "piazza_qa_53",
    "doc_type": "piazza_qa",
    "is_followup": false
  },
  {
    "text": "Q: question about Relu\nWhen choose Relu as the activation function, the entire background of result is a single color. The network predicts the same class across the whole grid and has learned virtually no separable boundary. How to due with this problem? Thanks.\n\nA: It looks like ReLU units are \u201cdying\u201d so the hidden layer outputs are mostly zeros, which makes the network predict a single class. Try He initialization for ReLU, set a small positive bias (e.g., 0.1), lower the learning rate, and reduce L2 weight decay.",
    "source": "Piazza Q&A",
    "source_detail": "Piazza Question & Answer",
    "question": "question about Relu\nWhen choose Relu as the activation function, the entire background of result is a single color. The network predicts the same class across the whole grid and has learned virtually no separable boundary. How to due with this problem? Thanks.",
    "answer": "It looks like ReLU units are \u201cdying\u201d so the hidden layer outputs are mostly zeros, which makes the network predict a single class. Try He initialization for ReLU, set a small positive bias (e.g., 0.1), lower the learning rate, and reduce L2 weight decay.",
    "tags": [
      "assignment1"
    ],
    "doc_id": "piazza_qa_54",
    "doc_type": "piazza_qa",
    "is_followup": false
  },
  {
    "text": "Q: Question about DCN structure\nI have a question regarding how to interpret the DCN model structure: conv1(5-5-1-32) - ReLU - maxpool(2-2) - conv2(5-5-32-64) - ReLU - maxpool(2-2)- fc(1024) - ReLU - DropOut(0.5) - Softmax(10) Is there a second fully connected layer between the dropout layer and the softmax? Otherwise, the dropout would apply directly to the 10-class output before softmax rather than to a hidden layer\u2018s 1024 neurons. In the skeleton code, there's an indication of a second fc layer: self.fc2 = [inset-code]. If there's indeed a second fc layer, what should the output dimension of fc1 be?\n\nA: Ouput dimension of fc1 is 1024 neurons. You need fc2 to go from 1024 neurons to 10 neurons before applying softmax.",
    "source": "Piazza Q&A",
    "source_detail": "Piazza Question & Answer",
    "question": "Question about DCN structure\nI have a question regarding how to interpret the DCN model structure: conv1(5-5-1-32) - ReLU - maxpool(2-2) - conv2(5-5-32-64) - ReLU - maxpool(2-2)- fc(1024) - ReLU - DropOut(0.5) - Softmax(10) Is there a second fully connected layer between the dropout layer and the softmax? Otherwise, the dropout would apply directly to the 10-class output before softmax rather than to a hidden layer\u2018s 1024 neurons. In the skeleton code, there's an indication of a second fc layer: self.fc2 = [inset-code]. If there's indeed a second fc layer, what should the output dimension of fc1 be?",
    "answer": "Ouput dimension of fc1 is 1024 neurons. You need fc2 to go from 1024 neurons to 10 neurons before applying softmax.",
    "tags": [
      "assignment1"
    ],
    "doc_id": "piazza_qa_55",
    "doc_type": "piazza_qa",
    "is_followup": false
  },
  {
    "text": "Q: OH\nDo we still have OH for today?\n\nA: It appears @Mingshi Chen didn't make it to their office hour today. I'll be on the same Zoom link from 12:45-1:45pm",
    "source": "Piazza Q&A",
    "source_detail": "Piazza Question & Answer",
    "question": "OH\nDo we still have OH for today?",
    "answer": "It appears @Mingshi Chen didn't make it to their office hour today. I'll be on the same Zoom link from 12:45-1:45pm",
    "tags": [
      "other"
    ],
    "doc_id": "piazza_qa_56",
    "doc_type": "piazza_qa",
    "is_followup": false
  },
  {
    "text": "Q: Can we change the learning rate rate in part 2?\ncan we change the learning rate in the skeleton code in part 2? With lr=0.01 in the skeleton code, I found the loss not decreasing when training. I guessed it was oscillation. And after I tried to decrease the lr, it worked well. So is it allowed change the lr in the assignment? (I know that for c) I can definitely change it, but can I also change it in a) and b)? Or I would not be able to complete the training.)\n\nA: Yes, you\u2019re encouraged to experiment with different hyperparameters, just make sure to explain your findings in the report.",
    "source": "Piazza Q&A",
    "source_detail": "Piazza Question & Answer",
    "question": "Can we change the learning rate rate in part 2?\ncan we change the learning rate in the skeleton code in part 2? With lr=0.01 in the skeleton code, I found the loss not decreasing when training. I guessed it was oscillation. And after I tried to decrease the lr, it worked well. So is it allowed change the lr in the assignment? (I know that for c) I can definitely change it, but can I also change it in a) and b)? Or I would not be able to complete the training.)",
    "answer": "Yes, you\u2019re encouraged to experiment with different hyperparameters, just make sure to explain your findings in the report.",
    "tags": [
      "assignment1"
    ],
    "doc_id": "piazza_qa_57",
    "doc_type": "piazza_qa",
    "is_followup": false
  },
  {
    "text": "Q: Do we need to create a validation set? In the assignment PDF, it states: \"the MNIST data is split into three parts: 55,000 data points of training data (mnist.train), 10,000 points of test data (mnist.test), and 5,000 points of validation data (mnist.validation).\" And in Part 2(b), the requirement says: \"Also monitor the test and validation error after each 1100 iterations (equivalently, after each epoch).\" However, in the provided skeleton code , I only see: train_loader = [inset-code] test_loader = [inset-code] There is no val_loader or validate() function in the skeleton.",
    "source": "Piazza Q&A",
    "source_detail": "Piazza Question & Answer",
    "question": "Do we need to create a validation set?\nIn the assignment PDF, it states: \"the MNIST data is split into three parts: 55,000 data points of training data (mnist.train), 10,000 points of test data (mnist.test), and 5,000 points of validation data (mnist.validation).\" And in Part 2(b), the requirement says: \"Also monitor the test and validation error after each 1100 iterations (equivalently, after each epoch).\" However, in the provided skeleton code , I only see: train_loader = [inset-code] test_loader = [inset-code] There is no val_loader or validate() function in the skeleton. When I looked up the PyTorch MNIST dataset online, I found that PyTorch's datasets.MNIST does not have a validation set. So, should we follow the skeleton code structure (only train and test) and ignore the requirement for monitoring the validation error, or should we manually split the PyTorch training set into 55,000 train + 5,000 validation to match the description in the PDF?",
    "answer": "Sorry for the confusion, please follow the skeleton code structure (only train and test) In PyTorch, the MNIST dataset has a training set and a test set. For Part 2(b), please ignore any mention of a validation set and monitor accuracy/error on the test set. But you\u2019re welcome to split the training set into training and validation sets and report your findings on the validation set.",
    "tags": [
      "assignment1"
    ],
    "doc_id": "piazza_qa_58_chunk1",
    "doc_type": "piazza_qa",
    "is_followup": false,
    "parent_doc_id": "piazza_qa_58",
    "chunk_index": 1,
    "total_chunks": 4
  },
  {
    "text": "When I looked up the PyTorch MNIST dataset online, I found that PyTorch's datasets.MNIST does not have a validation set.",
    "source": "Piazza Q&A",
    "source_detail": "Piazza Question & Answer",
    "question": "Do we need to create a validation set?\nIn the assignment PDF, it states: \"the MNIST data is split into three parts: 55,000 data points of training data (mnist.train), 10,000 points of test data (mnist.test), and 5,000 points of validation data (mnist.validation).\" And in Part 2(b), the requirement says: \"Also monitor the test and validation error after each 1100 iterations (equivalently, after each epoch).\" However, in the provided skeleton code , I only see: train_loader = [inset-code] test_loader = [inset-code] There is no val_loader or validate() function in the skeleton. When I looked up the PyTorch MNIST dataset online, I found that PyTorch's datasets.MNIST does not have a validation set. So, should we follow the skeleton code structure (only train and test) and ignore the requirement for monitoring the validation error, or should we manually split the PyTorch training set into 55,000 train + 5,000 validation to match the description in the PDF?",
    "answer": "Sorry for the confusion, please follow the skeleton code structure (only train and test) In PyTorch, the MNIST dataset has a training set and a test set. For Part 2(b), please ignore any mention of a validation set and monitor accuracy/error on the test set. But you\u2019re welcome to split the training set into training and validation sets and report your findings on the validation set.",
    "tags": [
      "assignment1"
    ],
    "doc_id": "piazza_qa_58_chunk2",
    "doc_type": "piazza_qa",
    "is_followup": false,
    "parent_doc_id": "piazza_qa_58",
    "chunk_index": 2,
    "total_chunks": 4
  },
  {
    "text": "So, should we follow the skeleton code structure (only train and test) and ignore the requirement for monitoring the validation error, or should we manually split the PyTorch training set into 55,000 train + 5,000 validation to match the description in the PDF?  A: Sorry for the confusion, please follow the skeleton code structure (only train and test) In PyTorch, the MNIST dataset has a training set and a test set.",
    "source": "Piazza Q&A",
    "source_detail": "Piazza Question & Answer",
    "question": "Do we need to create a validation set?\nIn the assignment PDF, it states: \"the MNIST data is split into three parts: 55,000 data points of training data (mnist.train), 10,000 points of test data (mnist.test), and 5,000 points of validation data (mnist.validation).\" And in Part 2(b), the requirement says: \"Also monitor the test and validation error after each 1100 iterations (equivalently, after each epoch).\" However, in the provided skeleton code , I only see: train_loader = [inset-code] test_loader = [inset-code] There is no val_loader or validate() function in the skeleton. When I looked up the PyTorch MNIST dataset online, I found that PyTorch's datasets.MNIST does not have a validation set. So, should we follow the skeleton code structure (only train and test) and ignore the requirement for monitoring the validation error, or should we manually split the PyTorch training set into 55,000 train + 5,000 validation to match the description in the PDF?",
    "answer": "Sorry for the confusion, please follow the skeleton code structure (only train and test) In PyTorch, the MNIST dataset has a training set and a test set. For Part 2(b), please ignore any mention of a validation set and monitor accuracy/error on the test set. But you\u2019re welcome to split the training set into training and validation sets and report your findings on the validation set.",
    "tags": [
      "assignment1"
    ],
    "doc_id": "piazza_qa_58_chunk3",
    "doc_type": "piazza_qa",
    "is_followup": false,
    "parent_doc_id": "piazza_qa_58",
    "chunk_index": 3,
    "total_chunks": 4
  },
  {
    "text": "For Part 2(b), please ignore any mention of a validation set and monitor accuracy/error on the test set. But you\u2019re welcome to split the training set into training and validation sets and report your findings on the validation set..",
    "source": "Piazza Q&A",
    "source_detail": "Piazza Question & Answer",
    "question": "Do we need to create a validation set?\nIn the assignment PDF, it states: \"the MNIST data is split into three parts: 55,000 data points of training data (mnist.train), 10,000 points of test data (mnist.test), and 5,000 points of validation data (mnist.validation).\" And in Part 2(b), the requirement says: \"Also monitor the test and validation error after each 1100 iterations (equivalently, after each epoch).\" However, in the provided skeleton code , I only see: train_loader = [inset-code] test_loader = [inset-code] There is no val_loader or validate() function in the skeleton. When I looked up the PyTorch MNIST dataset online, I found that PyTorch's datasets.MNIST does not have a validation set. So, should we follow the skeleton code structure (only train and test) and ignore the requirement for monitoring the validation error, or should we manually split the PyTorch training set into 55,000 train + 5,000 validation to match the description in the PDF?",
    "answer": "Sorry for the confusion, please follow the skeleton code structure (only train and test) In PyTorch, the MNIST dataset has a training set and a test set. For Part 2(b), please ignore any mention of a validation set and monitor accuracy/error on the test set. But you\u2019re welcome to split the training set into training and validation sets and report your findings on the validation set.",
    "tags": [
      "assignment1"
    ],
    "doc_id": "piazza_qa_58_chunk4",
    "doc_type": "piazza_qa",
    "is_followup": false,
    "parent_doc_id": "piazza_qa_58",
    "chunk_index": 4,
    "total_chunks": 4
  },
  {
    "text": "Q: Dropout in 4-layer DCN impelmentation I have a question regarding the CNN architecture for Part 2. According to the assignment instructions, the required architecture is: conv1(5-5-1-32)- ReLU- maxpool(2-2)- conv2(5-5-32-64)- ReLU- maxpool(2-2)- fc(1024)- ReLU- DropOut(0.5)- Softmax(10) Based on this specification, it appears that Dropout should only be applied once, after the first fully connected layer (fc1).",
    "source": "Piazza Q&A",
    "source_detail": "Piazza Question & Answer",
    "question": "Dropout in 4-layer DCN impelmentation\nI have a question regarding the CNN architecture for Part 2. According to the assignment instructions, the required architecture is: conv1(5-5-1-32)- ReLU- maxpool(2-2)- conv2(5-5-32-64)- ReLU- maxpool(2-2)- fc(1024)- ReLU- DropOut(0.5)- Softmax(10) Based on this specification, it appears that Dropout should only be applied once, after the first fully connected layer (fc1). However, in the provided skeleton code, the __init__ method includes: class Net(nn.Module): def __init__(self): super(Net, self).__init__() self.conv1 = [inset-code] self.conv2 = [inset-code] self.conv2_drop = [inset-code] # This line self.fc1 = [inset-code] self.fc2 = [inset-code] This suggests defining a conv2_drop layer, which would imply a second Dropout after conv2. So, Should we: implement conv2_drop (Dropout after conv2 layer) in addition to the Dropout after fc1, i.e. conv1(5-5-1-32)- ReLU- maxpool(2-2)- conv2(5-5-32-64)- ReLU- maxpool(2-2)- DropOut2d(0.5) - fc(1024)- ReLU- DropOut(0.5)- Softmax(10) ? only implement Dropout after fc1 as specified in the architecture diagram, and ingore the conv2_drop in the __init__ method? Thanks for your clarification!",
    "answer": "Good catch. Option 1. implement conv2_drop (Dropout after conv2 layer) in addition to the Dropout after fc1 Option 2. only implement dropout layer after the fc layer. You can build the basic model as described in the instructions, but you\u2019re encouraged to explore, for example, adding more layers or adding dropout.",
    "tags": [
      "assignment1"
    ],
    "doc_id": "piazza_qa_59_chunk1",
    "doc_type": "piazza_qa",
    "is_followup": false,
    "parent_doc_id": "piazza_qa_59",
    "chunk_index": 1,
    "total_chunks": 4
  },
  {
    "text": "However, in the provided skeleton code, the __init__ method includes: class Net(nn.Module): def __init__(self): super(Net, self).__init__() self.conv1 = [inset-code] self.conv2 = [inset-code] self.conv2_drop = [inset-code] # This line self.fc1 = [inset-code] self.fc2 = [inset-code] This suggests defining a conv2_drop layer, which would imply a second Dropout after conv2. So, Should we: implement conv2_drop (Dropout after conv2 layer) in addition to the Dropout after fc1, i.e.",
    "source": "Piazza Q&A",
    "source_detail": "Piazza Question & Answer",
    "question": "Dropout in 4-layer DCN impelmentation\nI have a question regarding the CNN architecture for Part 2. According to the assignment instructions, the required architecture is: conv1(5-5-1-32)- ReLU- maxpool(2-2)- conv2(5-5-32-64)- ReLU- maxpool(2-2)- fc(1024)- ReLU- DropOut(0.5)- Softmax(10) Based on this specification, it appears that Dropout should only be applied once, after the first fully connected layer (fc1). However, in the provided skeleton code, the __init__ method includes: class Net(nn.Module): def __init__(self): super(Net, self).__init__() self.conv1 = [inset-code] self.conv2 = [inset-code] self.conv2_drop = [inset-code] # This line self.fc1 = [inset-code] self.fc2 = [inset-code] This suggests defining a conv2_drop layer, which would imply a second Dropout after conv2. So, Should we: implement conv2_drop (Dropout after conv2 layer) in addition to the Dropout after fc1, i.e. conv1(5-5-1-32)- ReLU- maxpool(2-2)- conv2(5-5-32-64)- ReLU- maxpool(2-2)- DropOut2d(0.5) - fc(1024)- ReLU- DropOut(0.5)- Softmax(10) ? only implement Dropout after fc1 as specified in the architecture diagram, and ingore the conv2_drop in the __init__ method? Thanks for your clarification!",
    "answer": "Good catch. Option 1. implement conv2_drop (Dropout after conv2 layer) in addition to the Dropout after fc1 Option 2. only implement dropout layer after the fc layer. You can build the basic model as described in the instructions, but you\u2019re encouraged to explore, for example, adding more layers or adding dropout.",
    "tags": [
      "assignment1"
    ],
    "doc_id": "piazza_qa_59_chunk2",
    "doc_type": "piazza_qa",
    "is_followup": false,
    "parent_doc_id": "piazza_qa_59",
    "chunk_index": 2,
    "total_chunks": 4
  },
  {
    "text": "conv1(5-5-1-32)- ReLU- maxpool(2-2)- conv2(5-5-32-64)- ReLU- maxpool(2-2)- DropOut2d(0.5) - fc(1024)- ReLU- DropOut(0.5)- Softmax(10) ? only implement Dropout after fc1 as specified in the architecture diagram, and ingore the conv2_drop in the __init__ method? Thanks for your clarification!  A: Good catch. Option 1. implement conv2_drop (Dropout after conv2 layer) in addition to the Dropout after fc1 Option 2. only implement dropout layer after the fc layer.",
    "source": "Piazza Q&A",
    "source_detail": "Piazza Question & Answer",
    "question": "Dropout in 4-layer DCN impelmentation\nI have a question regarding the CNN architecture for Part 2. According to the assignment instructions, the required architecture is: conv1(5-5-1-32)- ReLU- maxpool(2-2)- conv2(5-5-32-64)- ReLU- maxpool(2-2)- fc(1024)- ReLU- DropOut(0.5)- Softmax(10) Based on this specification, it appears that Dropout should only be applied once, after the first fully connected layer (fc1). However, in the provided skeleton code, the __init__ method includes: class Net(nn.Module): def __init__(self): super(Net, self).__init__() self.conv1 = [inset-code] self.conv2 = [inset-code] self.conv2_drop = [inset-code] # This line self.fc1 = [inset-code] self.fc2 = [inset-code] This suggests defining a conv2_drop layer, which would imply a second Dropout after conv2. So, Should we: implement conv2_drop (Dropout after conv2 layer) in addition to the Dropout after fc1, i.e. conv1(5-5-1-32)- ReLU- maxpool(2-2)- conv2(5-5-32-64)- ReLU- maxpool(2-2)- DropOut2d(0.5) - fc(1024)- ReLU- DropOut(0.5)- Softmax(10) ? only implement Dropout after fc1 as specified in the architecture diagram, and ingore the conv2_drop in the __init__ method? Thanks for your clarification!",
    "answer": "Good catch. Option 1. implement conv2_drop (Dropout after conv2 layer) in addition to the Dropout after fc1 Option 2. only implement dropout layer after the fc layer. You can build the basic model as described in the instructions, but you\u2019re encouraged to explore, for example, adding more layers or adding dropout.",
    "tags": [
      "assignment1"
    ],
    "doc_id": "piazza_qa_59_chunk3",
    "doc_type": "piazza_qa",
    "is_followup": false,
    "parent_doc_id": "piazza_qa_59",
    "chunk_index": 3,
    "total_chunks": 4
  },
  {
    "text": "You can build the basic model as described in the instructions, but you\u2019re encouraged to explore, for example, adding more layers or adding dropout..",
    "source": "Piazza Q&A",
    "source_detail": "Piazza Question & Answer",
    "question": "Dropout in 4-layer DCN impelmentation\nI have a question regarding the CNN architecture for Part 2. According to the assignment instructions, the required architecture is: conv1(5-5-1-32)- ReLU- maxpool(2-2)- conv2(5-5-32-64)- ReLU- maxpool(2-2)- fc(1024)- ReLU- DropOut(0.5)- Softmax(10) Based on this specification, it appears that Dropout should only be applied once, after the first fully connected layer (fc1). However, in the provided skeleton code, the __init__ method includes: class Net(nn.Module): def __init__(self): super(Net, self).__init__() self.conv1 = [inset-code] self.conv2 = [inset-code] self.conv2_drop = [inset-code] # This line self.fc1 = [inset-code] self.fc2 = [inset-code] This suggests defining a conv2_drop layer, which would imply a second Dropout after conv2. So, Should we: implement conv2_drop (Dropout after conv2 layer) in addition to the Dropout after fc1, i.e. conv1(5-5-1-32)- ReLU- maxpool(2-2)- conv2(5-5-32-64)- ReLU- maxpool(2-2)- DropOut2d(0.5) - fc(1024)- ReLU- DropOut(0.5)- Softmax(10) ? only implement Dropout after fc1 as specified in the architecture diagram, and ingore the conv2_drop in the __init__ method? Thanks for your clarification!",
    "answer": "Good catch. Option 1. implement conv2_drop (Dropout after conv2 layer) in addition to the Dropout after fc1 Option 2. only implement dropout layer after the fc layer. You can build the basic model as described in the instructions, but you\u2019re encouraged to explore, for example, adding more layers or adding dropout.",
    "tags": [
      "assignment1"
    ],
    "doc_id": "piazza_qa_59_chunk4",
    "doc_type": "piazza_qa",
    "is_followup": false,
    "parent_doc_id": "piazza_qa_59",
    "chunk_index": 4,
    "total_chunks": 4
  },
  {
    "text": "Q: PDF documen I would like to confirm about the report format for this assignment.",
    "source": "Piazza Q&A",
    "source_detail": "Piazza Question & Answer",
    "question": "PDF documen\nI would like to confirm about the report format for this assignment. For the PDF report, do we only need to include the written answers and the results after running the code (such as screenshots, graphs, and outputs)? And should the actual code files be placed separately in a ZIP file instead of being included in the PDF?",
    "answer": "From the instructions on the Canvas assignment (which doesn't match the assignment PDF itself ...): Option 1: Please submit your work for the following assignment as a PDF document, providing all answers, screenshots, and pictures required together in one document. Then include all relevant code and other files in a zip file (naming structure for this file defined in assignment instructions). Option 2: After converting your .ipynb file to a .pdf file, submit a PDF with both the code and output, i.e., code for Q1a followed by output for Q1a, etc. Make sure to run all the cells before submission. Don't forget to include textual answers to any written questions.",
    "tags": [
      "assignment1"
    ],
    "doc_id": "piazza_qa_60_chunk1",
    "doc_type": "piazza_qa",
    "is_followup": false,
    "parent_doc_id": "piazza_qa_60",
    "chunk_index": 1,
    "total_chunks": 3
  },
  {
    "text": "For the PDF report, do we only need to include the written answers and the results after running the code (such as screenshots, graphs, and outputs)? And should the actual code files be placed separately in a ZIP file instead of being included in the PDF?  A: From the instructions on the Canvas assignment (which doesn't match the assignment PDF itself ...): Option 1: Please submit your work for the following assignment as a PDF document, providing all answers, screenshots, and pictures required together in one document.",
    "source": "Piazza Q&A",
    "source_detail": "Piazza Question & Answer",
    "question": "PDF documen\nI would like to confirm about the report format for this assignment. For the PDF report, do we only need to include the written answers and the results after running the code (such as screenshots, graphs, and outputs)? And should the actual code files be placed separately in a ZIP file instead of being included in the PDF?",
    "answer": "From the instructions on the Canvas assignment (which doesn't match the assignment PDF itself ...): Option 1: Please submit your work for the following assignment as a PDF document, providing all answers, screenshots, and pictures required together in one document. Then include all relevant code and other files in a zip file (naming structure for this file defined in assignment instructions). Option 2: After converting your .ipynb file to a .pdf file, submit a PDF with both the code and output, i.e., code for Q1a followed by output for Q1a, etc. Make sure to run all the cells before submission. Don't forget to include textual answers to any written questions.",
    "tags": [
      "assignment1"
    ],
    "doc_id": "piazza_qa_60_chunk2",
    "doc_type": "piazza_qa",
    "is_followup": false,
    "parent_doc_id": "piazza_qa_60",
    "chunk_index": 2,
    "total_chunks": 3
  },
  {
    "text": "Then include all relevant code and other files in a zip file (naming structure for this file defined in assignment instructions). Option 2: After converting your .ipynb file to a .pdf file, submit a PDF with both the code and output, i.e., code for Q1a followed by output for Q1a, etc. Make sure to run all the cells before submission. Don't forget to include textual answers to any written questions..",
    "source": "Piazza Q&A",
    "source_detail": "Piazza Question & Answer",
    "question": "PDF documen\nI would like to confirm about the report format for this assignment. For the PDF report, do we only need to include the written answers and the results after running the code (such as screenshots, graphs, and outputs)? And should the actual code files be placed separately in a ZIP file instead of being included in the PDF?",
    "answer": "From the instructions on the Canvas assignment (which doesn't match the assignment PDF itself ...): Option 1: Please submit your work for the following assignment as a PDF document, providing all answers, screenshots, and pictures required together in one document. Then include all relevant code and other files in a zip file (naming structure for this file defined in assignment instructions). Option 2: After converting your .ipynb file to a .pdf file, submit a PDF with both the code and output, i.e., code for Q1a followed by output for Q1a, etc. Make sure to run all the cells before submission. Don't forget to include textual answers to any written questions.",
    "tags": [
      "assignment1"
    ],
    "doc_id": "piazza_qa_60_chunk3",
    "doc_type": "piazza_qa",
    "is_followup": false,
    "parent_doc_id": "piazza_qa_60",
    "chunk_index": 3,
    "total_chunks": 3
  },
  {
    "text": "Parent Q: PDF documen\nI would like to confirm about the report format for this assignment. For the PDF report, do we only need to include the written answers and the results after running the code (such as screenshots, graphs, and outputs)? And should the actual code files be placed separately in a ZIP file instead of being included in the PDF?\n\nFollowup Q: Thanks. So for the Option 1 here, we don't need to contain any code in report, right? Do we need to zip the tensorboard result file as well?\n\nA: Yes upload the tensorboard file as the 2nd file to avoid the TAs from dealing with a zip file",
    "source": "Piazza Q&A (Followup)",
    "source_detail": "Piazza Followup Question & Answer",
    "parent_question": "PDF documen\nI would like to confirm about the report format for this assignment. For the PDF report, do we only need to include the written answers and the results after running the code (such as screenshots, graphs, and outputs)? And should the actual code files be placed separately in a ZIP file instead of being included in the PDF?",
    "question": "Thanks. So for the Option 1 here, we don't need to contain any code in report, right? Do we need to zip the tensorboard result file as well?",
    "answer": "Yes upload the tensorboard file as the 2nd file to avoid the TAs from dealing with a zip file",
    "tags": [
      "assignment1"
    ],
    "doc_id": "piazza_qa_61",
    "doc_type": "piazza_qa",
    "is_followup": true
  },
  {
    "text": "Parent Q: PDF documen\nI would like to confirm about the report format for this assignment. For the PDF report, do we only need to include the written answers and the results after running the code (such as screenshots, graphs, and outputs)? And should the actual code files be placed separately in a ZIP file instead of being included in the PDF?\n\nFollowup Q: As for Option 2, do we need to paste the code of another .py file into Jupyter notebooks? For example, do we need to paste and modify the code of three_layer_neural_network.py into Jupyter or just import it?\n\nA: You can just import it. You can upload a .py file in addition to the jupyter notebook",
    "source": "Piazza Q&A (Followup)",
    "source_detail": "Piazza Followup Question & Answer",
    "parent_question": "PDF documen\nI would like to confirm about the report format for this assignment. For the PDF report, do we only need to include the written answers and the results after running the code (such as screenshots, graphs, and outputs)? And should the actual code files be placed separately in a ZIP file instead of being included in the PDF?",
    "question": "As for Option 2, do we need to paste the code of another .py file into Jupyter notebooks? For example, do we need to paste and modify the code of three_layer_neural_network.py into Jupyter or just import it?",
    "answer": "You can just import it. You can upload a .py file in addition to the jupyter notebook",
    "tags": [
      "assignment1"
    ],
    "doc_id": "piazza_qa_62",
    "doc_type": "piazza_qa",
    "is_followup": true
  },
  {
    "text": "Q: Questions about 1 d) 1. (mathematical derivation)\nDo we need to add regularization for 1 d) 1. (mathematical derivation)? Because in the provided code, there is one line for regularization, I'm not sure whether we should count for it in the mathematical derivation. Are we expected to write derivations for one sample (x is an vector with D dimensions) or a N samples (X is a matrix with the shape NxD)?\n\nA: No, you do not Neither, you need to compute the loss derivatives in terms of the neural network's components, e.g. W_1",
    "source": "Piazza Q&A",
    "source_detail": "Piazza Question & Answer",
    "question": "Questions about 1 d) 1. (mathematical derivation)\nDo we need to add regularization for 1 d) 1. (mathematical derivation)? Because in the provided code, there is one line for regularization, I'm not sure whether we should count for it in the mathematical derivation. Are we expected to write derivations for one sample (x is an vector with D dimensions) or a N samples (X is a matrix with the shape NxD)?",
    "answer": "No, you do not Neither, you need to compute the loss derivatives in terms of the neural network's components, e.g. W_1",
    "tags": [
      "assignment1"
    ],
    "doc_id": "piazza_qa_63",
    "doc_type": "piazza_qa",
    "is_followup": false
  },
  {
    "text": "Parent Q: Questions about 1 d) 1. (mathematical derivation)\nDo we need to add regularization for 1 d) 1. (mathematical derivation)? Because in the provided code, there is one line for regularization, I'm not sure whether we should count for it in the mathematical derivation. Are we expected to write derivations for one sample (x is an vector with D dimensions) or a N samples (X is a matrix with the shape NxD)?\n\nFollowup Q: Thanks! Maybe I did not express my question clearly. Because we need to use x to express aL/aW_1, I wonder whether we should use (x is an vector with D dimensions) or a N samples (X is a matrix with the shape NxD) when calculating.\n\nA: Your derivatives should not include X at all. Express dL/dW_1 in terms of the neural network's components, i.e., a, z, w",
    "source": "Piazza Q&A (Followup)",
    "source_detail": "Piazza Followup Question & Answer",
    "parent_question": "Questions about 1 d) 1. (mathematical derivation)\nDo we need to add regularization for 1 d) 1. (mathematical derivation)? Because in the provided code, there is one line for regularization, I'm not sure whether we should count for it in the mathematical derivation. Are we expected to write derivations for one sample (x is an vector with D dimensions) or a N samples (X is a matrix with the shape NxD)?",
    "question": "Thanks! Maybe I did not express my question clearly. Because we need to use x to express aL/aW_1, I wonder whether we should use (x is an vector with D dimensions) or a N samples (X is a matrix with the shape NxD) when calculating.",
    "answer": "Your derivatives should not include X at all. Express dL/dW_1 in terms of the neural network's components, i.e., a, z, w",
    "tags": [
      "assignment1"
    ],
    "doc_id": "piazza_qa_64",
    "doc_type": "piazza_qa",
    "is_followup": true
  },
  {
    "text": "Parent Q: Questions about 1 d) 1. (mathematical derivation) Do we need to add regularization for 1 d) 1. (mathematical derivation)? Because in the provided code, there is one line for regularization, I'm not sure whether we should count for it in the mathematical derivation. Are we expected to write derivations for one sample (x is an vector with D dimensions) or a N samples (X is a matrix with the shape NxD)?  Followup Q: Thanks! Maybe I did not express my question clearly.",
    "source": "Piazza Q&A (Followup)",
    "source_detail": "Piazza Followup Question & Answer",
    "parent_question": "Questions about 1 d) 1. (mathematical derivation)\nDo we need to add regularization for 1 d) 1. (mathematical derivation)? Because in the provided code, there is one line for regularization, I'm not sure whether we should count for it in the mathematical derivation. Are we expected to write derivations for one sample (x is an vector with D dimensions) or a N samples (X is a matrix with the shape NxD)?",
    "question": "Thanks! Maybe I did not express my question clearly. Because we need to use x to express aL/aW_1, I wonder whether we should use (x is an vector with D dimensions) or a N samples (X is a matrix with the shape NxD) when calculating.",
    "answer": "Ah, sorry, I forgot to say this as well: Your computed derivatives should be a product of derivatives. Here is a hint, fill in the ... and question mark $$\\frac{\\mathrm{dL} }{\\mathrm{d} W_{1}} = \\frac{\\mathrm{dL} }{\\mathrm{d} ...}\\cdot ... \\cdot \\frac{\\mathrm{d?} }{\\mathrm{d} W_{1}}\\cdot$$ You don't need to explicitly compute the last derivative, which avoids including either x or X in your final answer. I apologize for the confusion. Feel free to follow up if you need further clarification.",
    "tags": [
      "assignment1"
    ],
    "doc_id": "piazza_qa_65_chunk1",
    "doc_type": "piazza_qa",
    "is_followup": true,
    "parent_doc_id": "piazza_qa_65",
    "chunk_index": 1,
    "total_chunks": 3
  },
  {
    "text": "Because we need to use x to express aL/aW_1, I wonder whether we should use (x is an vector with D dimensions) or a N samples (X is a matrix with the shape NxD) when calculating.  A: Ah, sorry, I forgot to say this as well: Your computed derivatives should be a product of derivatives. Here is a hint, fill in the ... and question mark $$\\frac{\\mathrm{dL} }{\\mathrm{d} W_{1}} = \\frac{\\mathrm{dL} }{\\mathrm{d} ...}\\cdot ...",
    "source": "Piazza Q&A (Followup)",
    "source_detail": "Piazza Followup Question & Answer",
    "parent_question": "Questions about 1 d) 1. (mathematical derivation)\nDo we need to add regularization for 1 d) 1. (mathematical derivation)? Because in the provided code, there is one line for regularization, I'm not sure whether we should count for it in the mathematical derivation. Are we expected to write derivations for one sample (x is an vector with D dimensions) or a N samples (X is a matrix with the shape NxD)?",
    "question": "Thanks! Maybe I did not express my question clearly. Because we need to use x to express aL/aW_1, I wonder whether we should use (x is an vector with D dimensions) or a N samples (X is a matrix with the shape NxD) when calculating.",
    "answer": "Ah, sorry, I forgot to say this as well: Your computed derivatives should be a product of derivatives. Here is a hint, fill in the ... and question mark $$\\frac{\\mathrm{dL} }{\\mathrm{d} W_{1}} = \\frac{\\mathrm{dL} }{\\mathrm{d} ...}\\cdot ... \\cdot \\frac{\\mathrm{d?} }{\\mathrm{d} W_{1}}\\cdot$$ You don't need to explicitly compute the last derivative, which avoids including either x or X in your final answer. I apologize for the confusion. Feel free to follow up if you need further clarification.",
    "tags": [
      "assignment1"
    ],
    "doc_id": "piazza_qa_65_chunk2",
    "doc_type": "piazza_qa",
    "is_followup": true,
    "parent_doc_id": "piazza_qa_65",
    "chunk_index": 2,
    "total_chunks": 3
  },
  {
    "text": "\\cdot \\frac{\\mathrm{d?} }{\\mathrm{d} W_{1}}\\cdot$$ You don't need to explicitly compute the last derivative, which avoids including either x or X in your final answer. I apologize for the confusion. Feel free to follow up if you need further clarification..",
    "source": "Piazza Q&A (Followup)",
    "source_detail": "Piazza Followup Question & Answer",
    "parent_question": "Questions about 1 d) 1. (mathematical derivation)\nDo we need to add regularization for 1 d) 1. (mathematical derivation)? Because in the provided code, there is one line for regularization, I'm not sure whether we should count for it in the mathematical derivation. Are we expected to write derivations for one sample (x is an vector with D dimensions) or a N samples (X is a matrix with the shape NxD)?",
    "question": "Thanks! Maybe I did not express my question clearly. Because we need to use x to express aL/aW_1, I wonder whether we should use (x is an vector with D dimensions) or a N samples (X is a matrix with the shape NxD) when calculating.",
    "answer": "Ah, sorry, I forgot to say this as well: Your computed derivatives should be a product of derivatives. Here is a hint, fill in the ... and question mark $$\\frac{\\mathrm{dL} }{\\mathrm{d} W_{1}} = \\frac{\\mathrm{dL} }{\\mathrm{d} ...}\\cdot ... \\cdot \\frac{\\mathrm{d?} }{\\mathrm{d} W_{1}}\\cdot$$ You don't need to explicitly compute the last derivative, which avoids including either x or X in your final answer. I apologize for the confusion. Feel free to follow up if you need further clarification.",
    "tags": [
      "assignment1"
    ],
    "doc_id": "piazza_qa_65_chunk3",
    "doc_type": "piazza_qa",
    "is_followup": true,
    "parent_doc_id": "piazza_qa_65",
    "chunk_index": 3,
    "total_chunks": 3
  },
  {
    "text": "Parent Q: Questions about 1 d) 1. (mathematical derivation)\nDo we need to add regularization for 1 d) 1. (mathematical derivation)? Because in the provided code, there is one line for regularization, I'm not sure whether we should count for it in the mathematical derivation. Are we expected to write derivations for one sample (x is an vector with D dimensions) or a N samples (X is a matrix with the shape NxD)?\n\nFollowup Q: Thanks! Maybe I did not express my question clearly. Because we need to use x to express aL/aW_1, I wonder whether we should use (x is an vector with D dimensions) or a N samples (X is a matrix with the shape NxD) when calculating.\n\nA: Yes, the intermediate term should also be left in its symbolic form",
    "source": "Piazza Q&A (Followup)",
    "source_detail": "Piazza Followup Question & Answer",
    "parent_question": "Questions about 1 d) 1. (mathematical derivation)\nDo we need to add regularization for 1 d) 1. (mathematical derivation)? Because in the provided code, there is one line for regularization, I'm not sure whether we should count for it in the mathematical derivation. Are we expected to write derivations for one sample (x is an vector with D dimensions) or a N samples (X is a matrix with the shape NxD)?",
    "question": "Thanks! Maybe I did not express my question clearly. Because we need to use x to express aL/aW_1, I wonder whether we should use (x is an vector with D dimensions) or a N samples (X is a matrix with the shape NxD) when calculating.",
    "answer": "Yes, the intermediate term should also be left in its symbolic form",
    "tags": [
      "assignment1"
    ],
    "doc_id": "piazza_qa_66",
    "doc_type": "piazza_qa",
    "is_followup": true
  },
  {
    "text": "Q: Question sbout 1.b.2\nHi team, For the task 1.b.2 \u201cDerive the derivatives of Tanh, Sigmoid, and ReLU\u201d, do we need to include the mathematical derivations in the report, or is it sufficient to just complete the code implementation? (what's the difference with 1.b.3) Thanks!\n\nA: 1.b.2 is the mathematical derivation, whilst 1.b.3 is the coding implementation",
    "source": "Piazza Q&A",
    "source_detail": "Piazza Question & Answer",
    "question": "Question sbout 1.b.2\nHi team, For the task 1.b.2 \u201cDerive the derivatives of Tanh, Sigmoid, and ReLU\u201d, do we need to include the mathematical derivations in the report, or is it sufficient to just complete the code implementation? (what's the difference with 1.b.3) Thanks!",
    "answer": "1.b.2 is the mathematical derivation, whilst 1.b.3 is the coding implementation",
    "tags": [
      "assignment1"
    ],
    "doc_id": "piazza_qa_67",
    "doc_type": "piazza_qa",
    "is_followup": false
  },
  {
    "text": "Parent Q: Question sbout 1.b.2\nHi team, For the task 1.b.2 \u201cDerive the derivatives of Tanh, Sigmoid, and ReLU\u201d, do we need to include the mathematical derivations in the report, or is it sufficient to just complete the code implementation? (what's the difference with 1.b.3) Thanks!\n\nFollowup Q: So is it ok to write in hand, and paste the picture into the report?\n\nA: Yes, that\u2019s perfectly fine",
    "source": "Piazza Q&A (Followup)",
    "source_detail": "Piazza Followup Question & Answer",
    "parent_question": "Question sbout 1.b.2\nHi team, For the task 1.b.2 \u201cDerive the derivatives of Tanh, Sigmoid, and ReLU\u201d, do we need to include the mathematical derivations in the report, or is it sufficient to just complete the code implementation? (what's the difference with 1.b.3) Thanks!",
    "question": "So is it ok to write in hand, and paste the picture into the report?",
    "answer": "Yes, that\u2019s perfectly fine",
    "tags": [
      "assignment1"
    ],
    "doc_id": "piazza_qa_68",
    "doc_type": "piazza_qa",
    "is_followup": true
  },
  {
    "text": "Q: Question about MNIST template code\nI have a question about the criterion for section #line 118 in the Mnist part of the HW. the commented part says nn.CrossEntropyLoss() but I believe the criterion we want to be using is NLLLoss since I believe that this formula embodies that. # = sum_k(-t_k * log(y_k)) Was the cross entropy part just included for us to potentially use later for playing around with the model after the initial implementation?\n\nA: NLLLoss expects input as log-probabilities of each class. Obtaining log-probabilities in a neural network is easily achieved by adding a LogSoftmax layer in the last layer of your network. You may use CrossEntropyLoss instead, if you prefer not to add an extra layer. ( PyTorch docs nn.NLLLoss) So, the choice of criterion depends on the output of the last layer of your network.",
    "source": "Piazza Q&A",
    "source_detail": "Piazza Question & Answer",
    "question": "Question about MNIST template code\nI have a question about the criterion for section #line 118 in the Mnist part of the HW. the commented part says nn.CrossEntropyLoss() but I believe the criterion we want to be using is NLLLoss since I believe that this formula embodies that. # = sum_k(-t_k * log(y_k)) Was the cross entropy part just included for us to potentially use later for playing around with the model after the initial implementation?",
    "answer": "NLLLoss expects input as log-probabilities of each class. Obtaining log-probabilities in a neural network is easily achieved by adding a LogSoftmax layer in the last layer of your network. You may use CrossEntropyLoss instead, if you prefer not to add an extra layer. ( PyTorch docs nn.NLLLoss) So, the choice of criterion depends on the output of the last layer of your network.",
    "tags": [
      "assignment1"
    ],
    "doc_id": "piazza_qa_69",
    "doc_type": "piazza_qa",
    "is_followup": false
  },
  {
    "text": "Q: Are we allowed to search over the internet to solve problems in assignment 1 and future assignments?\nJust a general question, are we allowed to search over the internet to solve problems in assignment 1 and future assignments? If allowed I'll cite them academically.\n\nA: Yes, feel free to search over the internet for tutorials or debugging. But if you used someone's code, please cite.",
    "source": "Piazza Q&A",
    "source_detail": "Piazza Question & Answer",
    "question": "Are we allowed to search over the internet to solve problems in assignment 1 and future assignments?\nJust a general question, are we allowed to search over the internet to solve problems in assignment 1 and future assignments? If allowed I'll cite them academically.",
    "answer": "Yes, feel free to search over the internet for tutorials or debugging. But if you used someone's code, please cite.",
    "tags": [
      "assignment1"
    ],
    "doc_id": "piazza_qa_70",
    "doc_type": "piazza_qa",
    "is_followup": false
  },
  {
    "text": "Q: sum form or mean form\nso in 3 layer nn.py, i see in fit model func, we add regularization in sum form: dW2 += self.reg_lambda * self.W2 dW1 += self.reg_lambda * self.W1 does this mean in our backprop func, we should also use the sum form, which means delta don't need to be divided by number of samples? but then in loss func, i see the result is calculated using the mean form: return (1. / num_examples) * data_loss which look contradicting. So I'm a bit confused by this\n\nA: Backprop works fine either way (sum vs mean). If you divide by num_examples, you're just averaging, and that gets scaled by the learning rate. If you don't, the learning rate absorbs the extra scale. What really matters is the direction of the gradient, not the exact magnitude. But for calculating loss, you need to average it to be more interpretable.",
    "source": "Piazza Q&A",
    "source_detail": "Piazza Question & Answer",
    "question": "sum form or mean form\nso in 3 layer nn.py, i see in fit model func, we add regularization in sum form: dW2 += self.reg_lambda * self.W2 dW1 += self.reg_lambda * self.W1 does this mean in our backprop func, we should also use the sum form, which means delta don't need to be divided by number of samples? but then in loss func, i see the result is calculated using the mean form: return (1. / num_examples) * data_loss which look contradicting. So I'm a bit confused by this",
    "answer": "Backprop works fine either way (sum vs mean). If you divide by num_examples, you're just averaging, and that gets scaled by the learning rate. If you don't, the learning rate absorbs the extra scale. What really matters is the direction of the gradient, not the exact magnitude. But for calculating loss, you need to average it to be more interpretable.",
    "tags": [
      "assignment1"
    ],
    "doc_id": "piazza_qa_71",
    "doc_type": "piazza_qa",
    "is_followup": false
  },
  {
    "text": "Q: Assignment 1 deadline\nJust to confirm, the HW 1 is due to Oct 14 as stated in Canvas and not today oct7 as stated on the Course webpage?\n\nA: It is due October 14. I've fixed the typo on the Assignments tab of the course page.",
    "source": "Piazza Q&A",
    "source_detail": "Piazza Question & Answer",
    "question": "Assignment 1 deadline\nJust to confirm, the HW 1 is due to Oct 14 as stated in Canvas and not today oct7 as stated on the Course webpage?",
    "answer": "It is due October 14. I've fixed the typo on the Assignments tab of the course page.",
    "tags": [
      "assignment1"
    ],
    "doc_id": "piazza_qa_72",
    "doc_type": "piazza_qa",
    "is_followup": false
  },
  {
    "text": "Q: Visualization Problem 2 part B\nHi, I have a question on Assignment 1, problem 2, part B. This task generated so many plots, and I am not sure which one I need to put on my report. Which one do we attach to the report, the time series or scalars or distributions or histograms? Thank you! Best Regards,\n\nA: Include training plots (values across time) for the following: Weights Biases Net input Activations after ReLU Activations after maxpool",
    "source": "Piazza Q&A",
    "source_detail": "Piazza Question & Answer",
    "question": "Visualization Problem 2 part B\nHi, I have a question on Assignment 1, problem 2, part B. This task generated so many plots, and I am not sure which one I need to put on my report. Which one do we attach to the report, the time series or scalars or distributions or histograms? Thank you! Best Regards,",
    "answer": "Include training plots (values across time) for the following: Weights Biases Net input Activations after ReLU Activations after maxpool",
    "tags": [
      "assignment1"
    ],
    "doc_id": "piazza_qa_73",
    "doc_type": "piazza_qa",
    "is_followup": false
  },
  {
    "text": "Parent Q: Visualization Problem 2 part B\nHi, I have a question on Assignment 1, problem 2, part B. This task generated so many plots, and I am not sure which one I need to put on my report. Which one do we attach to the report, the time series or scalars or distributions or histograms? Thank you! Best Regards,\n\nFollowup Q: Do we also need to paste all the same figures for all the configurations in Q2c? That would be a really large number of figures because I tried a lot of different configurations in Q2c.\n\nA: Onle one combination @48",
    "source": "Piazza Q&A (Followup)",
    "source_detail": "Piazza Followup Question & Answer",
    "parent_question": "Visualization Problem 2 part B\nHi, I have a question on Assignment 1, problem 2, part B. This task generated so many plots, and I am not sure which one I need to put on my report. Which one do we attach to the report, the time series or scalars or distributions or histograms? Thank you! Best Regards,",
    "question": "Do we also need to paste all the same figures for all the configurations in Q2c? That would be a really large number of figures because I tried a lot of different configurations in Q2c.",
    "answer": "Onle one combination @48",
    "tags": [
      "assignment1"
    ],
    "doc_id": "piazza_qa_74",
    "doc_type": "piazza_qa",
    "is_followup": true
  },
  {
    "text": "Q: Slides\nHi, Where can we download the most updated slides? The slides from the course website is missing some contents. Thanks.\n\nA: To get you started, the class website's schedule has links to the slides from the 2020 version of the course: https://elec576.rice.edu/schedule-and-syllabus/ . I'll ask the professors if they want to update the slides on the website I've followed up with the profs, will keep you updated (Kesha)",
    "source": "Piazza Q&A",
    "source_detail": "Piazza Question & Answer",
    "question": "Slides\nHi, Where can we download the most updated slides? The slides from the course website is missing some contents. Thanks.",
    "answer": "To get you started, the class website's schedule has links to the slides from the 2020 version of the course: https://elec576.rice.edu/schedule-and-syllabus/ . I'll ask the professors if they want to update the slides on the website I've followed up with the profs, will keep you updated (Kesha)",
    "tags": [
      "logistics"
    ],
    "doc_id": "piazza_qa_75",
    "doc_type": "piazza_qa",
    "is_followup": false
  },
  {
    "text": "Q: Slides\nHi, Where can we download the most updated slides? The slides from the course website is missing some contents. Thanks.\n\nA: Slides for Sep 24, Oct 1, and Oct 8 are updated.",
    "source": "Piazza Q&A",
    "source_detail": "Piazza Question & Answer",
    "question": "Slides\nHi, Where can we download the most updated slides? The slides from the course website is missing some contents. Thanks.",
    "answer": "Slides for Sep 24, Oct 1, and Oct 8 are updated.",
    "tags": [
      "logistics"
    ],
    "doc_id": "piazza_qa_76",
    "doc_type": "piazza_qa",
    "is_followup": false
  },
  {
    "text": "Q: Can we submit JupyterBook in HW1\nHello, Because we need to write code and paste the results to the PDF report. Can we use JupyterBook ( ipynb ) directly and submit it as the report? Thanks.\n\nA: After converting your .ipynb file to a .pdf file, submit a PDF with both the code and output, i.e., code for Q1a followed by output for Q1a, etc. Make sure to run all the cells before submission. Don't forget to include textual answers to any written questions. This is now included in the Canvas assignment instructions:",
    "source": "Piazza Q&A",
    "source_detail": "Piazza Question & Answer",
    "question": "Can we submit JupyterBook in HW1\nHello, Because we need to write code and paste the results to the PDF report. Can we use JupyterBook ( ipynb ) directly and submit it as the report? Thanks.",
    "answer": "After converting your .ipynb file to a .pdf file, submit a PDF with both the code and output, i.e., code for Q1a followed by output for Q1a, etc. Make sure to run all the cells before submission. Don't forget to include textual answers to any written questions. This is now included in the Canvas assignment instructions:",
    "tags": [
      "assignment1"
    ],
    "doc_id": "piazza_qa_77",
    "doc_type": "piazza_qa",
    "is_followup": false
  },
  {
    "text": "Q: Deadline of HW1\nHi, HW1 is not available up until today and it seems we only have one week and a half to finish it (Dr. Ankit Patel said in class we would have 2-3 weeks to finish it). I think it's very challenging for many students in this class to meet the deadline given the amount of work needs to be done in HW1. Would you possibly consider postponing the deadline for a week (or just for a few more days)? Thank you!\n\nA: We have decided to give y'all an additional week for HW1",
    "source": "Piazza Q&A",
    "source_detail": "Piazza Question & Answer",
    "question": "Deadline of HW1\nHi, HW1 is not available up until today and it seems we only have one week and a half to finish it (Dr. Ankit Patel said in class we would have 2-3 weeks to finish it). I think it's very challenging for many students in this class to meet the deadline given the amount of work needs to be done in HW1. Would you possibly consider postponing the deadline for a week (or just for a few more days)? Thank you!",
    "answer": "We have decided to give y'all an additional week for HW1",
    "tags": [
      "assignment1"
    ],
    "doc_id": "piazza_qa_78",
    "doc_type": "piazza_qa",
    "is_followup": false
  },
  {
    "text": "Q: Question regarding HW1\nDear Professor, The homework folder seems to be locked. Would you mind unlocking the homework? Best, Stephen Tan\n\nA: Sorry for the inconvenience. We\u2019ve fixed the problem. Please let me know if it\u2019s still not visible.",
    "source": "Piazza Q&A",
    "source_detail": "Piazza Question & Answer",
    "question": "Question regarding HW1\nDear Professor, The homework folder seems to be locked. Would you mind unlocking the homework? Best, Stephen Tan",
    "answer": "Sorry for the inconvenience. We\u2019ve fixed the problem. Please let me know if it\u2019s still not visible.",
    "tags": [
      "assignment1"
    ],
    "doc_id": "piazza_qa_79",
    "doc_type": "piazza_qa",
    "is_followup": false
  },
  {
    "text": "Q: Regarding zoom recording\nHi, Are the class recordings uploaded anywhere? Where can I get the recordings? Thank you.\n\nA: On the Canvas course, click on Zoom in the left-hand side column (see screenshot). Then, click on cloud recordings. Finally, click on the date you're interested in.",
    "source": "Piazza Q&A",
    "source_detail": "Piazza Question & Answer",
    "question": "Regarding zoom recording\nHi, Are the class recordings uploaded anywhere? Where can I get the recordings? Thank you.",
    "answer": "On the Canvas course, click on Zoom in the left-hand side column (see screenshot). Then, click on cloud recordings. Finally, click on the date you're interested in.",
    "tags": [
      "logistics"
    ],
    "doc_id": "piazza_qa_80",
    "doc_type": "piazza_qa",
    "is_followup": false
  },
  {
    "text": "Q: Regarding zoom recording\nHi, Are the class recordings uploaded anywhere? Where can I get the recordings? Thank you.\n\nA: Please consider making your post public so other students can benefit from it if they have the same question.",
    "source": "Piazza Q&A",
    "source_detail": "Piazza Question & Answer",
    "question": "Regarding zoom recording\nHi, Are the class recordings uploaded anywhere? Where can I get the recordings? Thank you.",
    "answer": "Please consider making your post public so other students can benefit from it if they have the same question.",
    "tags": [
      "logistics"
    ],
    "doc_id": "piazza_qa_81",
    "doc_type": "piazza_qa",
    "is_followup": false
  },
  {
    "text": "Q: Are we allowed to search over the internet to solve problems?\nFor task 2, there are several commands like D,V = linalg.eig(a, b), D,V = eigs(a, k=3), cg and signal.resample(x, np.ceil(len(x)/q)) that seem can't be compiled using numpy packages. Are we allowed to search over the internet to solve this problem?\n\nA: Yes, some of the commands may be based on different versions of the Numpy package. You can search over to find the compatible command/version.",
    "source": "Piazza Q&A",
    "source_detail": "Piazza Question & Answer",
    "question": "Are we allowed to search over the internet to solve problems?\nFor task 2, there are several commands like D,V = linalg.eig(a, b), D,V = eigs(a, k=3), cg and signal.resample(x, np.ceil(len(x)/q)) that seem can't be compiled using numpy packages. Are we allowed to search over the internet to solve this problem?",
    "answer": "Yes, some of the commands may be based on different versions of the Numpy package. You can search over to find the compatible command/version.",
    "tags": [
      "assignment0"
    ],
    "doc_id": "piazza_qa_82",
    "doc_type": "piazza_qa",
    "is_followup": false
  },
  {
    "text": "Q: Can we compile all task results in a Jupyter Notebook for A0\nThere are many parts that require running code and copying and pasting the results. Could we instead put all the task results in a Jupyter Notebook, then either download the notebook as a PDF, or take screenshots of the results in the notebook and insert them into a Word document?\n\nA: Yes you can export the notebook. Please make sure all answers are included in the notebook.",
    "source": "Piazza Q&A",
    "source_detail": "Piazza Question & Answer",
    "question": "Can we compile all task results in a Jupyter Notebook for A0\nThere are many parts that require running code and copying and pasting the results. Could we instead put all the task results in a Jupyter Notebook, then either download the notebook as a PDF, or take screenshots of the results in the notebook and insert them into a Word document?",
    "answer": "Yes you can export the notebook. Please make sure all answers are included in the notebook.",
    "tags": [
      "assignment0"
    ],
    "doc_id": "piazza_qa_83",
    "doc_type": "piazza_qa",
    "is_followup": false
  },
  {
    "text": "Parent Q: Final Project Presentation - I noticed that the date of the final project presentation on the schedule is from December 10th to December 17th.\n\nFollowup Q: Is it allowed to do transfer learning with pre-trained model and add additional layers to the pre-trained model?\n\nA: Yes",
    "source": "Piazza Q&A (Followup)",
    "source_detail": "Piazza Followup Question & Answer",
    "parent_question": "Final Project Presentation",
    "question": "Is it allowed to do transfer learning with pre-trained model and add additional layers to the pre-trained model?",
    "answer": "Yes",
    "tags": [
      "project"
    ],
    "doc_id": "piazza_qa_104",
    "doc_type": "piazza_qa",
    "is_followup": true
  }
]